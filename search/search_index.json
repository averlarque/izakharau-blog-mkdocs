{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Recent Publications","text":""},{"location":"about/","title":"About","text":""},{"location":"about/#hello-world","title":"Hello World","text":"<p>Hi,</p> <p>My name is Ilya (\u026al\u02b2\u02c8ja),</p> <p>I am a skilled Product Manager and Agile Product Owner with extensive experience in B2B Enterprise products. I am passionate about building Platforms that allow other people to develop and deliver their products.</p> <p>I focus on helping teams integrate and adapt their Product APIs to customer needs as part of the Digital Experience transformation, building Insurance SaaS. My target areas are API Discovery with Dev portals, API Design with Low and No-code tooling, and the Platform's Infrastructure.</p> <p>My previous 5+ years in Business Analysis, prior Support Engineer experience, and Bachelor's degrees in Linguistics (Interpretation &amp; Literary Translation) and Economics (Logistics &amp; Supply Chain Management) give me the opportunity to communicate with tech and business stakeholders to find common ground. Product Management and Business Analysis are about translating customer needs into requirements and then addressing them with a product or its feature. So, I am still translating and interpreting what I have been doing at the university, but a bit on another level.</p> <p>I really care about mentoring and building empowered product teams. My favorite quote is from \"Creativity, Inc\" by Ed Catmull: \"If you give a good idea to a mediocre team, they will screw it up. If you give a mediocre idea to a brilliant team, they will either fix it or throw it away and come up with something better.\" I don't just believe that - I saw it multiple times. The team should have a trusted environment, the right tools, and shared knowledge. I have done that twice, so now I think I do know the recipe.</p> <p>My writing is disproportionally spread among LinkedIn, Medium, and my blog. I write about topics in which I feel I have some expertise and at least a few people could find it useful. Usually, it is about APIs, Business Analysis, and some Product Manager career insights </p> <p>I am a frequent speaker in the magnificent BA Warszawa community to which I am proud to belong. I would love to extend my speaking to conferences and other events, but time is very limited.</p> <p>Here are a few additional facts about me:</p> <ul> <li>I have Bachelor's degrees in Linguistics (interpretation &amp; literary translation - English, and French) and Economics (logistics).</li> <li>I started my IT career as an L1 Support Engineer back in 2014</li> <li>Then I switched to a Business Analyst role and worked for five years in outsourcing and product companies on various projects.</li> <li>Most of my projects and products have been B2B Enterprise related.</li> <li>I am usually involved in technically advanced endeavors. That is why I have knowledge of Python, SQL, RESTful APIs, etc. My current goal is to learn Go.</li> </ul>"},{"location":"about/#my-social-media","title":"My Social Media","text":"<p> ilya-zakharau</p> <p> ilya_zakharau</p> <p> @ilyazakharau</p> <p> ilya.zakharau</p> <p> averlarque</p>"},{"location":"about/#contact-me","title":"Contact Me","text":"<p>I am the most active on LinkedIn so you can connect and write to me there. Also, you can send me an old-fashioned email to ilya.zakharau@gmail.com.</p>"},{"location":"essays/api-design/","title":"API Design Series Overview","text":""},{"location":"essays/api-design/#api-design-series-overview","title":"API Design Series Overview","text":"<p>In 2022 I started exploring the API design-first approach and dedicated to this topic a series of articles on Linkedin (1, 2, 3, 4). I have revised the entire material and published the enhanced version on my blog.</p> <p>The enhanced version is more structured and has better language. Also, I rewrote some sections for more clarity. If you have already read those articles on LinkedIn, I encourage you to revisit them here.</p> <p>I decided to choose a more common term, API design, to entitle the series. Because of that, the series with a few articles might get more content in the future.</p> <p>It will be helpful for those Business Analysts, Product Owners, and Product Managers who want to learn more about API design concepts, tools, and find useful materials to continue the study.</p>"},{"location":"essays/api-design/#part-1-definition-of-api-requirements","title":"Part 1. Definition of API Requirements","text":"<p>An introduction to the API world, where we cover the following:</p> <ul> <li>why do we need to write requirements for API</li> <li>basic API terms you need to know</li> <li>what is API definition, API contract, and request logic</li> </ul>"},{"location":"essays/api-design/#part-2-non-functional-requirements-and-api","title":"Part 2. Non-functional Requirements and API","text":"<p>Here we talk about quality attributes for API (aka non-functional requirements):</p> <ul> <li>security</li> <li>reliability</li> <li>performance</li> <li>usability</li> <li>maintainability</li> <li>compliance</li> </ul>"},{"location":"essays/api-design/#part-3-api-design-first","title":"Part 3. API Design-First","text":"<p>In this article, we explore the following:</p> <ul> <li>why API definition is involved</li> <li>what API design-first means</li> <li>what are the benefits</li> <li>what are the disadvantages</li> <li>where should you go to learn to design API</li> </ul>"},{"location":"essays/api-design/#part-4-api-design-tooling","title":"Part 4. API Design Tooling","text":"<p>In this article, we review six low-code and no-code tools to design your API quickly and for free:</p> <ul> <li>Swagger Editor</li> <li>Postman</li> <li>Insomnia</li> <li>Stoplight</li> <li>Apicurio</li> <li>Apibldr</li> </ul>"},{"location":"essays/api-design/#part-5-backward-compatibility","title":"Part 5. Backward Compatibility","text":"<p>Here we learn how to avoid breaking changes, if possible</p>"},{"location":"essays/replacing-legacy/","title":"Foreword to the Blog Edition","text":""},{"location":"essays/replacing-legacy/#foreword-to-the-blog-edition","title":"Foreword to the Blog Edition","text":"<p>This is a summarized and edited version of the \"Replacing Legacy\" series published in Analyst's Corner on Medium from June 2023 to January 2024.</p> <p>The original Medium articles: 1, 2, 3, 4, 5.</p> <p>The Blog edition keeps the same structure:</p> <ul> <li>Part 1. Definition, Reasons, Characteristics</li> <li>Part 2. Archeology, Politics, Red Flags</li> <li>Part 3. Conversion &amp; Data Mapping</li> <li>Part 4. Business Logic Burden</li> <li>Part 5. Cloud, SaaS Legacy, and AI</li> </ul> <p>I started that topic when I made a\u00a0public speech\u00a0in 2019 describing BA challenges in a Legacy-replacing project dealing with a three-decade-old COBOL monolith. Four years later, I did a retrospective about that project and shared the lessons I had learned at\u00a0a BArszawa Community meetup. </p> <p>Then, I thought publishing my meetup materials as two articles on Medium would be a great idea. After publishing the first piece, I agreed to join the \"Analyst's Corner\" publication. I got incredible feedback, which inspired me to write three more articles.</p> <p>Now, they are available for everyone as a single long-read on my blog with some minor adjustments in the text. I still see potential improvements to the narrative, so I might rewrite some pieces one day.</p> <p>Enjoy reading!</p> <p> Sample of COBOL code generated by ChatGPT</p>"},{"location":"essays/replacing-legacy/replacing-legacy-1/","title":"Definition, Reasons, Characteristics","text":""},{"location":"essays/replacing-legacy/replacing-legacy-1/#definition-reasons-characteristics","title":"Definition, Reasons, Characteristics","text":"<p>Let's start with a definition of \"Legacy\":</p> <p>A legacy system is an old method, technology, computer system, or application program, \"of, relating to, or being a previous or outdated computer system,\" yet still in use.</p> <p>\u2014\u00a0Wikipedia</p> <p></p> <p>Our understanding of Legacy depends on what we consider \"old\" and \"outdated.\" From some perspective, a service you deployed last week to Production might already be the Legacy.</p> <p>Sorts of Legacy systems surround us. You can co-exist with a legacy by integrating it into your environment. Or you can replace it with a new system (which ironically will become the Legacy soon).</p> <p>In this and the following article, we will define what the Legacy-replacing project implies for a Business Analyst and other participants.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-1/#why-do-we-need-to-replace-a-legacy-system","title":"Why do we need to replace a Legacy system?","text":"<p>There are multiple reasons for replacing the Legacy:</p> <p>The system must be more scalable to meet current business needs</p> <p>We are living in a dynamic business environment, so software and hardware pursue the evolution to adapt or predict the needs. There is a limited capacity for change in an existing system. There will be a dilemma at some point: keep updating by sacrificing some new opportunities or proceed with the replacement.</p> <p>Security concerns</p> <p>Old software will likely contain exploits that can be used for malicious purposes. The protocols, libraries, and frameworks used in such systems may be outdated and no longer supported by their creators. So, security becomes a concern for the Legacy system.</p> <p>Difficulty in hiring people</p> <p>The popularity of some technologies can fade away. People who know it may not be willing to continue working with it and are ready to switch to a newer tech stack. A new generation is not eager to learn the \"old stuff.\" The older generation might be already retired. Replacing the Legacy with a more recent tech stack is also an attempt to match the current and possibly future hiring trends.</p> <p>License change</p> <p>A maintainer of technology used for a Legacy system may change the terms and conditions of usage. That may increase usage costs and trigger the replacement of Legacy with different, \"cheaper\" technology.</p> <p>Recent examples are\u00a0Oracle's changes\u00a0in licensing for Java and\u00a0Akka's change to BSL.</p> <p>There is a budget to spend and a manager's career to promote</p> <p>That may sound ridiculous, but it is true. Having ambitions and some resources may trigger replacing an existing system with a newer version. And it is good if such a replacement is justified from the business perspective. Otherwise, that might cause only additional troubles.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-1/#what-are-common-traits-of-legacy-projects","title":"What are common traits of Legacy projects?","text":"<p>If you join a project that aims to replace an operational Legacy system, you are likely to observe one or many items in various combinations:</p> <p>It is a Monolith (but not always)</p> <p>A Monolith software application is a single-tiered software application where all the components of the application are interconnected and interdependent. In other words, it is a single, unified application that performs all the functions required by the system. Monolith applications are usually large and complex, and any changes to the system require changes to the entire application. This makes it difficult to scale, maintain, and update the application.</p> <p>But Legacy does not always mean a monolith and vice versa. Any system built on other architectural patterns can be a legacy one.</p> <p>Outdated or absent documentation</p> <p>Documentation is the most overlooked piece in software development. The \"let's-document-it-later\" (never) approach in the long term becomes a significant concern. You need to understand the AS-IS of a system to proceed with a desired TO-BE.</p> <p>Absent documentation is much better than outdated and incorrect docs. In the first case, you know what you don't understand, which gives you an understanding of where to look. In the latter, you need to figure out where you are wrong. And that is more dangerous.</p> <p>Runtime is the source of truth</p> <p>You can't rely on the docs only. And depending on people is not an option either. It is an advantage to reach some people who have been working with the system for many years. But it would be best if you were cautious, as they might have their perspective on how things work. And that does not always coincide with reality.</p> <p>So, system-in-operation can be the source of truth. A BA can study how it operates under different conditions even though it is a black box. You need a lot of time, patience, and probably Postman.</p> <p>Another hint is to read a source code. It is uncommon for a BA to understand what is written there. But if you can understand how particular classes and methods work, that will make your life much easier.</p> <p>The source code is missing</p> <p>It is the worst-case scenario. The possibility that an organization can lose a source code of their service sounds ridiculous. But such cases happen in reality.</p> <p>You are not the first BA on a project</p> <p>And likely not the last one. There might be generations of business analysts who worked on maintaining or replacing a legacy system. If those persons are still reachable within your organization, it is an excellent opportunity to learn from their experience. Or start regretting that you are assigned to this project.</p> <p>Don't trust previous requirements</p> <p>I learned the hard way that if some requirements were written but not implemented some time ago, they are the subject of comprehensive revision.</p> <p>If you have inherited the backlog from a previous BA and it is already more than 1\u20133 months old, then you'd better revisit it. Requirements are not like wine. They usually turn to shit pretty quickly.</p> <p>Unmotivated Team</p> <p>Developers prefer to work with something other than legacy technologies. That can give some level of stability. But that may end up with losing a cost on the hiring market. But there are some exceptions, like COBOL developers.</p> <p>Older developers are dreaming more about retirement. Younger ones are dreaming about trending tech stacks. And they can have the motivation to replace the Legacy. But do they possess enough patience and competence to do that \u2014 that is the question.</p> <p>Building something from scratch is always easier than dealing with a tricky spaghetti code, sometimes not covered with any tests. And if there is poor team management, the atmosphere on such a project might not be very healthy for an ambitious BA.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-1/#one-more-important-thing","title":"One more important thing","text":"<p>\"Organizations which design systems \u2026 are constrained to produce designs which are copies of the communication structures of these organizations.\"</p> <p>\u2014\u00a0M. Conway</p> <p>A legacy is a blueprint to reflect many years of an organization's communication structure's development (or degradation). It is a corporate archeology when trying to reach an ever-missed context.</p> <p>Do we need to replicate those layers and bring them to the future? That topic we will discuss in the following chapters.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-2/","title":"Archeology, Politics, Red Flags","text":""},{"location":"essays/replacing-legacy/replacing-legacy-2/#archeology-politics-red-flags","title":"Archeology, Politics, Red Flags","text":"<p>In this part, we cover one of the approaches for modernization and possible caveats.</p> <p>Legacy systems usually have a monolithic structure with several layers of business logic added throughout the years of operation. And the microservice architecture is a modern response to the old lavish monolith. As there is no sense in replacing a monolith with another monolith, right?</p> <p>Such a pattern generally implies \"eating an elephant by pieces\": step-by-step re-implementing the functionality to transition from an old to a new system. But do we need to bring the old mess to the new home? That is the critical question to answer.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-2/#you-cant-repeat-the-past","title":"You can't repeat the past","text":"<p>There are two undeniable statements:</p> <ul> <li>The new system can't do something exactly like the old one. You will not create the exact copy even if you try hard to achieve a 100% match. You will get a different system anyway.</li> <li>There is no sense for the new system to act exactly like the old one. You most likely need some help understanding what you are doing if replicating the full functionality.</li> </ul> <p>For instance, the Legacy's Entity structure might be outdated and not match the current business domain. The entire data definition needs to be revised so that some entities will no longer possess the attributes they had, and some will no longer exist. So, the user and application interfaces are also the subject of complete revisions.</p> <p>A Business Analyst is usually involved in what I call \"Software archeology.\" The context between now and then shifted or was missed entirely. The responsible people left or forgot many details. No one knows why some features or logic were added and if it is utilized now or ever. You can spend time investigating the reasoning and end up with nothing. In this case, there are two ways: bring that into the new system (just in case) or cut that functionality and\u00a0see if that will hurt someone. The second option might be painful and consequential, so be cautious.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-2/#deconstructing-the-colossus","title":"Deconstructing the Colossus","text":"<p>If we are talking about a backend legacy, which multiple consumers use via API, the best strategy is to:</p> <ul> <li>Wrap the Legacy with the new API layer (API Gateway), replicating the current payload and bringing the new data format or API type (e.g., XML to JSON, SOAP to RESTful API, etc).</li> <li>Make the data conversion happen in that new layer, so the Legacy still works with its data structure, but now it is detached from the consumers.</li> <li>Make consumers migrate to call the Gateway instead of the Legacy directly. Be persistent and, at some point, cut the possibility of calling it directly. However, there is a must-have condition: the data conversion should work ideally without any performance concerns.</li> </ul> <p></p> <p>Data mapping and conversion is a massive topic on its own. It is challenging to manage the mapping of multiple huge entities between two formats. But if there is a three format, the conversion complexity doubles if not triples. Especially if you don't own all the structures.</p> <p></p> <p>The Team was working on the conversion between the legacy format and input/output JSON for Microservices API. But there was already a 3rd structure used by a Client with the existing conversion from Legacy to XML and vice versa. XML was not 100% equal to the Legacy structure and had unique data definitions.</p> <p>So that looks like Legacy -&gt; XML -&gt; JSON and reverse JSON -&gt; XML -&gt; Legacy. Supporting that kind of conversion was hell for the Team. They did a direct conversion between Legacy and JSON. However, the Client did not agree to migrate, so the transformation was challenging to maintain because both structures were fluent and constantly changed by different teams.</p> <p>The most important thing is to have a\u00a0technical vision\u00a0of how the Legacy will be decomposed. More than just a deck with a few fancy diagrams is required.</p> <p>Assuming we have the API layer and conversion layers.\u00a0Before we move to the actual decomposition, we need to have a testing strategy: how will we ensure that the new system does not regress compared to the monolith?</p> <p>A solution is to have an orchestrator that calls the new and old systems and then compares the outcomes. API layer can handle the first, and the testing service can do the latter. That will allow you to track and address possible degradation of the client experience (and catch bugs).</p> <p>Now that we have the API layer, conversion, and testing service, we can start cutting off monolith pieces and re-implement them as microservices. Doing it purely Agile without prior comprehensive system analysis can turn sour.</p> <p>What is lying on the surface is the low-hanging fruit. However, moving further and deeper might change the previous design and make further decomposition much harder.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-2/#lets-talk-about-politics","title":"Let's talk about politics","text":"<p>Internal politics is also a reason why delivering the result soon is critical, not waiting until you finish the decomposition. If you have an intermediate result sufficient to cover some logic handled without monolith, you must push it to Production. First, it is a good (but painful) experience. Second, it is difficult to cancel a project that is already in Production and used by customers.</p> <p>It is inevitable that some of the resources you had from the start will be drawn from you and reallocated to other business priorities. Or you will not be given enough resources constantly. So, from the beginning, there should be a releasing strategy. Not in a distant future, desirably.</p> <p>The Engineering Manager pushed the Team to launch a few already decomposed microservices along with the \"wrapped\" monolith for a Client product on a significant market. Those services were quite raw, so that was a challenging release with much effort spent on support.</p> <p>That seemed an unjustified effort, and the Team would instead focus on stabilization and further decomposition. But now I see that the manager was right, and it was necessary to do that release to demonstrate the progress and keep going.</p> <p>There is a temptation to introduce some decomposed pieces as a new application with enhanced capabilities previously not seen in the monolith. I call them Sidekicks, and they can outshine the \"parent\" product and shift the main focus to chasing a quick profit. I covered that topic in a\u00a0different essay\u00a0available on my blog.</p> <p>Such replacement is a money-consuming endeavor with no evident profits in the foreseeable future. It is a hard sell for the executive management. Having a new exited application is a trick to start chasing quick money instead of focusing the resources on the legacy replacement.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-2/#red-flags","title":"Red flags","text":"<p>To name a few signs when something goes wrong or will likely go wrong in the future:</p> <ol> <li>Legacy system components are owned by different teams without a single Leadership.</li> <li>The \"Legacy\" and the \"Replacement\" are different teams under different management.</li> <li>The source code of a Legacy is missed, or the Replacement Team cannot access it.</li> <li>Some Legacy documentation cannot be shared with the Replacement Team due to various concerns.</li> <li>Develop the Sidekicks (see above) in parallel.</li> <li>\"Deal with it later\" attitude toward the next steps.</li> <li>Frequent changes in the technology stack: frequent migration to different CI/CD tools, libraries, frameworks, and databases (e.g., MongoDB to PostgreSQL).</li> </ol>"},{"location":"essays/replacing-legacy/replacing-legacy-2/#closing-thoughts-to-part-2","title":"Closing thoughts to Part 2","text":"<p>We all know that the system exists only to satisfy the needs of higher systems (to simplify things, we call it \"the Business\"). And we also know that there are multiple ways to satisfy those needs. It is about making the right choice when answering the \"how\" question. People behind a Legacy system once made their choice. Time proved whether they were right about something or not.</p> <p>People behind the new system need to make their own calculated choices based on the context and environment where an organization currently exists. They only need the required time, resources, competence, and dedication. Not so much, right?</p> <p>In the end, here is my favorite picture on this topic:</p> <p></p>"},{"location":"essays/replacing-legacy/replacing-legacy-3/","title":"Conversion & Data Mapping","text":""},{"location":"essays/replacing-legacy/replacing-legacy-3/#conversion-data-mapping","title":"Conversion &amp; Data Mapping","text":"<p>Previously, I mentioned an approach of \"wrapping\" a legacy system by providing a modern API layer as an abstraction to separate the Legacy from their clients. And migrate them to new APIs with the updated data format/new models. After that, you can proceed with the decomposition, not bothering the clients again.</p> <p></p> <p>The \"wrapping\" strategy implies that the Legacy will still operate for some time alongside the new system, creating a seamless transition experience for consumers. That results in the conversion layer requiring data mapping as a BA artifact.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-3/#lets-talk-about-mappings","title":"Let's talk about mappings","text":"<p>We already discussed the massive challenge of reinventing the Legacy Data Models, so let's assume you have already done it. Mapping is a data dictionary containing relationships among new and old attributes with helpful information for executing data conversion. That may include (in any format and combination):</p> <ul> <li>attribute name</li> <li>attribute position in a structure (e.g., JSON path)</li> <li>related Entity (especially ones not presented in the Legacy)</li> <li>related legacy attribute(s)</li> <li>data type (especially if there is a data type conversion)</li> <li>description of what that attribute means with any useful references</li> <li>any aggregation or other logic (you don't think it is always 1\u20131 mapping, right?)</li> </ul> <p>A BA must combine and maintain the mapping throughout the project timeline. So, where and how to manage a mapping is an important question you'd better know the answer from the start.</p> <p>I don't have numbers, but such data mapping for a legacy system is usually enormously big. Migrating it from one tool to another is not what you want to spend time on. So, let's see a few options.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-3/#confluence","title":"Confluence","text":"<p>It might be an obvious choice if you work with the Atlassian products. But I wouldn't say it is suitable for large mappings due to poor performance and sometimes strange table formatting. Some paid plugins allow you to manage huge tables on multiple pages, but not in an out-of-the-box on-premise installation.</p> <p>The main advantage is version management and integration with Jira. But problems may come when a senior stakeholder asks about exporting it to\u2026</p>"},{"location":"essays/replacing-legacy/replacing-legacy-3/#excel-spreadsheets","title":"Excel spreadsheets","text":"<p>Let's be clear: that should be your first choice by default. Once, I had to migrate data mapping from Confluence to an Excel spreadsheet due to a stakeholder's request I could not deny. Only my Python skills saved me from the very dull routine. I made up a trivial script that parses Confluence's XML and converts it to a spreadsheet.</p> <p>And you are right: since I had to support both mappings in Confluence and in Excel. But my script helped me to work that out and focus on the mapping in Confluence.</p> <p>By the way, I was very proud that developers put my amateur Python code under the project's git repository to keep that script alongside the new system code.</p> <p>Managing a considerable data mapping in Microsoft's Excel/Google spreadsheet is still challenging. But that is still better than Confluence (sorry, Atlassian). You can also attach that spreadsheet to a Confluence page if needed.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-3/#versioning","title":"Versioning","text":"<p>Managing versions and access rights is still debatable and depends on project specifics. I recommend keeping the master version with ongoing changes where only a few people can edit it. Each release has a release mapping version copy as a separate file and stored somewhere else (Confluence, Sharepoint).</p> <p>It is also possible to introduce versioning of each attribute. But it would be best if you had a solid reason to justify increased maintenance efforts. That can quickly end up as a burden.</p> <p>And there is always an option to put it under a git and manage versioning there if you know how to do that.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-3/#other-mapping-tools","title":"Other mapping tools","text":"<p>I researched to find an alternative where I can keep and manage extensive mappings. But most of them were enterprise tools and part of a tooling vendor portfolio. They looked awful from the UI/UX perspective and cost too much. No manager will be happy to spend so much of the project budget on a license when Confluence and Excel are under your hands.</p> <p>At some point, I was so desperate to start thinking about writing my own tool to manage data mappings. But I found that idea too altruistic and time-consuming to do it alone.</p> <p>If you know a free tool to manage data mappings, please let me know in the comments or write me on LinkedIn.</p> <p>Right now, Google Spreadsheets is the best available option. And maybe Notion, with its databases, can also work for large mappings.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-3/#what-about-xslt","title":"What about XSLT?","text":"<p>At some point, the Team was considering the possibility of using\u00a0XSLT\u00a0to manage the data mapping. But we decided not to proceed with that approach because:</p> <ul> <li>Stakeholders from the business side can't read and understand that format. They prefer old-fashioned spreadsheets. So, you will have to maintain both artifacts and spend more time than you already spend on maintaining hundreds of attributes.</li> <li>Maintaining a massive mapping in one file is a challenge. However, decomposing it into multiple files adds more issues to resolve.</li> <li>Part of the mapping was from XML to JSON, but there was also a part in a COBOL data format. I don't think XSLT can handle this.</li> <li>Developers did not like that idea from the start for their reasons.</li> </ul>"},{"location":"essays/replacing-legacy/replacing-legacy-3/#testing-conversion","title":"Testing conversion","text":"<p>We made both-side conversions in a separate microservice and provided a command-line interface for testing. Having a legacy input, we can convert it into the new format and back and check for a difference. Legacy outcomes are converted to the new format and back similarly.</p> <p>However, a \"converted\" legacy data can have some\u00a0expected differences\u00a0from an \"original\" one. For example, in a COBOL structure, \"0\" may have the same meaning as a blank space. And we can't predict what we get from a client. But conversion shall have only one interpretation in a result.</p> <p>Additionally, some intentional changes can be implemented for the conversion. Or some legacy structures can be omitted. They should be documented and considered by test and automation tests.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-3/#legacy-does-not-sleep","title":"Legacy does not sleep","text":"<p>If a legacy system is operational and some critical business processes rely on it, it will continue evolving. It is unlikely that changes will happen in the existing attributes (remember, they need to maintain layers and layers of prehistoric logic), but new attributes may arrive.</p> <p>A BA must be aware of such changes in the mapping until the Legacy is entirely replaced. In most cases, development is done by different teams and mostly in parallel to keep the new and old data layers consistent.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-3/#piece-of-advice","title":"Piece of advice","text":"<p>A BA should know the meaning of each mapped attribute. Or at least think that they know. But when you inherit a mapping structure from previous BAs who left the project, some context is lost anyway. You may research Jira tickets, emails, and documentation, but some valuable information is lost anyway. Moreover, there might be non-discovered mistakes in the mapping.</p> <p>It is easier to say that you must understand each attribute's definition and avoid thoughtless mapping, relying on intuition and presumable common sense. But that will help when you proceed to the next big step: decomposing the legacy business logic \u2014 that one we cover in the next chapter.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-4/","title":"Business Logic Burden","text":""},{"location":"essays/replacing-legacy/replacing-legacy-4/#business-logic-burden","title":"Business Logic Burden","text":"<p>In the previous chapters, we focused on a gap we must cover for transitioning from a legacy to a new model definition. The business logic layer is the next challenge to address.</p> <p>Legacy systems contain multiple layers of business logic developed throughout the years of operation. Each layer usually represents a business context of a particular period. We believe such layers are added cautiously, avoiding impact on the previous layers, even if that is not always true.</p> <p>Another notorious characteristic of legacy systems is outdated or lack of documentation. As a result, knowledge about a specific business logic is encoded in source code and kept in the minds of employees who work with that logic. That \"people\" knowledge is temporary: it vanishes with time and when employees leave an organization or join another team.</p> <p>Thus, we again reference archeology, which has many historic layers buried under the ground without written pieces of evidence and other eyewitnesses. Handling that burden is one of a business analyst's most complex tasks. I summarized a few thoughts on the topic following my experience.</p> <p> Documentation of an ancient business rule. Approximately the beginning of the 2010s. The author is unknown (no longer working in a company). Free Stock photos by Vecteezy</p>"},{"location":"essays/replacing-legacy/replacing-legacy-4/#definition-of-business-logic","title":"Definition of Business Logic","text":"<p>\"Business logic\" is the first term I heard when I joined IT. It is a self-explanatory term everyone understands universally. As usual, with universal terms, everyone has their understanding.</p> <p>I was surprised when I realized that neither BABOK v3 nor the \"Software Requirements\" explicitly defines what business logic means. So I turned to\u00a0Wikipedia:</p> <p>In computer software, business logic or domain logic is part of the program that encodes the real-world business rules that determine how data can be created, stored, and changed.</p> <p>But later in the article, it provides a bit of a conflicting statement with the definition mentioned above:</p> <p>Business logic should be distinguished from business rules. Business logic is the portion of an enterprise system which determines how data is transformed or calculated, and how it is routed to people or software (workflow). Business rules are formal expressions of business policy. Anything that is a process or procedure is business logic, and anything that is neither a process nor a procedure is a business rule.</p> <p>Not to spend more time battling on the terminology, let's agree that within this article, I understand both workflows and business rules implementation as the business logic.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-4/#starting-conditions","title":"Starting Conditions","text":"<p>Considering the new model definition and modern business context, it is impossible to move business logic from the Legacy to the new system as-is. So, there is a gap to address in transitioning from AS-IS to TO-BE. But to make that leap, we must have a precise understanding (and preferably well-documented) of the AS-IS state.</p> <p>The overall complexity of the task depends on the current phase of the Legacy support in an organization:</p> <p>1) Active development A development team keeps supporting old and implementing new features in a Legacy system. That means there is at least enough documentation, test cases, and BA artifacts for the new pieces. Also, some SMEs (Subject Matter Experts) know some parts of the system well. They might have a partial picture, but that is a good starting point anyway.</p> <p>There are a few caveats here:</p> <ul> <li>The Team might not be happy to help you because, technically, your work will eliminate their work. Especially when they work on an outdated technology stack that is not very popular on the market.</li> <li>The quality of their artifacts and knowledge, in general, might be low, so you would need to invest a lot of effort anyway.</li> <li>You need to keep up with their changes, which may need to be aligned with the vision of the Replacement system.</li> </ul> <p>2) Support mode There is no new functionality, but an internal or outsourced team supports a Legacy system by fixing bugs and making minor improvements. Or it can be a vendor. They possess little knowledge about the system compared to an active development team. And they are also not happy about your presence.</p> <p>3) Hibernation A Legacy system is not operational, so neither development nor support is happening. So, there are low chances to find up-to-date documentation or SMEs.</p> <p>I can barely imagine why some organizations might need to replace a system not in Production. But let's keep that option for a better count.</p> <p>Thus, your activities to reinstate the AS-IS state depend on those conditions. Please consider that when you estimate BA activities and choose strategy wisely.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-4/#top-to-bottom-bottom-to-top-approach","title":"Top-to-bottom &amp; bottom-to-top approach","text":"<p>Business logic can be re-discovered with top-to-bottom and bottom-to-top approach:</p> <p>Top-to-bottom: interviewing stakeholders to understand how the system works and mainly why it works that way, not another.</p> <p>And remember that:</p> <ul> <li>you need to identify them first;</li> <li>some stakeholders are missed and, possibly forever;</li> <li>existing stakeholders might forget or miss something.</li> </ul> <p>That is why we also need Bottom-to-top: learning how the system works by testing it or reviewing the source code.</p> <p>Use those methods interchangeably: prove the words of stakeholders with current behavior. Refrain from trusting them unquestioningly, even ones who are very senior, and claim they know how everything works. Reality shows that it is not always the case.</p> <p>So my main advice sounds doom-ish: \"Don't trust stakeholders. Don't trust documentation. Trust tests that you executed and proved they are correct.\" It is good when there are test scenarios or even automation tests. But if that is not the case, I encourage you to create them.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-4/#moving-to-to-be-without-complete-as-is","title":"Moving to TO-BE without complete AS-IS","text":"<p>Based on the current business logic, together with stakeholders, you need to elaborate new logic aligned with the new model definition. And here is a caveat: you start working on the new/improved business logic for a Replacement system before you get a complete picture of the current logic. Simply because you are not paid to document the as-is state, you are paid to replace it.</p> <p>So, while documenting and understanding the current process, you will also work on the TO-BE state in parallel. In this case, you must be very cautious about the scope of the pieces you analyze. The legacy system has layers that can be interconnected in sometimes very bizarre ways.</p> <p>So, when you think you have done the analysis, you might get to redo it once again when you move forward and discuss some further system modules.</p> <p>While working with Legacy, you will also start treating debt differently, as, during analysis, you face years of aggregated tech or business debt. Ideally, you must not move that kind of debt from the Legacy to the new system. But there might be cases when a proper solution requires revising the TO-BE state once and again, and proceeding with a weaker solution is easier. That is all about compromises.</p> <p>You might feel that Agile is unsuitable for such projects due to its iterative nature with frequent delivery. But that is not actually true. However, you need to get the full picture as quickly as possible to be able to decompose the system and address those pieces with as little re-work as possible.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-4/#describing-business-logic","title":"Describing business logic","text":"<p>There are different ways of describing business logic, from textual to visual. Business stakeholders like fancy diagrams but are not good at reading heavy and puzzling pieces. No one is good at it, actually.</p> <p>So, you have to translate them to the audience and carefully drive their understanding. Just sending them links to Lucidchart or PDF files with diagrams and asking for approval is a questionable approach that won't be effective in the long run. Be prepared to hold multiple workshop sessions. Very quickly, you realize you know the system better than most experts.</p> <p>Throwing AS-IS and TO-BE diagrams to the Development team is not enough. As a Business Analyst, you will have to decompose the pieces and clearly articulate the scope of changes with acceptance criteria.</p> <p>So, you'll likely have different BA artifacts for the business and the implementation. That is a big deal once you reach a heavy cognitive load by supporting many artifacts.</p> <p>I suggest minimizing that gap: whether devs become more proficient in BPMN diagrams or business stakeholders in reading details acceptance criteria.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-4/#determinate-a-decision-maker","title":"Determinate a Decision-maker","text":"<p>Our best intention is to avoid moving the mess to the new system. The Legacy usually aggregates the layers of business logic, and their context can be lost in time and be overridden with the following pieces. It is a frequent case that someone requests a business rule implementation, and then something changes, and it becomes non-valid. So customers stopped using it without notifying developers or, worse, never used it. But the code continues to exist without questioning its relevance.</p> <p>Remember, Legacy is usually an on-premise solution where developers are rarely involved in operation. Not mentioning any kind of analytics.</p> <p>The purpose is to cut obsolete parts and move the important ones to the Replacement system. And there should be a person, not a Business Analyst, but a senior business stakeholder. Who must also be accountable for decisions if a cut piece appears vital for some parties.</p> <p>For larger systems, there can be a group of persons responsible for specific business areas. And this is where politics enters the room. Most likely, such a committee will always choose the safest option: to move existing stuff to the new system so as not to cause potential issues.</p> <p>The best option is to have a brave business leader who knows exactly what is required and clearly defines what needs to be migrated and how. I have heard that such people exist but have never met one.</p> <p>But please, my dear Business Analyst, don't put that burden on your shoulders.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-5/","title":"Cloud, SaaS Legacy, and AI","text":""},{"location":"essays/replacing-legacy/replacing-legacy-5/#cloud-saas-legacy-and-ai","title":"Cloud, SaaS Legacy, and AI","text":"<p>Here, we reflect on the reasoning behind the past, current, and future trends: Cloud deployments, SaaS (Software-as-a-Service), and AI (Artificial Intelligence). The first two can\u2019t be considered trends anymore. It has been the reality for more than a decade. AI is more speculative; knowing it impacts the industry, we still need to find out to what extent that will be.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-5/#empire-of-the-clouds","title":"Empire of the Clouds","text":"<p>Software modernization has recently accelerated for several interconnected reasons: Cloud, then SaaS, and related deviations such as PaaS (Platform-as-a-Service), IaaS (Infrastructure-as-a-Service), etc. For simplicity, let\u2019s call them XaaS (X-as-a-Service). That resulted in DevOps, which, in its turn, has launched a technology race.</p> <p>Despite all the skepticism a decade ago, most Enterprises moved to the Cloud infrastructure. We will not discuss the pros and cons of such a move and the multiple factors that led to that. I can pay my respects to the tremendous marketing efforts from AWS, Azure, Google Cloud, and smaller cloud vendors to convince business folks to take that step.</p> <p>We focus on one thesis: Cloud infrastructure works better with services built around Microservice Architecture (MSA). You can run a monolithic application in the Cloud but cannot benefit from scaling, resilience, and using tooling built around the infrastructure effectively.</p> <p>Legacy doesn\u2019t always mean a monolith. However, most legacy systems are monolithic just because that was the way to design software in the past. So, decomposing a monolith into microservices began as a prerequisite or one of the phases of modernization triggered by the Cloud migration. That has not necessarily been the case everywhere, but there was and still is a trend for such decomposition.</p> <p>Also, the Cloud caused the rise of a new XaaS market for multiple industries. That shift implied having the MSA to keep up with the rapid pace of business and technology changes. So, organizations had to embrace the new approach and adapt their software for a new way of doing business.</p> <p>Another factor is the technological shift. Cloud also caused the DevOps movement/philosophy, which changed the software development and operations landscape. A new tooling class emerged in the growing market to develop, deploy, and run software in a new way.</p> <p>That is quite a simplified explanation, but the sequence is precise: Cloud caused XaaS as a new business form and DevOps as a technological paradigm. All that, also implying MSA, pushed the need to replace legacy systems, sometimes decades in operations, with something new and shiny. No matter what.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-5/#its-almost-easy","title":"It\u2019s Almost Easy","text":"<p>I don\u2019t have numbers on my side, but as an industry, we are not very successful with the total replacement. Even if someone has numbers to prove or oppose my idea, I doubt it. My point is purely subjective based on personal and professional experience and outlook.</p> <p>The key is that we struggle to get rid of Legacy entirely due to various reasons, such as:</p> <ul> <li>new systems will become outdated sooner or later anyway</li> <li>high costs that do not cover the benefits</li> <li>legacy environment impacting a replacement system</li> </ul> <p>The first two points are clear: it is difficult to compete with time, and the complexity of the migration might not meet ROI (return on investment) expectations for the next decade. And it is a general problem; we are more focused on the current and near-future outcomes. We only care a little if the benefits are too far and difficult to reach. We would instead choose a more accessible and quicker resolution. Thus, it will likely be cut off if the legacy migration projects exceed their budget and timeline (I think it is a common issue).</p> <p>We should remember that a software application co-exists with others. It is always a part of a larger system, a part of a higher-level system, and so on. A system operates in a specific environment that might appear to be a legacy. If we replace a legacy system, that might not impact the environment in an expected way.</p> <p>Another aspect of a legacy environment is that some lousy design decisions might be imposed for the sake of compatibility. In my practice, while wrapping a COBOL application with a REST API layer supporting JSON format, the team had to support an intermediary XML format conversion. Support of such a 3-side conversion caused multiple problems in the result.</p> <p>Replacing a legacy environment is a perilous and costly endeavor. That is why it usually ends with sub-optimizing certain parts; let\u2019s call it modernization.</p> <p>So we understand we can\u2019t fully win in that battle. What can we do:</p> <ul> <li>Decompose only certain \u201creasonable\u201d parts as microservices and keep the remaining Legacy wrapped with a modern API interface. I covered that approach in Part 2 and recently learned it is called the Stranger pattern.</li> <li>Start building a new system/environment from scratch so you have complete freedom. There are two significant concerns: does the organization possess the expertise and resources to create a new system, and how will it migrate an existing customer? Mainly if the Legacy still generates a considerable income.</li> <li>Replace some parts or an entire legacy with one or several SaaS vendors. Let\u2019s talk about that option in detail.</li> </ul>"},{"location":"essays/replacing-legacy/replacing-legacy-5/#legacy-saas","title":"Legacy SaaS","text":"<p>Can SaaS become a legacy? Sure, it can.</p> <p>Developing a custom application or outsourcing is one of many options. If a legacy was built internally, you can find an appropriate SaaS vendor for relatively small or mid-size legacy applications. For giant multifunctional monoliths, there are fewer chances to find an all-in-vendor. It can be moguls like Salesforce or SAP with various customizations and integrations or a set of specialized SaaS vendors.</p> <p>If a legacy was a vendor, it will most likely be replaced with another vendor. In the case of a relatively small and non-complex solution with enough business domain and technical expertise, it can be substituted with an internally built service.</p> <p>There are still open questions about choosing, integrating, and onboarding an org with a SaaS vendor, plus business risk with a vendor lock-in. So, it is all about trade-offs, and, in fact, SaaS vendors might not be much cheaper or even successful.</p> <p>With several vendors, integrating and operating several SaaS services as a unified system is challenging. Even if you succeed with the initial implementation, there might be a question further about how to replace a SaaS vendor. There might be various reasons behind such a move, such as increased costs, imposed new regulations, not following SLA (Service Level Agreement), or a failed reputation.</p> <p>Thus, we face a new type of Legacy: not an old monolith but a cloud-native microservice-oriented SaaS. That requires a different approach, so the Composable approach (aka Composable Commerce) composes different vendors into reusable modules. But even that requires heavy effort in designing, integrating, and operating such a system. We will definitely return to that topic in the future.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-5/#deus-ex-machina","title":"Deus Ex MachInA","text":"<p>Considering the complexity of the replacement/modernization activities, the industry would have developed tools to help with a monolith decomposition. That is not an easy stack considering the outdated stack, lack of knowledge, and accessibility of non-public enterprise code. And this is where AI can flourish.</p> <p>And IBM seems to be a leader in leveraging AI to modernize legacy systems. Unsurprisingly, IBM suits that role as, to this day, they serve as mainframes to run legacy software for their customers. And that seems to be a considerable part of their business nowadays.</p> <p>How AI can help:</p> <ul> <li>refactor the code</li> <li>generate legacy code documentation</li> <li>summarizing the code, how the system works</li> <li>generate a new code</li> <li>translate legacy code to another programming language</li> </ul> <p>IBM\u2019s open-source project, \u201cMinerva,\u201d is to refactor legacy code to move from monolithic toward MSA. It is based on the CARGO algorithm (Context-sensitive lAbel pRopaGatiOn) that allows analysis of how pieces of code are connected and provides some resolution for further refactoring to split code into microservices.</p> <p>So, it does not do the composition for you, but it helps an understanding with some suggestions on how to proceed. It is now limited to Java, but it might expand to other languages in the future.</p> <p>Alternatively, IBM conducts COBOL-to-Java translation with their code assistant. Considering that COBOL is still widely used in critical infrastructure and most of them, I assume, are IBM clients. So it is a win-win and tons of money for IBM as it is not open source.</p> <p>Just look at that beautiful demo:</p> <p>AI tackles only the code, which is something specific and reflects the current functionality. Modernization should enable further paths to embracing new opportunities for the software. So here we are again at the crossroads, deciding what should go into the new system.</p>"},{"location":"essays/replacing-legacy/replacing-legacy-5/#final-words","title":"Final Words","text":"<p>So, to conclude that Series, what is the next?</p> <p>For sure, we will not replace all Legacy software. In a moment, our recently developed software will become the new Legacy. With the current pace of progress, this is a never-ending process until it becomes non-economically feasible. However, it is unlikely with growing AI capabilities, which will mature more and more. There is still a long way to self-improving software. But AI will definitely play a key role in modernizing Legacy.</p> <p>The concern is that enterprise legacy code is closed, so such vendors as IBM, with their extensive book of business, can leverage that more than anyone. However, other AI tools like MS Copilot will compete with them. Plus, new players might appear.</p> <p>As we complete migrating on-premise monoliths, we go the next circle and start migrating organizations from Legacy SaaS solutions. That is debatable how it will be. But I think that MACH architecture and a Composable approach are driven by the ability to painlessly replace SaaS vendors with the new, what they call \u201cbest-of-breed\u201d solutions.</p> <p>So, this will be my next focus to research.</p>"},{"location":"essays/requirements-api/","title":"Requirements & API","text":""},{"location":"essays/requirements-api/#requirements-api","title":"Requirements &amp; API","text":""},{"location":"essays/requirements-api/#foreword","title":"Foreword","text":"<p>In recent years, I wrote several materials about API design and last year (2023) did a local workshops and online webinars titled \"Requirements &amp; API\" targeted for Business Analysts and Product Owners who want to learn aobut APIs. Since then, I have had an idea to expand and restructure the content by making it more accessible. Original blog posts lacked some storytelling consistency, and workshops/webinars were for the Russian-speaking audience. So now I am doing the final step to revise that material and extend it further continuously.</p> <p>We start from scratch, uncovering what API means, what place it takes in the world of software requirements, and what components are critical to addressing. Then, we proceed to more advanced topics I want to uncover: Interface Definition Languages and API tooling.</p> <p>Below is a plan with all the topics I plan to cover (some even for a 3rd time). Stay tuned for the updates!</p>"},{"location":"essays/requirements-api/#chapters","title":"Chapters","text":"<ul> <li>Glossary</li> <li>Definitions</li> <li>Analysis</li> <li>Structure</li> <li>Interface Definition Language (IDL)<ul> <li>IDL: OpenAPI</li> <li>IDL: JSight</li> <li>IDL: Typespec</li> </ul> </li> <li>API Sequence Definition<ul> <li>API Sequence: OpenAPI Workflows</li> </ul> </li> </ul> <p>Start</p>"},{"location":"essays/requirements-api/1-glossary/","title":"Glossary","text":"Term Definition API Application Programming Interfaces --&gt; see the section \"What is API\"? API call A process of sending a request to an API endpoint and getting a response API endpoint / operation A single instance of API with a unique address (URL). Sending a required input to that URL triggers some command within your system and returns an output about a successful result or failure CLI Command-line interface Client A general term to identify someone or something calling your API HTTP HyperText Transfer Protocol IDL Interface Definition Language MSA Microservice Architecture OAI OpenAPI Initiative REST REpresentational State Transfer RPC Remote Procedural Call SaaS Software-as-a-Service SOAP Simple Object Access Protocol <p>Next</p>"},{"location":"essays/requirements-api/2-definitions/","title":"Definitions","text":""},{"location":"essays/requirements-api/2-definitions/#requirements-api-definitions","title":"Requirements &amp; API: Definitions","text":""},{"location":"essays/requirements-api/2-definitions/#what-is-api","title":"What is API?","text":"<p>API stands for the \"Application Programmable Interface,\" and this definition is self-explanatory and unclear at the same time. It is a vast term, and different people with different roles have different understandings of what it is.</p> <p>Let's go old-fashioned and ask Wikipedia: </p> <p>\"An application programming interface (API) is a way for two or more computer programs to communicate with each other. It is a type of software interface, offering a service to other pieces of software.\"</p> <p>That gives more clarity but might sound ambiguous. I would focus your attention on \"offering service\" as that is crucial in our further conversation.</p> <p>There is another excellent definition from the \"The API Book\" by Sergey Konstantinov:</p> <p>An API is an obligation. A formal obligation to connect different programmable contexts.</p> <p>The author draws an analogy with a Roman Aqueduct dated to the 1st century AD as it:</p> <ul> <li>interconnects two areas </li> <li>flows water (analogy to data)</li> <li>keeps backward compatibility for almost 2000 years</li> <li>provided an additional infrastructure to support water supply from both ends.</li> </ul> <p> Image by Ridoe from Pixabay</p> <p>I suggest thinking about API as a distribution channel. It is like a User Interface (UI): not directly for end-users, but for developers to build their solutions on top of API for their end-users.</p>"},{"location":"essays/requirements-api/2-definitions/#api-lifecycle-and-actors","title":"API Lifecycle and Actors","text":"<p>As with everything in that universe, API has its lifecycle and different people allocated to its various phases. We distinguish a Producer who develops API and is responsible for its further support and a Consumer who utilizes that API for their purposes. However, that is not a one-sided charity. Producers receive something in return, whether it is money or data.</p> <p>Under Producers and Consumers, we don't mean only developers, as many other roles are involved: Business Analysts, Software Architects, Quality Assurance Engineers, Product Owners, Delivery Managers, etc.</p> <p>The lifecycle differs whether you are on the Producer's or Consumer's side. For the Producer, there are the following stages:</p> <ul> <li>Definition: defining what API should do</li> <li>Design: answering on how API should do, designing its component</li> <li>Delivery: developing and publishing API into the outer world</li> <li>Operation: running and supporting API</li> <li>Deprecation: announcing plans to finish support, preparing migration strategy, removing API</li> </ul> <p>The Consumer's lifecycle starts a bit later than the Producer's:</p> <ul> <li>Discovery: identify API that provides value for your business</li> <li>Integration: enable API into your service</li> <li>Delivery: utilize API for your purpose</li> <li>Migration/Deprecation: migrating to a new API or another Producer; closing the feature/services that utilized API</li> </ul> <p>The beauty of API is that Discovery and Integration do not require an API to be up and running somewhere in the Cloud. In particular cases, the Consumer may ask to share an API contract and/or provide a mock API so they could integrate beforehand. Consumers will not get a working API until the Producer Delivery happens, but they can do their part of the work and not be blocked from proceeding. We discuss that topic in the following chapters.</p> <p>The integration is an important part: it is not free as Consumers apply some effort to integrate with API and embed it into their solution. Producers can alter APIs that might hurt Consumers unexpectedly. That is where the concept of Backward Compatibility applies as a temporary (nothing lasts forever) obligation that the Producer will take care of the smooth operation. We will discuss that concept further as well.</p> <p>There is another Actor that is usually hidden from the public eye: the API Platform. Producers need proper tooling to expose and manage their APIs. The task might be easy if we talk about a dozen API operations. But there can be hundreds if not thousands of operations of different types, formats, protocols, etc. Keeping quality standards and consistency across the APIs, providing means to quicken the development, and ensuring required management policies are the challenges to be handled by the API Platform. We cover that topic separately.</p>"},{"location":"essays/requirements-api/2-definitions/#the-value-chain","title":"The Value Chain","text":"<p>From the API Platform perspective, you are too far away from end-users who get some value from indirectly using your API. Your immediate users are the producers who build APIs using your platform. They have specific needs: quick-time-to-market, reliability, monitoring, support of different protocols, etc. But basically, they need to be able to design &amp; deploy quickly and straightforwardly.</p> <p>However, the platform's role is to imply specific rules and limitations. It is not responsible for the outcome. Is it on the API developer's shoulders? However, it could provide some quality gateway and not allow API to be published until it meets the required criteria.</p> <p>Taking into account all those policy and technical limitations, API developers are building APIs. And it is essential to mention that API does not equal a feature or a piece of system functionality. API is a way to access and utilize it programmatically. There can be multiple ways to access one particular piece, but they are designed for different scenarios. Yes, again, that is a distribution channel.</p> <p>So API developers need to extract a piece value from the system and, with API Platform, make it available. </p> <p>On the Consumer side, a so-called Business Owner decides whether an API under consideration will satisfy business needs. In another case, a Business Owner requests an API from Producers. That business owner might be anyone, a product owner, another team member, or some stakeholder from your business clients. There might be different approaches in handling internal and external owners, but the idea is the same: they will only pick and utilize an API if it does some job for them.</p> <p>The integration happens, and the value, in a significantly transformed way compared to the beginning, finally passes to end-users. However, if we consider B2B2B, the value chain might be longer. So, the API platform and developer folks from the producer side are distant from end-users. Should they even care about them? They should.</p>"},{"location":"essays/requirements-api/2-definitions/#api-categorization","title":"API Categorization","text":"<p>Multiple categories can be applied there:</p> <ul> <li>by accessibility:<ul> <li>public</li> <li>partner</li> <li>internal</li> </ul> </li> <li>by complexity:<ul> <li>basic (CRUD operations)</li> <li>composite (converging several Models)</li> </ul> </li> <li>by interaction:<ul> <li>synchronous (client waiting for response)</li> <li>asynchronous (client doesn't wait; it will get a response later, if any)</li> </ul> </li> <li>by monetization:<ul> <li>paid</li> <li>free</li> </ul> </li> </ul> <p>But the most controversial is the technical one. Let's consider REST (REpresentational State Transfer), SOAP (Simple Object Access Protocol), RPC (Remote Procedural Call), and GraphQL. Besides they are all API-related, there are also different levels of abstraction:</p> <ul> <li>REST is an architectural style</li> <li>SOAP is a messaging protocol specification</li> <li>RPC is a request-response protocol</li> <li>GraphQL is a query language (that is what QL stands for).</li> </ul> <p>REST is the most problematic topic because, as an architectural style, it has a lot of representations. I like an analogy with classicism as an architectural style in construction. As a mere mortal, you can know some common traits of that style. But you are unlikely to distinguish it from neo-classicism.</p> <p>REST architecture styles principles:</p> <ul> <li>The client and the server do not know how each of them is implemented  </li> <li>Sessions are stored on the client (the \"stateless\" constraint) </li> <li>Data must be marked as cacheable or non-cacheable </li> <li>Interaction interfaces between system components must be uniform </li> <li>Network-based systems are layered, meaning every server may just be a proxy to another server </li> <li>The functionality of the client might be enhanced by the server providing code on demand.</li> </ul> <p>And that's it. Not much, right? I suggest reading other sources if you want to dive into the topic. General terms described in the REST principles can be interpreted and implemented in many ways. Term REST API has caused holy wars in the tech community for 20 years. So, there is a notion of RESTful API that loosely follows some REST principles.</p> <p>Instead, let's focus on HTTP (HyperText Transfer Protocol) because it is the foundation of modern API. REST author Roy Fielding is also a co-author of HTTP. So they are literally tight together. Also, GraphQL is served over HTTP, HTTP is the default protocol for SOAP, and RPC uses HTTP as the underlying protocol.</p> <p>So, we start with what is called HTTP API and keep exploring that concept in the following chapters.</p> <p>Next</p>"},{"location":"essays/requirements-api/3-analysis/","title":"Analysis","text":""},{"location":"essays/requirements-api/3-analysis/#requirements-api-analysis","title":"Requirements &amp; API: Analysis","text":"<p>With this chapter, we first will understand why we need requirements for API and their place in the requirements classification frameworks. Then, we review the requirements engineering process and specific aspects you need to consider.</p>"},{"location":"essays/requirements-api/3-analysis/#why-do-we-need-requirements-for-api","title":"Why do we need requirements for API?","text":"<p>Let's answer why business analysts have suddenly started working on API requirements. About a decade ago, when I began my career in IT as a business analyst, it was not a part of my general BA responsibilities. Now, you can see more job descriptions for BAs, POs, and PMs requiring API knowledge. And I have a subjective explanation of why that happened.</p> <p>The leading software architecture approach back then was an on-premise deployed monolithic application. Simply, that was a tied backend service that communicated with a desktop or web UI client. That backend was integrated with several internal or external services in different ways, such as file upload via FTP. </p> <p>A Business analyst focused on business capabilities and their representation on the UI side, plus requirements for integrations such as mappings and request logic. The detailed interaction across the backend, UI client, and integrated system was the responsibility of tech folks. </p> <p>But things started moving when Cloud, SaaS, and Microservices architecture (MSA) became a dominant trend for system design:</p> <p></p> <p>Because of those trends, systems become more interconnected than ever before. Some services become API-first, meaning you can only use them through their APIs. So, API becomes a business model with higher-level requirements. With that, you get stakeholders, regulations, restrictions, etc. The stuff a business analyst, product owner, and product manager takes care of.</p> <p>The number of API clients has increased exponentially, including those on the web, mobile applications, IoT, etc. Additionally, microservices communicate with each other within a system through APIs. Thus, there are many external and internal clients, vertically and horizontally, each with its stakeholders and specific needs.</p> <p>Another crucial aspect is that APIs are more vulnerable to attacks as they provide a direct way to break into a system. So, we are not just designing and implementing API but also ensuring their security.</p> <p>To summarize, the \"businessfication\" of API due to the rise of Cloud, MSA, and SaaS, increased number of clients, high-security risks, and, last but not least, imposed industry and government regulations have made API also a zone of interest for all kinds of business folks.</p> <p>That is not a comprehensive explanation of that shift, but that is how I see it from my perspective. I would like to see your thoughts in the comments.</p>"},{"location":"essays/requirements-api/3-analysis/#requirements-classification","title":"Requirements classification","text":"<p>Before diving into BA theory, let's clarify that API requirements are not functional. UI is the closest analogy. There is a system capability (function) and several ways for users to access it. In the previous chapter, we identified API as a distribution channel. And that is the same for any public interface: UI, Command-line interface (CLI), Chatbots, etc.</p> <p>You can express a functional requirement through API design. However, API itself is not a direct concern of system capabilities. Going back to the UI analogy: the design patterns, components you choose to use, or color scheme are crucial for UX, but we don't call them functional requirements.</p> <p>For example: \"System shall return a list of X items filtered by Y and sorted by Z\" that is a functional requirement. However, how you return this list to UI and API might differ. If a single front-end utilizes that API endpoint, it is enough to describe how from a UI perspective. This single client acts as the primary stakeholder here. But if several clients want to get the list for their purpose, we need to spend additional time communicating with them and aligning on expectations of what they need to get and why. The outcome might differ significantly from how you return those list items for UI.</p> <p>Ok, API requirements are not functional, so what type of requirements do they belong to? Let's review several sources.</p> <p>In the recent \"Software Requirements Essentials\" by K. Wiegers and C. Hokanson define \"External interface requirement\":</p> <p>A description of a connection between the solution being built and other elements of the world around it, including users, other software systems, hardware devices, and networks.</p> <p>The classic \"Software Requirements,\" 3rd edition by K. Wiegers and J. Beatty, highlights the interconnection between non-functional requirements and interfaces.</p> <p>\"Other classes of non-functional requirements describe external interfaces between the system and the outside world. These include connections to other software systems, hardware components, and users, as well as communication interfaces.\"</p> <p>According to the standard ISO/IEC/IEEE 29148:2018 \"Systems and software engineering \u2014 Life cycle processes \u2014 Requirements engineering,\" there is such a requirement type as Interface requirements (5.2.8.3):</p> <p>Interface requirements are the definition of how the system is required to interact with external systems (external interface), or how system elements within the system, including human elements, interact with each other (internal interface). External interface requirements state characteristics required of the system, software or service at a point or region of connection of the system, software or service to the world outside of the item. They include, as applicable, characteristics such as location, geometry and what the interface is to be able to pass in each direction.</p> <p>Interface requirements are not non-functional because interfaces have its own quality attributes: security, compatibility, usability, compliance, etc. An interface is not just a quality attribute of a specific capability. However, a lousy interface will definitely worsen user experience, whether we are talking about UI or API.</p> <p>Also, selected technology and design patterns imply constraints on interfaces. So, software architecture also impacts the analysis process, especially for API. For example, whether API should be synchronous or asynchronous (event-driven) depends on the architecture and utilized protocol.</p> <p>Under interface requirements (where we also include UI and CLI), it also makes sense to separate integration requirements when a system acts as a Consumer and API requirements when it is a Producer (see previous part about Producers &amp; Consumers). Those subtypes share a lot in common, but the outcome differs. The latter's outcome means operational API endpoints. Meanwhile, working interaction between systems is the first outcome.</p>"},{"location":"essays/requirements-api/3-analysis/#requirements-engineering","title":"Requirements engineering","text":"<p>BABOK v3 (IIBA, 2015) does not classify API or integration requirements. However, it describes the interface analysis technique (10.24), which talks about API and interfaces in general. The analysis consists of 3 stages such as:</p> <ul> <li>Preparing to identify and understand what interfaces are needed by studying actors' interactions.</li> <li>Conducting identification by describing a function of each future interface, evaluating the type of an interface and its initial design.</li> <li>Defining interface with inputs, outputs, validations, etc.</li> </ul> <p>The requirements development is not so different from the \"traditional\" business analysis process: elicitation, analysis, specification, and validation. Right now, we are focusing more on the first steps. Specification and further validation have some peculiarities, but we need to dive into HTTP protocol basics and API structure to discuss them. That will come in later chapters.</p>"},{"location":"essays/requirements-api/3-analysis/#starting-point","title":"Starting point","text":"<p>There we have a bunch of questions to consider:</p> <ul> <li>Why do we need this?<ul> <li>E.g., We want to make an access point for 3rd parties to get data our system produces not from UI but a paid public API. In short, add a new distribution channel and monetize it.</li> </ul> </li> <li>For whom are we doing this?<ul> <li>For example, medical data brokers will use our data to build their market prediction models.</li> </ul> </li> <li>What will it do?<ul> <li>E.g., Return set purchase records for the provided period.</li> </ul> </li> <li>How will they do it?<ul> <li>For example, authorize with a token and provide a line-of-business ID with period start and end dates.</li> </ul> </li> </ul>"},{"location":"essays/requirements-api/3-analysis/#prerequisites","title":"Prerequisites","text":"<p>The next step is to define prerequisites of an API call - authentication and authorization:</p> <ul> <li>Authentication is about verifying clients and allowing them to communicate with your API.</li> <li>Authorization is about permissions to enable specific clients to make particular API requests and see certain data.</li> <li>Another critical point is whether a Consumer possesses all the necessary input data to make a call.</li> <li>You need to understand whether you need a new permission associated with a new API endpoint or re-use existing ones.</li> </ul>"},{"location":"essays/requirements-api/3-analysis/#functional-gap","title":"Functional gap","text":"<p>Another important question is whether a system already provides such capability. And if so, does it require any improvement?</p> <p>If there is a gap between current system capabilities and the desired interface, it is a matter of solution requirements. So, the traditional BA practices should be used there.</p> <p>For example, if there are search criteria for a new API endpoint, we need to make sure they are included in the search index. And that is already a backend-related matter.</p> <p>If you want to describe a solution through the interface, that will not be enough to cover all the aspects. A bare minimum is to have a data model as a data dictionary or entity relationship diagram with good-old use cases describing where new APIs will be used.</p> <p>The task is to identify and describe use cases where one or several API endpoints will be utilized. Nowadays, APIs are very granular, which is why a single API without context doesn't make much sense. So, a scenario where specific actions with several Entities are involved will consist of more than one API call. </p>"},{"location":"essays/requirements-api/3-analysis/#contract-black-box","title":"Contract &amp; Black box","text":"<p>If we take a simplistic look at API, it will look like</p> <p></p> <p>The outcome of the analysis is a described input/request structure and outcome/response. That represents a black box, which we also call an API contract.</p> <ul> <li>An API contract is an agreement about expected input and outcome between you and the Clients. </li> <li>The Contract is strictly formalized, and clients agree to follow it when they start using your API. </li> <li>The API Producer takes responsibility for maintaining the consistency of the Contract.</li> <li>There can be legal punishment for breaking API contracts</li> <li>API contract can be defined before the implementation so both sides can work in parallel.</li> </ul> <p>And two important things there:</p> <ol> <li> <p>The request/response model, called the API model, does not equal a Data Model in a database. API is an abstraction built upon a database to secure interaction with the outside world. Models might differ in naming, set of exposed attributes, and even in some data types.</p> </li> <li> <p>New API must be consistent with existing system APIs. If something is called in a particular way, you should follow that. It would help to avoid possible confusion and increased cognitive load for your Consumers</p> </li> </ol> <p>API Models can be described in:</p> <ul> <li>formal ways:<ul> <li>data formats like XML and JSON</li> <li>in specification forma like OpenAPI. OpenAPI is the most common formal API specification format for HTTP</li> </ul> </li> <li>informal ways, like an Excel spreadsheet or any textual format. Informal formats usually tend to mimic OpenAPI but in a more human-friendly manner</li> </ul> <p>Request logic handles what happens inside the black box (glass box). It can also be described as:</p> <ul> <li>informally (text description with several steps)</li> <li>visually: UML activity or sequence diagram etc</li> <li>specification like formats</li> </ul> <p>Request logic can be a simple CRUD command for an Entity object. It also can be a sophisticated aggregated request with a few internal APIs involved. We cover that in later chapters.</p>"},{"location":"essays/requirements-api/3-analysis/#dont-be-so-agile","title":"Don't be so agile","text":"<p>While working with UI, it is easier to introduce changes than with API. There is a risk of breaking the user experience, but that is generally about the cognitive effort of the user to adapt to something new. They are not paying money for your changes.</p> <p>On the other side, Consumers are paying the price for adapting to breaking changes of the utilized API or migrating to the new ones. They need additional integration and maintenance effort, from changing client code to updating autotests, documentation, etc.</p> <p>Thus, all that \"iterative-flexible\" is not very much about API. They evolve during their lifecycle, for sure. However, breaking API contracts frequently is not a good way of achieving sustainability. There are ways to mitigate that, but it definitely should be in the mind of every API Producer.</p> <p>From the requirements engineering perspective, analysis should be done more thoroughly, especially if it is a paid public API that is to be used by multiple consumers.</p>"},{"location":"essays/requirements-api/3-analysis/#reading-on-the-topic","title":"Reading on the topic","text":"<ul> <li>Definition of API Requirements</li> <li>Non-functional Requirements and API</li> <li>Breaking changes &amp; Backward compatibility</li> <li>Summary of the \"Requirements &amp; API\" webinars for IIBA Belarus</li> </ul> <p>Next Chapter: Structure (WIP)</p>"},{"location":"definition-of-api-requirements/","title":"Definition of API requirements","text":"<p>There is a 2nd revision of this article, so please read it instead. This, as my first published post in this blog, will stay here as a reminder of my bad writing.</p> <p>At some point in my career, I faced a need to specify requirements for API. Those were not typical solution requirements I worked on before. I learned about the API layer which is very common among the enterprise systems. It can hide a set of microservices or a legacy system from the outer world. Like any other system, it is also impacted by stakeholders' needs. And those needs have to be translated into requirements.</p> <p>We are going to decompose the definition of API requirements and see what lies within. I will pay your attention to what should be taken into consideration for the API layer. It is an introduction to this topic as there are other sides of it to explore further.</p> <p>We are not going to talk about implementation types of API such as REST, RPC, GraphQL, etc. Ideally, requirements should not be tied to the technical implementation and that rule works here as well.</p> <p>I have been working more with REST and REST-like APIs. Like most of you, I believe. However, I think my experience can be applied to other types as well. Considering some specifics, of course. But those are not covered here.</p>"},{"location":"definition-of-api-requirements/#why-you-dont-need-api-requirements","title":"Why You Don't Need API Requirements","text":"<p>Before we start you need to ask yourself:</p> <p>Do I need to write and maintain requirements for API?</p> <p>As a System or Business analyst, you don't need to proceed with them if the API is used only within your service. In that case, it is a part of the provided functionality.</p> <p>You can define a user story describing acceptance criteria with a bunch of functional, quality (non-functional) requirements, and attach UI wireframes. That is all about expected outcomes to be reflected on a UI and/or in data. API is something in-between that you don't need to care about. It is a part of technical design managed by the engineering team with the main purpose to address the requirements.</p> <p>But if your API is publicly exposed you need to consider interests of other parties. Those parties can be split into two big categories:</p> <ul> <li>Other teams within your organization.</li> <li>Customers and partners outside your organization.</li> </ul> <p>Despite obvious differences between them, they both need your service to reach their own business goals. Each party has its context under which your service is used and a particular integration approach. Thus you need to consider them as stakeholders and address their concerns to provide great customer experience.</p> <p>It is important to separate the functional requirements from API ones. API requirements are not about introducing new or improving current functionality. That is about providing the right way to use that functionality. So we identify the back-end as a functional piece and API as a gateway to access that functionality provided by the aforesaid.</p>"},{"location":"definition-of-api-requirements/#terms-definitions","title":"Terms &amp; Definitions","text":"<p>One more step before we go forward. Let us clarify some concepts and align on the terms used below.</p> <p>API is translated as \"Application Programmable Interface\" but that does not give you a key without a Computer Science degree. For my \"Bachelor of Arts\" fellows, the main word here is an \"Interface\". Generally, your mouth and tongue are an interface for speech communication. Your fingers are an interface to type text on your keyboard for written communication. The same is applied to the software in which classes and instances communicate with each other in some strictly formalized way.</p> <p>API is a very broad term. Here we talk about the gateway through which your service communicates with the outside world.</p> <p>API endpoint is a single instance of API with a unique address (URL). Sending a required input to that URL triggers some command within your system and returns an output about a successful result or failure.</p> <p>Example: <code>POST https://ecomplatform/api/v1/purchases/{purchaseId}/cancel</code></p> <p>API call is a process of sending a request to an API endpoint and getting a response.</p> <p>Client is a general term to identify someone or something that is using your API.</p>"},{"location":"definition-of-api-requirements/#api-definition","title":"API Definition","text":""},{"location":"definition-of-api-requirements/#what-why","title":"What &amp; Why","text":"<p>To provide the right API endpoint your need to understand:</p> <ul> <li>What is that API doing?</li> <li>Why is it required?</li> </ul> <p>The first question seems to be an easy one. Usually, there are data objects of some Entity that we can access and conduct some action with them. The basic actions are Create, Read, Update, Delete (CRUD) operations. Even some specific actions are just about changing some information in a data object.</p> <p>For example, our API endpoint should cancel a purchase in a store. A \"Purchase\" is an object and \"cancel\" is a required action. It is a single purchase so we need: a) make sure how we identify a right Purchase to cancel; b) how we proceed with the cancellation.</p> <p>Cancellation can mean an actual deletion (bad idea) or an update (good idea) of a Purchase data object. Changing a state of an object might trigger a chain of information updates elsewhere in the system. You should be aware about the business logic. Either it is triggered automatically or you need to make additional API calls to complete that action.</p> <p>The second question is more complex. An API call is a non-visible participant of the interaction between a user and the system (i.e. Use Case). One call can participate in several use cases with each having its context. You might cover each context with a separate API endpoint or craft the one to rule them all. That is a question of implementation. The main thing here is that you need to understand those contexts.</p> <p>Again, it is easier to own the context when it is all about systems within your organization. But when API goes outside and customer success is relying on that, it is difficult to consider all possible contexts which may appear.</p> <p>You lack control over how APIs are used. You can define the rules, provide some documentation, and hope that will work. Just be prepared that problems occur where no one expects them to be.</p>"},{"location":"definition-of-api-requirements/#prerequisites","title":"Prerequisites","text":"<p>Now we know why we build our API endpoint and what it does. Next step to define what conditions need to be satisfied to make that call. In most cases we talk here about authentication and authorization:</p> <ul> <li>Authentication is about verifying a client and giving them the possibility to communicate with your service.</li> <li>Authorization is about permission to allow certain clients to make particular API requests.</li> </ul> <p>Authentication is usually managed on a higher level considering an API layer itself. The specific API endpoint is likely to follow that approach. But if there is an exception from that rule, such requirements need to be considered.</p> <p>Permissions are usually managed on the back-end side. But some constraints may be imposed on the API layer as well. You can proceed with different API endpoints which are doing the same thing but for different roles, considering business restrictions.</p> <p>For example: canceling a Purchase by a Customer and canceling a Purchase by an Admin. Same action but with two different contexts. Let us assume that an Admin can skip some validation steps in business logic to cancel a Customer's Purchase in a simplified way. When designing an API endpoint you need to make sure that dangerous power will be used only by Admins. There are a dozen ways of handling this but that requirement should not be missed.</p>"},{"location":"definition-of-api-requirements/#api-call","title":"API Call","text":"<p>Now we are ready to design our API endpoint. Its definition consists of two things:</p> <ul> <li>API Contract for Request and Response</li> <li>Request logic</li> </ul>"},{"location":"definition-of-api-requirements/#api-request-contract","title":"API Request Contract","text":"<p>API contract is an agreement about expected input and outcome between you and your clients. Communication via API is strictly formalized and clients accept to follow the provided format. They accept it by default when starting using your API. The API owner takes responsibility to follow the contract obligations by maintaining the operability of the service and consistency of the contract itself.</p> <p>For input, you expect clients to provide required and optional parameters. Required parameters usually identify objects or a set of homogeneous objects to access or modify them. The optional is used to modify expected responses and provide additional information.</p> <p>Generally, input parameters can be provided in a few ways:</p> <ul> <li>Manual user input When a User submits manually-typed information on the client-side passing directly to API.</li> <li>Context-provided input When the request is taken or combined from responses of preceding API calls made in that particular Use Case.</li> </ul> <p>From a technical perspective, there is no difference in how request parameters are provided. But that should be considered during the analysis.</p> <p>For example, you need to request a single Purchase. First, you find out what ID should be used to load a Purchase object. In \u201cbloody\u201d enterprise systems, there are always several identifiers for the same objects in different contexts. Let us assume a Purchase entity has Business ID as something human-readable and System ID as a hashcode.</p> <p>Our API endpoint asks for System ID to get Purchase details. That is OK, but what if clients expect their customers to manually enter a Purchase ID for some verification on that step of a Use Case?</p> <p>I would expect you to ask a question \"How did a Customer get that ID before?\" Let it be available on a bill and now a Customer wants to see Purchase details without being authenticated in the app. And providing System ID on that is not an option. Only if the customer suffering is a part of UX design.</p> <p>We can quickly consider a workaround by making a Purchase search request with Business ID, then extract a System ID from a found Purchase and make a call for Purchase details. Fine if you can use search for that purpose. But your clients need to make two API calls instead of one.</p> <p>Again, there are dozens of ways to handle such cases. This is just an illustration of how simple things might become surprisingly complex.</p>"},{"location":"definition-of-api-requirements/#request-logic","title":"Request Logic","text":"<p>When clients send a request to API then something should happen. Either we get a successful response or an error, some work is done beneath. We can consider:</p> <ul> <li>\"Simple\" request Making one call to the back-end with basic CRUD operation to a data object of a single Entity.</li> <li>\"Composite\" request Making a chain of calls to one or several back-end services with a few Entities involved. That means you are hiding that complexity from the clients. Otherwise, they would be forced to do all those operations and transformations by themselves with a high risk of doing something wrong.</li> </ul> <p>You need to define a sequence of steps on how that chain will work. It is important to consider accessibility, especially if third-parties services are involved. And what kind of request is passed for each call and how each response should be processed.</p> <p>Don't forget about non-functional stuff: maintaining overall performance and sustainability. More steps we have in a sequence - the higher probability of a failure. You need to consider different \"bad\" scenarios: long response time, bad data, downtime, etc. Even if such \"edge\" cases seem to be unreal you should consider them. Even you can't cover them all due to time and financial restrictions.</p> <p>Whether you call other services within your organization or a third-party, now you are in the client\u2019s shoes. You agree with the contract hoping both parties are going to follow their commitment. If you can somehow impact other services inside your organization by forcing them to follow or change the contract, for third-parties and vendors that can be problematic. Only if you have the leverage to make them but that is not always the case in real life. Anyway, all that should be considered when you are defining a composite API call.</p>"},{"location":"definition-of-api-requirements/#api-response-contract","title":"API Response Contract","text":"<p>For a successful call, an API endpoint returns a response with some amount of information. That can be all information about a data object or just a message that information about that object has been updated. It is a matter of request type and endpoint design.</p> <p>You need to consider that the data model stored in your database is not the same as the data model provided to the clients via API. B First, there can be some differences in data types used. Secondly, there is no need to expose all attributes you have in the data model via API. There is always some information you don't want to share with some types of users.</p> <p>Providing expected outcomes is a part of the Contract. So the information should correspond to clients' goals and expected format. Sometimes you need to transform the data originally provided by the back-end. That can be localization to a different language, another date format, currency conversion, combining data objects of different entities, adapting data from third-party providers, etc. Data mapping is the right requirement artifact to keep that important information.</p>"},{"location":"definition-of-api-requirements/#epilogue","title":"Epilogue","text":"<p>That is just a basic overview of what is beneath the API layer. We are not touching specific implementation and possible format of API specification and documentation. Hopefully, we will investigate those topics in the future.</p>"},{"location":"api-design-first/","title":"API Design-First","text":"","tags":["API Design"]},{"location":"api-design-first/#api-design-first","title":"API Design-First","text":"<p>This article is a part of the API Design series, where I will uncover API design concepts for my non-technical peers. You don't need to be a developer or an architect to participate to design or even build an API, but there is something you should learn to succeed.</p> <p>So we start with API design-first, which takes the opportunity to democratize the API development process.</p>","tags":["API Design"]},{"location":"api-design-first/#api-definition","title":"API Definition","text":"<p>Let's take a step back to explore the term \"API definition.\" I will take some points from my \"Definition of API requirements\" essay to keep all the needed information in one text.</p> <p>So, the API definition is a documented API contract - an agreement about expected input and outcome between you (API provider) and your clients who consume your API. API communication is formalized with the contract documented in a specific format. It covers what data should be sent to a particular web address and what is expected to return as a successful or failed response.</p> <p>Many types of such formats are usually technically-driven. OpenAPI (previously known as Swagger) is the most common way to specify RESTful API, so that I will refer to it. You should study that format if you need to work with APIs. OpenAPI is not covered here, but later I will guide you on how to approach that study.</p> <p>So in our case, a JSON or YAML file with the contents aligned with OpenAPI specification acts as the API definition. The definition does not mean implementation. Our API can be defined on \"paper\" but does not yet exist as a deployed code running on a web server. It is important to separate those meanings like we separate requirements as a description of a system from the actual implementation.</p>","tags":["API Design"]},{"location":"api-design-first/#what-api-design-first-means","title":"What API design-first means","text":"<p>API definition has two dimensions:</p> <p>Documentation: You can have API implementation with code and then autogenerate API definition to reflect the actual implementation. It is also called \"code-first\" and is a more traditional approach.</p> <p>Specification: You can design API definitions with your hands in a Notepad or use advanced tools to produce such machine-readable formats as OpenAPI. That allows autogenerating code for both the client and server sides. Or you can still develop it manually. Both ways lies in the concept we call \"API design-first.\"</p> <p>API definition can mediate between business logic, domain models, and UI. It can't cover them all, but there is no need for that. That can be considered a business analysis (BA) artifact, which may better transcribe business-to-system requirements than several written text lines.</p> <p></p> <p>Designing API definition helps to crystalize the data model and the operations to make your application functional. It is a ready-made contract between the backend and UI or API consumers. Such traditional BA artifacts as use cases, Entity-Relationship diagrams, and UI mockups are still required to specify the system requirements.</p> <p>I am usually advocating to keep a separate line between Requirements and Design. API definition lies between \"What?\" and \"How?\". It does not answer those questions for an entire system. But that might be beneficial if API is crucial in delivering value to your customers.</p>","tags":["API Design"]},{"location":"api-design-first/#rise-of-api-design-first","title":"Rise of API design-first","text":"<p>I think it is related to the rising popularity of the \"API economy.\" It is climbing to the \"hype\" train. I googled \"Forbes about API,\" and on the first page, I found six(!) Forbes articles about APIs published in 2022 (1,\u00a02,\u00a03,\u00a04,\u00a05,\u00a06). Forbes as a media and API are very distant from each other worlds. It proves the increasing interest in everything related to APIs.</p> <p>Thus, API design-first is also a part of this trend. Now we talk more about APIs and try to revisit some traditional approaches. There is a new market of tools to replace regular API development or integration with more user and business-friendly solutions.</p>","tags":["API Design"]},{"location":"api-design-first/#when-you-dont-need-this","title":"When you don't need this","text":"<p>To fully understand the concept, you need to focus on its disadvantages more than its advantages. There is a bulletproof fact: despite trends, the industry has been developing software without API design-first for dozens of years and will continue doing that.</p> <p>The API design-first approach can be an overhead in a case when:</p> <p>1) There are internal APIs only / no time for that</p> <p>I can hardly imagine a viable system without an API exposed to 3rd parties. But if we consider this case, API design-first is hard to sell here. If API is only used by the UI application, why do you need to spend time designing API with stakeholders before coding? Especially when we are talking about small or medium-sized applications.</p> <p>Also, you need more time to design API. For sure, it is an overhead. If it is outside your initial plans, then it is unlikely to spend any effort on that. That might end up as a technical debt. But there is always a price we pay for the rush.</p> <p>2) No API conventions on the team or organizational level</p> <p>Having API conventions is crucial in any case: whether you design or code first. Without the conventions, you are doomed to redesign API repeatedly, trying to match pieces of broken glass. For an API in production that might end up with breaking changes. And no one likes breaking changes (I wrote the\u00a0essay\u00a0dedicated to that).</p> <p>3) Lacks stakeholder involvement/lack of knowledge in API</p> <p>API design-first is about collaboration among stakeholders. If API is not a priority for them, then the API design phase can be delegated to developers while implementing those APIs (or a little prior).</p> <p>Another case is when stakeholders are willing to participate but can't speak \"API language.\" OpenAPI, for instance, can be used as such a language. But learning a language needs personal effort. Not talking about mastering the OpenAPI specifics, just understanding the basic concepts (grammar) and the ability to express yourself and understand others.</p> <p>Thus, if stakeholders want to be involved in the API design but do not speak an API language or speak another API language (e.g., SOAP), there should be time dedicated to learning.</p> <p>4) (Very) extensive system</p> <p>To finalize some skepticism, applying the design-first approach for a very extensive system that may include hundreds of microservices is not reasonable. Spending time designing the API of each specific microservice is not the best idea. You'd better spend time creating templates or boilerplates for API facades. Some business-sensitive APIs can be designed, considering the specifics: security, customer needs, and government regulations.</p>","tags":["API Design"]},{"location":"api-design-first/#where-to-learn-about-designing-api","title":"Where to learn about designing API","text":"<p>Whether you have decided to apply the API design-first or are just interested in learning more about API, there is a proven-by-me list of resources to help you:</p> <ul> <li>A brilliant free\u00a0course\u00a0published at\u00a0https://idratherbewriting.com. It is designed primarily for technical writers, but this material suits any non-developer role. It has become a part of the mandatory onboarding for Business Analysts and even UX designers in my team. The course itself is immense. You will be enough with the first five chapters. I am most grateful to the author, Tom Johnson, for his great work.</li> <li>If you want to dive deeper into the topic, I can recommend \"The API\" by Sergey Konstantinov. It is free and available both in\u00a0English\u00a0and\u00a0Russian. The primary audience is API developers, but it is also good reading for System Analysts.</li> <li>Code Academy has a paid course, \"API Development with Swagger and OpenAPI\".</li> <li>There is also a book titled \"Continuous API Management\". I have read the first half of the 1st edition. Still, this is a more general reading for managers mainly. I will resume reading 2nd edition.</li> <li>And\u00a0OpenAPI specification\u00a0itself. The latest version on December 2022 is 3.1.0, even though it has yet to be very common. OpenAPI 3.0 and its previous iteration, Swagger 2.x, are still used in the industry.</li> <li>As a prerequisite, you must learn the basics of JSON, YAML, and XML formats. You'd better have a general notion of primitive data types: strings, integers, arrays, etc. There is plenty of available videos covering those topics on Youtube.</li> </ul>","tags":["API Design"]},{"location":"api-design-first/#outro","title":"Outro","text":"<p>I decided to explore that topic as I followed API design-first for one of my side projects for a simple reason: autogenerate client and server-side code. As I am not a developer, that helps me to save a lot of effort.</p> <p>In the following essay, I review some free low-code and no-code solutions for API design.</p>","tags":["API Design"]},{"location":"api-design-tooling/","title":"API Design Tooling","text":"","tags":["API Design"]},{"location":"api-design-tooling/#api-design-tooling","title":"API Design Tooling","text":"<p>This article is a part of the API Design series, where I will review several API design tools and summarize my experiences. There are the following criteria I use in selecting and evaluating the tools:</p> <ul> <li>it is free: either open source or a free plan of a paid product</li> <li>out-of-the-box functionality is considered only: no plugins</li> <li>both web and desktop products are considered</li> <li>it allows designing REST API definition in OpenAPI 3.x with JSON/YAML (low-code), UI means (no-code), or a combination of both</li> <li>code generation functionality is not required as there are several 3rd party libraries to do that</li> </ul> <p>I am not promoting, just expressing my honest opinion. But I might have my favorites. Also, I will describe these tools at the moment of December 2022.</p>","tags":["API Design"]},{"location":"api-design-tooling/#low-code-tools","title":"Low-code tools","text":"<p>Low-code means that you can design an API in a code editor but not using Java, Python, or another programming. There is a higher-level language, usually called a Domain-Specific Language (DSL). OpenAPI is such a DSL used in the API design tools.</p>","tags":["API Design"]},{"location":"api-design-tooling/#swagger-editor","title":"Swagger Editor","text":"<p>It is a default option for designing API with the OpenAPI specification. OpenAPI is formerly known as Swagger until version 3.0. Swagger Editor comes from the company that founded that initiative.</p> <p>Swagger Editor\u00a0is available on a web browser and can run on a local machine. You need Node.js, an NPM package manager, and a few trivial command-line manipulations for the latter.</p> <p></p> <p>It works with both YAML and JSON, which is very convenient. You can define API components via UI forms, so we are stepping on the no-code grounds. However, UX could be better there.</p> <p>One of the most significant advantages is that you can immediately generate client and server-side code for multiple programming languages (Python, Go, Kotlin, Java, etc.) after finishing the design part. I will not judge the quality of the autogenerated code - not an expert. But this is an excellent option to deploy and test your APIs quickly.</p> <p>The main disadvantage is the absence of autocomplete functionality in the code editor. For some people, like me, it is a crucial one. But fortunately, this will no longer be the case because of the available\u00a0beta\u00a0of an upcoming new version of the editor.</p> <p>It keeps all the advantages of the current editor plus:</p> <ul> <li>AsyncAPI 2.x support: a big deal in the Event-Driven world</li> <li>dark/light theme: must-have in the modern times</li> <li>autocomplete support</li> <li>built-in documentation</li> </ul> <p>The significant thing here is not autocompleting; it is the built-in OpenAPI documentation. It is available in the code editor. When something goes wrong, there is no need to look up anything in the\u00a0documentation\u00a0portal.</p> <p></p> <p>The only bad thing that happened to me in the beta was that my API definition, valid in the current Swagger Editor, needed to be corrected for no reason.</p> <p>So if you are a novice in the API world, start with Swagger Editor (beta).</p>","tags":["API Design"]},{"location":"api-design-tooling/#postman","title":"Postman","text":"<p>Postman is primarily known\u00a0as a REST API client for testing. However, it is far more than that. It is a complete API Platform, not only for designing and testing APIs.</p> <p>Postman supports many API formats, not limited to OpenAPI. Its editor supports JSON and YAML, along with auto-completion and error validation. Even though there is no immediate side-by-side preview, like Swagger Editor does, it generates fancy-looking API documentation.</p> <p></p> <p>The only disadvantage is that you must log in to your workspace in Postman. That is not a big deal, but running API requests without login is possible.</p> <p>Beyond that, Postman provides a lot more: create a mock server, test your API endpoints, automate your test, sync with a remote Git repository, deploy your API, etc. It even can generate server-side code. But the number of supported programming languages is less than in Swagger Editor.</p> <p>If you are already familiar with Postman, I recommend using it for API design.</p>","tags":["API Design"]},{"location":"api-design-tooling/#insomnia","title":"Insomnia","text":"<p>Insomnia is a Postman's counterpart, also developing from an API client to an API Platform. I used it a few years ago to build and validate end-to-end API scenarios. And for me, Insomnia was more friendly for beginners and seemed more straightforward than Postman.</p> <p>Now Insomnia also provides the possibility to design an OpeAPI definition, debug, and test it. From the design perspective, there is a code editor part on the left and a Swagger UI preview part on the right. API is defined with YAML, and the preview displays every change. The tool has good error validation but lacks autocomplete.</p> <p></p> <p>I recommend using something other than Insomnia when following the API design-first approach. And only then come back to debug and test. Insomnia's rich test and debug functionality becomes less relevant in this case as you need to generate the API layer and run a web server elsewhere.</p> <p>I am talking about a free version of the product. The paid enterprise might have that functionality, but that is beyond my current experience.</p> <p>An ideal use case for Insomnia: you already have a REST API service with OAS definition, which you can import, debug, and run tests. Meanwhile, you can adjust some documentation attributes in OAS.</p>","tags":["API Design"]},{"location":"api-design-tooling/#no-code-tools","title":"No-code tools","text":"<p>No-code means you can design API with the help of UI components rather than writing some code in the code editor.</p>","tags":["API Design"]},{"location":"api-design-tooling/#stoplight","title":"Stoplight","text":"<p>Stoplight\u00a0is an enterprise-level API Platform with impressive functionality. It also allows designing API with a free plan. Even though that free plan has some limitations, it is enough to develop a RESTful API.</p> <p></p> <p>You can edit your API definition as JSON or YAML in the code editor or configure it via the UI form. And then see the result with the preview. Altogether it may seem too complex, but Stoplight has the best user experience (UX) I have seen in the API-design tools.</p> <p>You can only build API with a technical background. Even with no-code configuration, you'd better know OpenAPI spec anyway. API design with fancy UI is more fun, for sure. But not so productive compared to an advanced code editor in the right hands.</p> <p>There is a bunch of details that largely contribute to what is called \"developer experience.\" In error validation, there is a \"done-it-right\" example. You can change the order of your API paths in the navigation pane. You can create a Model by generating a JSON file into a JSON schema. And these are only a few.</p> <p>When your API is ready, you can publish it in a developer portal. You can configure mock API requests, so other users will see your API documentation and try to use it. You can publish different versions of APIs and search across multiple portals. Overall, developer portals are another big topic I might cover someday. Stoplight handles that greatly, but this does not benefit you with the free plan.</p> <p>So if you want to engage in API design without studying OpenAPI the hard way by making your hands dirty in the code editor, then Stoplight is the right choice.</p>","tags":["API Design"]},{"location":"api-design-tooling/#apicurio-studio","title":"Apicurio Studio","text":"<p>Apicurio\u00a0is a bunch of open-source products for API design and management. My focus is on\u00a0Apicurio Studio, which deals with designing API with no code.\u00a0</p> <p>The \"open source\" label defines both strengths and weaknesses of this product. It neither does have a fancy UI nor multiple features to simplify the life of an API designer. But it is free to use: you can either use it on the Apicurio website or run it on your server with no charges.</p> <p></p> <p>Apicurio supports two configuration modes: Design for no-code users and Source ones who prefer code editors. Compared with Stoplight, Apicurio supports the same RESTful API configuration process. As they both follow the OpenAPI specification, it is challenging to build something extraordinary there. Apicurio looks less user-friendly and only provides a few additional services (remember, it is free).</p> <p>It also does not have a built-in preview. Instead, it uses\u00a0Redoc, another great open-source tool, to generate API documentation.</p> <p>If you need to scale the API design approach in your organization but are not willing to pay money, then it is the right choice for you. Just consider the possible risks that come with open source. Remember, the good thing is that OpenAPI is the industry standard nowadays, so you can take your API schemas and migrate them to other tools.</p>","tags":["API Design"]},{"location":"api-design-tooling/#apibldr","title":"Apibldr","text":"<p>Apibldr\u00a0is a free online tool (free does not mean open source) to design OpenAPI and AsyncAPI definitions. The latter is a big deal that is not very common. Of six tools, only the beta of Swagger Editor and Apibldr work with AsyncAPI.</p> <p></p> <p>From a UX perspective, it is something between Stoplight and Apicurio. You only have to define your Models in a JSON schema format; there are no other options, so that does not entirely stick with the no-code concept.</p> <p>Apibldr also allows code generation for the client and server sides. Again, I am not an expert, but it seems that it uses the\u00a0swagger-codegen\u00a0library for that purpose. So it is up to you whether to use it or not.</p> <p>My main concern is that Apibldr's\u00a0GitHub\u00a0looks abandoned. I realized that the developers focus on RestCase, a more enhanced API tool that uses Apibldr's UI. Not sure about its future, but for now, it is a good tool to open and start designing API in your web browser.</p>","tags":["API Design"]},{"location":"api-design-tooling/#what-tool-do-i-choose","title":"What tool do I choose?","text":"<p>I choose\u00a0Postman\u00a0to design API for my current side project. I am excited to learn more about that tool and its outstanding infrastructure. I am advanced enough to use just a code editor, so I don't need a no-code solution here.</p> <p>But I will keep my eye on another API tooling as one I may come up with in the next part of the API design tools overview.</p> <p>Take care</p> <p>Ilya</p> <p>Image by Merlin Lightpainting from Pixabay</p>","tags":["API Design"]},{"location":"performance-metrics-obsession/","title":"How I overcame my obsession with performance metrics","text":"","tags":["BA & PO"]},{"location":"performance-metrics-obsession/#how-i-overcame-my-obsession-with-performance-metrics","title":"How I overcame my obsession with performance metrics","text":"<p>I fell into a common trap of every manager: obsession with performance metrics. Since I have been promoted to the PO role my responsibilities include tracking stats related to the backlog and team performance. That includes the team\u2019s capacity, estimates, velocity, and other specific metrics. In an ideal world, the estimation of planned features matches capacity, the team performs a predicted velocity and (more importantly) delivers features in time. But we all know that doesn\u2019t work this way.</p> <p>This is the story of how I became obsessed with numbers instead of being obsessed with a product. And how I overcame that and shifted my focus to real value.</p>","tags":["BA & PO"]},{"location":"performance-metrics-obsession/#why-did-i-fall-into-the-number-obsession-trap","title":"Why did I fall into the \u201cnumber obsession\u201d trap?","text":"<p>Here are the main reasons, from my perspective:</p> <p>Ambitions</p> <p>As a newbie Product Owner, I wanted to do my job perfectly: produce an ideal roadmap with epics and user stories that contain clear requirements so that the team could provide precise estimations (in story points). Then that would be translated into a plan fitting the team\u2019s capacity. The team would commit to the plan and complete it with flying colors within a predicted timeframe. Customers are happy, stakeholders are happy, my manager is happy, and the team is also happy. I would receive a gold medal for \u201cthe best PO of the year\u201d with a promotion to the Chief Product Officer position. Or Vice President of something, why not?</p> <p>But the reality is harsh. The requirements are not always defined well, technical complexity is underestimated, the team lacks experience in some domains, dependencies on other teams, and urgent customer support requests. I named only a few obstacles - pretty sure you know the others.</p> <p>So the original plan is not valid anymore, epics and features shift to \u201csomewhen when it is ready - maybe this year, maybe not\u201d. You found yourself in the hell of constant re-planning (you can read about it in one of my previos essays). You re-plan, the plan fails to meet reality, you replan again and now it looks good. Oh, f*ck, two developers left the team\u2026 Here we go again.</p> <p>When you spend most of your time on re-planning, you can\u2019t be focused on the product.</p> <p>Pressure</p> <p>Of course, there are reports that track those performance metrics across all the teams. Nothing bad here, this is a must-have if you want to stay on track.</p> <p>\u201cWhy did your team close so few story points in a previous sprint?\u201d I have been asked more and more frequently.</p> <p>I had a default answer. \u201cWe dragged some user stories to the next sprint due to ...(blah-blah).\u201d </p> <p>That follows with something like, \u201cTake a look at this graph. You can see that you are behind the program increment plan. You should have completed this (number) of story points. But you only completed (much less) so please do something. Let me know if you need my help\u201d.</p> <p>That \u201cdo something\u201d implied the re-planning. \u201cSure, I will take a look and handle this\u201d.</p> <p>Now I understand: no one tried to assault me with those questions. Just to highlight an issue and make sure that it is on my radar. But that, multiplied by my ambitions and immaturity as a PO, built up enormous pressure inside me.</p> <p>I fiercely wanted those damn graphs to look good. I tried to use different approaches in feature decomposition and planning, introduced changes to the refinement process, and scheduled additional meetings to discuss any technical issues before the development. But still, non-completed tasks dragged from sprint to sprint and overlapped with new tasks. None of the original plans seemed feasible or even somehow controllable.</p> <p>With all that, my old good friend, the imposter syndrome came into play. \u201cWhat if I am not a real PO? What if they realize that I am not a real PO? I should have better stayed as a Business Analyst and never move to a product organization.\u201d</p>","tags":["BA & PO"]},{"location":"performance-metrics-obsession/#the-overcoming","title":"The Overcoming","text":"<p>Friday, the last day of a Sprint. About 10 PM. I am on the call with a Team Lead (TL) discussing the sprint closure. We really struggled a few previous iterations having a very low team velocity vs our quarter roadmap plans. Several big technical features were continuously dragged from sprint to sprint with multiple issues appearing along the way. </p> <p>But this sprint is different. We have managed to close those big features, handle a few customer requests, and fix a bunch of bugs. I did some calculations and that appeared to be our best sprint for the last 7 (!) months. The team is encouraged as it seems we have overcome that dark period.</p> <p>But this is not what we are talking about with TL. We are discussing 2 medium-sized features that have been developed but not yet tested. They were delivered to a testing environment late today, so our QA already ended her working day. If we could close those features right now, the sprint result will be outstanding. The team really worked hard and deserved that.</p> <p>\u201cWhat will we do with the features?\u201d TL asked. I am a Product Owner and I have the power to decide whether a feature is completed or needs additional work to be done.</p> <p>\u201cListen, those features are quite small improvements of non-critical functionality. They passed dev testing phase and I personally checked them. All works as expected. Right?\u201d I don\u2019t want to lose the outstanding number I already calculated in my mind. And I am determined to make that happen.</p> <p>\u201cWhat do you suggest? Close the tickets without real testing?\u201d</p> <p>\u201cYes, you are right. As I said, that is not a critical functionality. I don\u2019t see any risks there. Let\u2019s set them as non-QA, close, and go rest. We did a really great job so we all deserved that\u201d, I can sound very convincing.</p> <p>\u201cOK, I agree\u201d.</p> <p>After some manipulations, the features were considered as done, the tickets were resolved and the Sprint was closed. Time to enjoy the weekend.</p> <p>Saturday morning I received a message from our QA Lead (QL). \u201cHi, I saw you had closed those 2 tickets as non-QA\u201d.</p> <p>I am ready to defend, \u201cYes. Developers finished them very late so you were already off. They are quite small so I decided to complete them as non-QA\u201d.</p> <p>\u201cOK. I just wondering, do we need to cover them with automated tests?\u201d</p> <p>F*ck. We\u2019d better cover them with autotests. But that means the QA team needs to write testing scenarios, validate them, and then proceed with automation. Basically, to do the work I previously defined as \u201cnot needed\u201d by converting the features to non-QA.</p> <p>I take a pause. There is a growing feeling that I have done something very stupid. I manipulated with features and moved testing activities in \u201ca shadow mode\u201d to the next Sprint and proudly announced that they are completed. But they are not. I start feeling sick.</p> <p>\u201cYes, we need to automate both features\u201d, it took me about 30 minutes to answer her.</p> <p>\u201cOK, no problem. Next week I will pass it to the QA team and we will proceed with the automation. Have a nice weekend!\u201d</p> <p>That weekend was not nice for me at all. I passed through the Five stages \u2013 denial, anger, bargaining, depression, and acceptance. I fought with my ego which was obsessed with the numbers and wanted to achieve high results, even fictional, at any cost.</p> <p>Next Monday we had a team retrospective call. I apologized to the entire team. I confessed that I manipulated tickets for the only reason to satisfy my ego with good stats. I spoiled a really great team achievement and now QAs had to cover my ass with that testing.</p> <p>\u201cWhat I did is stupid. I am really sorry. I will never do that again\u201d.</p> <p>And I am keeping my promise. Now, by the end of each Sprint, I consider only what is really done. I am no longer pushing tickets for good stats. I don\u2019t really know how many story points my team closed last sprint or earlier. I am smiling when some managers report something like \u201cWe completed 1000 story points during a last sprint/quarter/year\u201d. I am no longer playing that game.</p> <p>I am focused on the value we, as the Team, can produce for our customers. We can do a complex functionality during a few iterations and that will not look good on reports. But when we deliver that might have a big positive impact on those who use our services. Value can be transitioned to customer satisfaction and that can be transitioned to profits. Story points do not transition to value.</p> <p>Take care,</p> <p>Ilya</p> <p>Meditation Vectors by Vecteezy</p>","tags":["BA & PO"]},{"location":"product-manager-year-one/","title":"Product Manager: Year One","text":"","tags":["Career"]},{"location":"product-manager-year-one/#product-manager-year-one","title":"Product Manager: Year One","text":"<p>One year has passed since I was promoted to a Product Manager position: first six months as an Associate (a Junior grade), and then I stepped in as a fully-fledged Product Manager. And that was a drastic shift that made me revisit some aspects of my work and added a new dimension to my view on product development.</p> <p>In this essay, I want to summarize my experience with the insights I collected throughout the year. Some of them might be obvious to a more experienced audience. But for me, some were revelations, and some were hugely underestimated initially. It is a good exercise to conduct such a personal retrospective, and others can benefit from that as well.</p>","tags":["Career"]},{"location":"product-manager-year-one/#lack-of-resources-is-permanent-live-with-that","title":"Lack of resources is permanent - live with that","text":"<p>During the meetings with senior management, some Product Managers from other teams always complained about needing more people to complete their goals. It is a big problem that cannot be resolved immediately. But at some point, that becomes irritating. Lacking human resources should not become a constant excuse for missing business objectives.</p> <p>I was also among the complainers at first. Then I realized a better strategy to focus on what you can achieve with the current amount of people in the team. Some objectives require a lot of people involved to get the right things done at the right time. But some of the objectives also can be decomposed and addressed with a current team capacity. Also, a business need can be handled in many ways, not always with hundreds of dev hours or story points spent on new features. You need some space to think out of the box and have the trust of the senior stakeholders in you and your team to find the right solution within current constraints.</p> <p>I asked myself, \"What should we not do or stop doing to achieve something?\" instead of \"What should we do?\". Do more with less. That is my motto right now. I know what I would do with more developers in my teams. But I have a strategy in case of decreasing the team's capacity even more.</p>","tags":["Career"]},{"location":"product-manager-year-one/#lights-on-work-is-a-real-threat-to-product-development","title":"\"Lights-on\" work is a real threat to product development","text":"<p>Support activities and tech debt can bite off a large piece of a team's capacity and defocus them from new product functionality. You can't avoid this, unfortunately. The best way to mitigate this is to forecast how much that might take in future iterations. But this is a challenging task. You can handle tech debt by splitting some fixed amount of dedicated efforts for each development sprint or having a full sprint once in a quartal. The support is much more challenging to handle, especially if you have legacy service with few people knowing how to work with it. And if you are an infrastructure team (that is my case). It is impossible to foresee the number of bugs, feature requests, and questions from other teams and customers. Each with the highest priority, of course. That can block the development of new features and break all the plans you committed before.</p> <p>The only way I found is to become ruthless in filtering \"urgent\" support items to complete. No more Mr. Nice Guy. You must become a gateway that needs to be passed so a team will take a support item, not from the queue. I am that guy who will stand against your request, even if it is crucial until you prove it is a real priority. Of course, you can go upstairs and push it through via higher management, but I will fight till the end to protect my team's backlog.</p> <p>Of course, I expected that pressure. But the real tension here is what surprised me.</p>","tags":["Career"]},{"location":"product-manager-year-one/#hell-of-constant-replanning","title":"Hell of constant replanning","text":"<p>Planning is a huge topic I would like to cover in separate essays. For now, I constantly revised a year's roadmap and quarter plans. There are dozens of reasons why that happens, but in the end, I get nothing but frustration.</p>","tags":["Career"]},{"location":"product-manager-year-one/#being-without-mentorship-sucks","title":"Being without mentorship sucks","text":"<p>My quick promotion to a standalone Product Manager happened before my mentor left the organization I am working in. So I stepped into his role and found myself in a vacuum. There is no senior product manager to manage me, and next-level VP management is a bit away from my day-to-day activities. They could help me with my questions. I am not questioning their good attitude. They have a broader view, and diving into a low-level of details is complicated: either because of lacking knowledge in my domain or having a more technical than product-oriented background.</p> <p>That does not mean I am alone and no one wants or can help me. The organization's product management process is well-defined but can't answer all the questions. Asking other PMs gives little as we are acting in a more isolated way and not aware of each other specifics.</p> <p>Recently, Q&amp;A sessions were introduced where I can fire my more-or-less stupid questions and get helpful responses from different audiences: POs, BAs, operational managers, etc. However, I would like a parental figure to sit down with me and say: \"Hey, son, stop doing this stupid shit. Here is what I'd suggest\u2026\".</p> <p>It may be for the best. In another year, I will let you know.</p>","tags":["Career"]},{"location":"product-manager-year-one/#afterword","title":"Afterword","text":"<p>Those are not all insights I have gotten during my first year in a Product Manager's shoes. And not all of them are as negative as I described above. It just appeared when I started writing this piece that the most pessimistic things appeared on the plate. I have gained much experience and still need additional time to analyze some things. I will be glad to share that with you here.</p> <p>Take care,</p> <p>Ilya </p> <p>Baby Vectors by Vecteezy</p>","tags":["Career"]},{"location":"reading-gharajedaghi-system-thinking/","title":"Thoughts about J. Gharajedaghi\u2019s \"System Thinking\"","text":"","tags":["BA & PO","System Thinking"]},{"location":"reading-gharajedaghi-system-thinking/#thoughts-about-j-gharajedaghis-system-thinking","title":"Thoughts about J. Gharajedaghi\u2019s \"System Thinking\"","text":"<p>This is a new rubric in my blog as I tried to avoid any posts about specific books before. I am taking some notes about the best books I have read. But those are not for the public eye. So this piece was not originally planned to be published. I just feel a need to share something with the world after I read a book in the title. Because that was a wonderful but pretty tough experience.</p> <p>Before we begin, let\u2019s make clear that:</p> <ul> <li>It is not a review. I will not write about bad books in my blog. By default, any book which has a separate essay is worth reading. Period.</li> <li>That will be in the form of an internal dialog.</li> </ul> <p>OK. What is the full title of this book?</p> <p>\u201cSystem Thinking: Managing Chaos and Complexity: A Platform for Designing Business Architecture\u201d by Jamshid Gharajedaghi, 3rd edition</p> <p>Nice. How did you learn about this book?</p> <p>A few years ago when I was listening to a podcast with a guest talking about System Thinking. He stated that the book is quite hard to read and should be considered as a final bullet after you have already read other sources. I accepted the challenge and bought the book on Amazon.</p> <p>I guess you read something about System Thinking before, right?</p> <p>Correct, I read a few books before. So I considered myself mature enough to have a shot at something more serious on that topic. I was too naive. Gharajedaghi\u2019s \u201cSystem Thinking\u201d at the same time was an exciting and difficult reading experience. It took me more than a year to read those 376 pages.</p> <p>Oh. Why was that so harsh?</p> <p>Several reasons. First of all, the topic itself is quite complex. Secondly, it is not an introductory book. It expects that you are familiar with a lot of concepts. Third, a written language. I am not a native English speaker so I can judge only from my reading experience but it was hard to pass through some passages. I consulted with an English dictionary a lot. Some word choices and syntax constructions confused me. I will not dive into examples, but \u201cdissemination of power\u201d sounds weird to me. In this context, \u201cdissemination\u201d means \u201cdistribution\u201d, I get it. And this is a very lightweight example.</p> <p>Also, I mistakenly approached this book as non-fiction. It is neither non-fiction nor a scientific reading. It is something beyond. Two times I re-started the reading and my third attempt was successful because I changed the reading approach.</p> <p>The thing is that when you stop reading for a week at least, it is difficult to jump back to the context. Just because of how deep this book goes you need to stay focused until the end or you go out. With my 3rd attempt, I started making summaries of the most complex chapters. If I stopped reading even for a few days, I did a recap of the previous chapters to dive in again. And that worked out for me.</p> <p>Now tell us more about the book</p> <p>Chapters 1 and 2 serve as an introduction to systems and the movement toward System Thinking. But that is not an introduction for beginners because it does not cover the basics. You will get a general idea about the whole thing, but that will not prepare you for what comes next.</p> <p>Chapters 2-9 are more theoretical. It uncovers concepts of sociocultural systems and different modes of thinking to understand those systems. And this is the hardest part of the book, where I failed 2 times and had to start reading again. Some thoughts are repeated in different parts of the book, but it is absolutely necessary to read those chapters carefully.</p> <p>Chapters 10-14 are the business cases from Jamshid Gharajedaghi\u2019s outstanding consulting experience. It is more relaxing reading than the preceding theoretical part and is more about applying that theory in practice. My only concern is that those cases focus on the \u201cTO-BE\u201d part, skipping the \u201cformulating the mess\u201d and how the implementation happened (if happened). It is a big deal to design the right solution but that needs to be implemented and delivered at the end. Unfortunately, that is not fully addressed in the book, but for obvious reasons: you will need another book.</p> <p>Also, some cases took place in the 1990s, and since those times some \u201cTO-BE\u201d suggestions are considered more like the industry standards today rather than insights. But this is a good sign actually as they have proved to be vital.</p> <p>What did you learn from this book?</p> <p>Not an easy question. I will definitely keep revisiting my notes and some chapters of the book. But I will try to formulate what I have so far:</p> <ol> <li> <p>Most business and management concepts has been originated in the 1950-1970s. Currently, we just keep re-inventing the wheel and putting it in a new colorful package to sell as courses. It is not a new idea either, but I have just become more convinced about that.</p> </li> <li> <p>As an IT person, I approached each system as software. Then, while reading more and more about System Thinking I started considering a system as something more technically advanced: a flight or an F1 car. This book gives a wider perspective on a higher level - sociocultural systems. Each organization is a sociocultural system. And that itself is a more complex being than any piece of software.</p> </li> <li> <p>5 Dimensions of social systems and the importance of their generation and distribution (\u201cdissemination\u201d): wealth, power, knowledge, beauty, value. If the first three are pretty obvious, beauty and value give me an additional perspective when now looking at social systems.</p> </li> <li> <p>Distribution without effective production can only result in equal distribution of poverty.</p> </li> <li> <p>The importance of communicating the shared image as leverage to transformation.</p> </li> <li> <p>Formulating the mess is sometimes more important than designing a solution. A quote by Russel L. Ackoff mentioned in the book: \u201cWe fail more often not because we fail to solve the problems we face but because we fail to face right problems\u201d.</p> </li> </ol> <p>Again, that might seem pretty obvious but it is really huge. Further I keep going, and the more I keep asking myself what the hell I am doing and for what reason someone needs that (shit).</p> <p>Let\u2019s stop on those six. But there are more, definitely.</p> <p>You mentioned that this book is not for beginners. What do you recommend for people who want to get acquainted with System Thinking?</p> <p>\u201cThinking in Systems\u201d by Donella H. Meadows. No doubt, the best introduction to this topic.</p> <p>Then start looking for other materials to dive deeper - you need to have some background for Gharajedaghi\u2019. Don\u2019t repeat my mistakes.</p> <p>Take care,</p> <p>Ilya</p>","tags":["BA & PO","System Thinking"]},{"location":"sidekick-product/","title":"Sidekick product","text":""},{"location":"sidekick-product/#sidekick-product","title":"Sidekick product","text":"<p>Throughout my career, I participated in the development of a few supplements for so-called \u201cparent\u201d products. They were standalone services with their own, not big, but still considerable business value. Recently I realized that even though those supplement products were developed in different organizations and in different business areas they did have common traits. Moreover, they shared the same problems.</p> <p>It was something laying on the surface. Sometimes you shoot yourself in the foot twice before starting to see obvious things. What is the nature of those Sidekick products and do they inherit the problems of \u201cbigger brothers\u201d? Let us sort it out in this essay.</p>"},{"location":"sidekick-product/#sidekicks-characteristics","title":"Sidekick\u2019s characteristics","text":"<p>A Sidekick product may appear near a \u201cbig\u201d product when there is an opportunity to address business needs that do not exactly lay on the main product direction. But still, such Sidekick can potentially bring additional value to the business.</p> <p>Here is a list of the characteristics for identifying a Sidekick:</p> <ul> <li>It can\u2019t exist without a \u201colder\u201d brother and it is very attached to it.</li> <li>It is considered to be an easy try to gain more with fewer efforts</li> <li>Quick development using already existing components and known practices</li> <li>Everyone is very excited about it (so far).</li> </ul> <p>At the same time, those points are Sidekick\u2019s strengths and the pitfalls hidden under the surface. What I learned from my experience (in a hard way), the wrong decisions from the start, even for the supplement, are very difficult to handle on the way. Similar to the \u201cbig\u201d products, the sidekicks should not be treated carelessly.</p>"},{"location":"sidekick-product/#sidekick-pitfalls","title":"Sidekick pitfalls","text":"<p>1. Flexible vision &amp; great expectations</p> <p>After starting building something \u201cquick and dirty\u201d you might very soon realize that it is not \u201cquick\u201d anymore. And this becoming dirtier and dirtier. It is a common situation for any product, but for the Sidekicks that is more fatal compared to others. Different sides push it in different directions which have been not considered from the beginning.</p> <p>Sometimes that is for good: history knows a lot of examples when a Sidekick resulted in a successful standalone product or even a new business. But history usually avoids mentioning a graveyard of the products with a such \u201cflexible\u201d vision.</p> <p>Stakeholders are excited about the new opportunities. Each has its own view on what should be added to make a proper solution. That causes an overload and losing the initial vision of the product. In the end, that leads to failed expectations from different parties.</p> <p>You\u2019d better know what you are going to build. And also, be pretty confident about what you are not. </p> <p>2. Prolongating MVP development</p> <p>This is an obvious consequence of Point 1. Unnecessary prolongation of an MVP stage is a common disease in any industry. But with a Sidekick, it is relatively easy to fall into an endless extending/redoing cycle. The unclear vision and desire to address the needs of every stakeholder makes the exit very complicated.</p> <p>On the other hand, if your MVP appears to be not very \u201cV\u201d (viable/valuable) because of the rush and not listening to the right guys, then welcome to the Sidekicks\u2019 graveyard.</p> <p>3. Lack of architecture guidance</p> <p>A Sidekick is expected to have a very quick time-to-market period. And such phrases as \u201cLet\u2019s deal with (put your option) later\u201d on the MVP stage, along with quick and unjustified tech decisions, could lead to the exhausting on-the-fly architecture changes. Lack of the proper architecture guidance from the start may cause time-consuming refactorings when a Sidekick becomes mature and need to address more complex functionality.</p> <p>Especially that hurts when your go live with it. Your team quickly realizes itself buried in the problems with scaling, performance, and integration. And the Security team is knocking on your door with a bunch of found vulnerabilities to be resolved ASAP. I bet you haven\u2019t got that planned initially.</p> <p>4. Team unfocus</p> <p>If you launch a Sidekick be sure your team will develop it along with the main product. I don\u2019t have any data on this, so let it be my assumption: you are unlikely to get a new team or new hires for a supplement. That might happen in later stages when a Sidekick proves its stake. But for the beginning, you are likely to handle that with what you have.</p> <p>Considering points 1-3, you can imagine how that affects the main product. All that might seem to be a temporary shift in the priority to push the Sidekick as much as possible and return to the mainline later. In the worst case, you found yourself chasing two hares with low chances to catch any.</p> <p>5. Selecting a new technology stack</p> <p>The team might be eager to try new frameworks, programming languages, and libraries with a Sidekick. Nothing bad with that, but you should consider the risks which appear there. Lack of experience may introduce architectural issues and a bigger tech debt to be resolved if the Sidekick transition to a mature \u201cproduction-ready\u201d service. The cost might be too high.</p> <p>Also, the learning curve for new technology can be very long. That causes potential issues with implementing complex features so the team will be not able to resolve that without outside help. That is OK when someone in your organization has experience with that stack and can dedicate some time to help you. But if not then you are in trouble. Hiring a new developer for that purpose or engaging a contractor/freelancer brings risks to a new level. Waiting until the team will be experienced enough to handle the complex feature might not be an option as well.</p> <p>6. Selecting the same stack as the \u201cParent\u201d</p> <p>The team is familiar with the technology so we do expect that even complex issues will be resolved in the known domain. However, there are new risks here:</p> <ul> <li>Bringing bad practices from the Parent to the Sidekick.</li> <li>Unnecessary tying the Parent with the Sidekick.</li> </ul> <p>Using the \u201cParent\u201d stack seems to be an easier way. And, actually, it does. However, there might be cases when some solutions could be done better (quicker and with more quality) if developers were not looking back on the Parent and bringing some practices from it. Those practices might be good there, but it is not always the case for the Sidekick.</p> <p>Also, tying the Sidekick with the Parent on the program and infrastructure levels can result in a very painful divorce. Such kind of migration will freeze the implementation of new features and cost many efforts.</p> <p>The best recipe is not to be afraid to bring some innovation and explore new technological capabilities for a new product. But ensure that someone in the team or in the organization can guide you in that journey.</p>"},{"location":"sidekick-product/#outro","title":"Outro","text":"<p>The main idea here is \u201cplease do not underestimate the complexity of a Sidekick product\u201d. Treat it as seriously as a \u201cbig\u201d product by investing time into defining vision and solid architecture from the start. This is not a recipe for success, but it still increases Sidekick\u2019s chances to go to Production and bring expected value to customers.</p> <p>Next time I will share with you a real case of such a Sidekick. Stay tuned!</p> <p>Take care,</p> <p>Ilya</p> <p>Happy Vectors by Vecteezy</p>"},{"location":"tips-for-junior-ba-interview/","title":"Pre-interview tips for Junior Business Analysts","text":"","tags":["BA & PO","Career"]},{"location":"tips-for-junior-ba-interview/#pre-interview-tips-for-junior-business-analysts","title":"Pre-interview tips for Junior Business Analysts","text":"<p>Recently I was looking for a Junior Business Analyst to join my team. I considered candidates with little or no experience in IT. And that was an excellent experience for me. For the first time in my career I:</p> <ul> <li>wholly owned job requirements for the position</li> <li>made a final decision to hire someone or not</li> <li>was not doing the tech part of an interview</li> <li>interviewed Junior-level specialists.</li> </ul> <p>It is different from interviewing a Middle or Senior BA. You can discuss various topics with more experienced professionals: practical cases, challenges, techniques, recent articles, etc. But that is hardly applicable for the Juniors as they can share only their background and knowledge of theory with the ability to apply that in practice, at the very least.</p> <p>The main proof of their ability is a diploma project if they have previously finished some business analysis courses. Another option is a test task or even a pet project. And be well prepared for an interview, of course.</p> <p>I was not hosting a part with Business Analysis questions, so I focused on the written evidence and carefully listened to the interviewee. After I finalized my feedback for each candidate, I realized some missteps which occurred in a number of the interviews. Even though they seem to be obvious, it is important to highlight them and provide my suggestions.</p>","tags":["BA & PO","Career"]},{"location":"tips-for-junior-ba-interview/#invest-your-efforts-in-formatting-and-language-of-your-testdiploma-project","title":"Invest your efforts in formatting and language of your test/diploma project","text":"<p>Whether it is a diploma project from BA courses or a practical task given to you before an interview: you must do your best.</p> <p>The first impression is essential. You can provide a better experience for the readers, which is your advantage over other candidates.</p> <p>Many years ago, I was helping my mentor with reviewing the practical tasks of candidates who applied for a Junior BA position. I was shocked when he refused to read a document further without a table of contents, so a candidate missed the chance. The mentor did not care how good the work might be. That was a crucial criterion for him to stop wasting time and proceed to the next candidate.</p> <p>From my perspective, it is unfair not to give a chance to a specification with some formatting issues. But that situation states that you never know who will look at your specification document and what their expectations are. </p>","tags":["BA & PO","Career"]},{"location":"tips-for-junior-ba-interview/#be-able-to-explain-the-requirements-documentation-approaches-you-use","title":"Be able to explain the requirements documentation approaches you use","text":"<p>\"We did that because our mentor told us\" - is a wrong answer about the decision to proceed with user stories instead of use cases in your test/diploma project. You should be ready to justify a used approach considering its advantages and disadvantages.</p> <p>An interviewer can ask you to compare two approaches and express your opinion on which is better. The fun part is that there is no correct answer; in Business Analysis, some things may work depending on a project context. Just share your opinion, even if you have little experience using both. That is a tricky way to test your current understanding of those techniques.</p>","tags":["BA & PO","Career"]},{"location":"tips-for-junior-ba-interview/#if-your-diploma-project-is-group-work-make-your-contribution-clear","title":"If your diploma project is group work, make your contribution clear","text":"<p>Business Analysis course students tend to write their diploma projects in a group of 3-5 persons. Nothing wrong with that. But for me, that makes assessing a candidate's skills problematic.</p> <p>\"We did all the stuff together\" - a lousy answer to a question on how you organized work on the diploma project. That gives me no clue why I should hire you instead of your group mates.</p> <p>Working in a group of BAs is a valuable skill, but that must be a well-organized process with a clear contribution from each peer. You'd better sign the parts you made with your name and be prepared to explain others' parts as your own. </p>","tags":["BA & PO","Career"]},{"location":"tips-for-junior-ba-interview/#write-your-diploma-project-in-english-for-non-native-speakers","title":"Write your diploma project in English (for non-native speakers)","text":"<p>If you plan to start your BA career in an international company or company with international customers, write your diploma project in English. As a Junior BA, you are unlikely to be involved much in communication with stakeholders from the beginning. Your time to shine will come a bit later. </p> <p>More time you will spend on specifying and documenting requirements. You'd better provide additional proof of your written English.</p>","tags":["BA & PO","Career"]},{"location":"tips-for-junior-ba-interview/#study-different-sources-of-knowledge","title":"Study different sources of knowledge","text":"<p>It is painful to hear how a prospective candidate fails to explain the meaning of stakeholder requirements and their place in the requirements hierarchy. I think that happens because most BA students read only the Wiegers*, in which stakeholder requirements are not considered a subject of the requirements structure and are implied to be a part of the business requirements. Wieger's definition is fine, but you'd better study BACCM** by IIBA (free) and learn the modern industry-agreed standard.</p>","tags":["BA & PO","Career"]},{"location":"tips-for-junior-ba-interview/#when-you-send-files-dont-use-proprietary-file-formats","title":"When you send files, don't use proprietary file formats","text":"<p>One candidate sent an \"eap\" file as a documented example to prove their BA skills. Once I got that file from recruiters, I realized I lacked the software to open it on my laptop. I quickly googled that \"eap\" is an extension for Enterprise Architect files. It is a well-known industry tool, but neither I have worked with it nor my organization. So what will my next steps be? To install Enterprise Architect, register, start a 30 days trial, learn how to use it, and finally open that file for a review, I guess.</p> <p>But that never happened. I switched to an assessment of other candidates, and that file's content remains a mystery.</p> <p>You can blame me, but I value my time and want other parties to respect it. Please use standard file formats (like PDF, docx, etc.) or something that can be opened in a web browser (without mandatory sign-up and providing my credit card information). Remember, as a Junior specialist, you compete for a job with many other talented people. And you are not in a position to demand more time than the others. Deal with that.</p>","tags":["BA & PO","Career"]},{"location":"tips-for-junior-ba-interview/#do-your-homework","title":"Do your homework","text":"<p>Not having questions for an interview is a bad sign for a hiring manager. Please prepare some questions about the company, the project/product, the team structure, your future responsibilities, organization processes, etc. Be bold and ask any relevant question which comes to your mind.</p> <p>If it is a product-oriented company, then study any available marketing materials about its products and value proposition you find on the Internet. Nowadays, organizations are largely investing in content marketing, so it is easy to find some hooks to help you formulate your questions.</p>","tags":["BA & PO","Career"]},{"location":"tips-for-junior-ba-interview/#as-conclusion","title":"As conclusion","text":"<p>If you have not got a job offer after an interview or your application hasn't even been considered, that does not mean you are a terrible business analyst. In 80% of cases, your skills do not fit a particular position. In the other 20%, you might not have done your homework, the interview went surprisingly bad, or it was a combination of these factors.</p> <p>Consider rejection as a blessing and keep going. Seek, and you shall find.</p>","tags":["BA & PO","Career"]},{"location":"tips-for-junior-ba-interview/#references","title":"References","text":"<p>*Karl Wiegers and Joy Beatty \u201cSoftware Requirements\u201d, 3rd edition</p> <p>**Business Analysis Core Concept Model</p> <p>Image from Cv Vectors by Vecteezy</p>","tags":["BA & PO","Career"]},{"location":"tips-for-junior-ba-interview/#change-history","title":"Change history","text":"<ul> <li>2022-02-06: Initial version published</li> <li>2023-05-10: Second revision published</li> </ul>","tags":["BA & PO","Career"]},{"location":"api-requirements-webinar-iiba-2/","title":"09.11.2023 Webinar \"Requirements & API. Part 2\" for IIBA Belarus","text":"<p>Following a theoretical Part 1 of the \"Requirements &amp; API\" webinar,  the second part will come on November 9 at 18:00 (GMT+2). Here is a LinkedIn event with a Zoom link.</p> <p>We will dive into API design-first, OpenAPI specification, and related tooling. Also, we will review a few practical cases and API patterns.</p> <p>See you there!</p> <p>As I mentioned, the entire webinar is based mainly on my API Design series, which I have worked on throughout this year.</p> <p>I will publish the recording as soon as it is available.</p> <p>Stay tuned!</p>","tags":["Webinar"]},{"location":"api-requirements-webinar-iiba-part-1%262/","title":"Summary of the \"Requirements & API\" webinars for IIBA Belarus","text":"","tags":["Webinar","Youtube","Slides","GitHub"]},{"location":"api-requirements-webinar-iiba-part-1%262/#summary-of-the-requirements-api-webinars-for-iiba-belarus","title":"Summary of the \"Requirements &amp; API\" webinars for IIBA Belarus","text":"","tags":["Webinar","Youtube","Slides","GitHub"]},{"location":"api-requirements-webinar-iiba-part-1%262/#overview","title":"Overview","text":"<p>Following a theoretical Part 1,  I was glad to talk about more practical API-related things and ways they can be designed.</p> <p>While preparing for the webinar, I expanded my knowledge of the FastAPI Python framework to design mocks. Some of them were not only displaying docs in Swagger UI but also worked kind of. My overall purpose was not only to talk about APIs from the Business Analysis perspective but to show them.</p> <p>Doing a retrospective of the original workshop, it needed some real API for people to interact with. Even a webinar where I talk for about an hour could be a more interactive format; it is a considerable step in that direction. If I do the API workshop again, I could give participants near-to-real API examples to integrate using FastAPI.</p> <p>I like to talk about tooling like every blacksmith likes to talk about their hammer. We have covered Swagger Editor, JSight, and Stoplight to represent different perspectives of API design.</p> <p>I decided not to dive into OpenAPI specification review as enough materials could do it better than me. I just shared an example and a few resources to learn.</p> <p>Also, I updated the API requirements (v3 currently) template using some feedback I received since Part 1. A few things needed to be corrected and more consistent there. Plus, I made it clear in terms of data structure description.</p> <p>At the end of Part 2, while reviewing a practical case, I revealed a custom format I use for textual API specification. It isn't for everyone, and the previous example seems more conventional. At least, that is how I approach API requirements and design based on some Client's input.</p> <p>Overall, doing two webinars at a two-week interval took a month of preparation. I thought it would be easier considering the amount of materials  I produced before. However, I took a complex way to give my best with new information resources, examples, approaches, etc.</p> <p>As I mentioned in my previous post, I still like giving offline speeches where I can interact with an audience and track their mood. But I need to get experience in making the webinars too.</p> <p>It was surprising for me that doing Zoom calls as work presentations and an open webinar are opposite things. The latter is more complex.</p> <p>Thanks to IIBA\u00ae Belarus Chapter for the opportunity to reach a wider audience.</p>","tags":["Webinar","Youtube","Slides","GitHub"]},{"location":"api-requirements-webinar-iiba-part-1%262/#part-1","title":"Part 1","text":"<p>[RUS] Webinar recording on Youtube:</p> <p>[ENG] Slides</p> <p></p>","tags":["Webinar","Youtube","Slides","GitHub"]},{"location":"api-requirements-webinar-iiba-part-1%262/#part-2","title":"Part 2","text":"<p>[RUS] Webinar recording on Youtube:</p> <p>[ENG] Slides:</p> <p></p> <p>Additional materials:</p> <ul> <li>GitHub repository with examples</li> <li>API Requirements Template v3 (download)</li> </ul> <p>P.S. Useful links and suggested reading about API I will publish as a separate post.</p>","tags":["Webinar","Youtube","Slides","GitHub"]},{"location":"api-requirements-webinar-iiba-part-1/","title":"IIBA Belarus \"Requirements & API. Part 1\" - Webinar materials","text":"","tags":["Webinar","Youtube","Slides"]},{"location":"api-requirements-webinar-iiba-part-1/#requirements-api-part-1-26102023","title":"Requirements &amp; API. Part 1 (26/10/2023)","text":"","tags":["Webinar","Youtube","Slides"]},{"location":"api-requirements-webinar-iiba-part-1/#overview","title":"Overview","text":"<p>On October 26, 2023, I hosted a webinar for Business Analysts about API and the requirements specifics about that (announcement).</p> <p>I was very excited about that opportunity. Even that part was based on my previous materials published here in my blog, and from the offline API workshop, I spent a lot of time polishing and re-structuring the content to fit a remote audience with different backgrounds.</p> <p>Personally, I do more like offline public speaking as it gives a sense of touch with people. While doing that online, you wonder whether people are still listening to you or you are not audible due to a connectivity issue. Also, you can't always see a reaction: you are just speaking with your laptop, hoping for the best.</p> <p>My speech was in Russian, and after years, I am losing my ability to make such long and structured pieces in that language. All my professional communication is done in English. I made hundreds of demos and other presentations in English rather than Russian. So, sometimes, I felt that I was translating from English.</p> <p>But overall, I had a good impression. I liked the questions from the audience and the general feedback. I am looking forward to Part 2 as there will be less theory and more practical examples with some tooling.</p> <p>All updates and announcement are available on IIBA\u00ae Belarus Chapter LinkdeIn page.</p>","tags":["Webinar","Youtube","Slides"]},{"location":"api-requirements-webinar-iiba-part-1/#rus-webinar-recording-on-youtube","title":"[RUS] Webinar recording on Youtube","text":"","tags":["Webinar","Youtube","Slides"]},{"location":"api-requirements-webinar-iiba-part-1/#eng-slides","title":"[ENG] Slides","text":"","tags":["Webinar","Youtube","Slides"]},{"location":"api-requirements-webinar-iiba/","title":"26.10.2023 Webinar \"Requirements & API. Part 1\" for IIBA Belarus","text":"<p>I am proud to announce that I am hosting a two-part \"Requirements &amp; API\" webinar for the IIBA Belarus Chapter.</p> <p>Part 1 will happen on October 26 at 18:00 (GMT+2) - a LinkedIn event link. The second part will come two weeks later.</p> <p>That is an online version of the workshop I made in Warsaw this February. There was great interest in the event. However, many folks could not travel to Warsaw for this specific event. So, there was an idea to transition it to online.</p> <p>The Belarusian Chapter of the International Institute of Business Analysis (IIBA) kindly provided their platform to reach a wider audience. That also means that I will do my speech in Russian so that it won't be for English-speaking audiences. But all materials will be in English, and I will publish them here on my blog. There is also an idea to make an English version of the webinar. We will see how it goes.</p> <p>It was a challenge to convert a 4-hour-long workshop with a lot of practice. I had to eliminate the practical task as I had yet to find an easy way to adapt it to the online format. But I will cover some cases from there.</p> <p>API is a vast topic, so there will be two parts:</p> <ul> <li>Part 1 will be more theoretical to give the basic notion of the discussed topic.</li> <li>Part 2 will be more practice-oriented, where we cover tools and approaches to define APIs.</li> </ul> <p>The webinar is largely based on my API Design series, which I have worked on throughout this year. Most likely, I will re-write some parts after.</p> <p>There will be a recording so that I will share it as soon as possible.</p> <p>Stay tuned!</p>","tags":["Webinar"]},{"location":"backward-compatibility/","title":"Breaking changes & Backward compatibility","text":"","tags":["API Design","BA & PO"]},{"location":"backward-compatibility/#breaking-changes-backward-compatibility","title":"Breaking changes &amp; Backward compatibility","text":"<p>I learned what backward compatibility means regarding software engineering when I started working on microservices. When you are responsible for services widely used by other teams inside and partners outside, you most likely become paranoid about maintaining backward compatibility of your API as much as possible. Especially when it is a  highly volatile environment with rapidly growing functionality and direction changes on the fly.</p> <p>At some point, I invented the term \"backward awkwardability\" - an awkward feeling while telling consumers that there are breaking changes in a new release, so they have to migrate. If your team does it frequently, they will say something like, \"C'mon guys, you introduced breaking changes just a few iterations before! What's going on?\"</p> <p>Let's talk about backward compatibility and how to deal with the breaking changes in terms of API.</p>","tags":["API Design","BA & PO"]},{"location":"backward-compatibility/#breaking-the-broken","title":"Breaking the broken","text":"<p>Maintaining backward compatibility means newer versions will keep the application's existing functionality intact. A recent version can contain bug fixes, improvements, or new features. But all previous components are working as expected, and no efforts are required to bring them back to work after the update.</p> <p>Breaking backward compatibility means you obligate your consumers to make efforts so they can retain the functionality they are already using. It is not the same as regression. The latter implies degrading the current customer experience due to newer changes. But that usually happens unintentionally because of a lack of quality assurance and fixed from the developer side.</p> <p>Breaking changes are intentional, and it requires some work to adapt the changes from the consumer side. They already did some job to start using your service. And now, they need to do this exercise again to keep going, and no guarantee that it will not happen again unless there is a written agreement to prevent such cases.</p> <p>Migration is often a non-planned job in the short or mid-term. Consumers are paying a double price: for new and current functionality. We assume that the value should compensate for the efforts.</p> <p>Regarding software development, the efforts are additional work hours to change the source code in compliance with the breaking changes. The cost of such changes may be high: a Business Analyst should assess the impact of changes, a Developer to investigate required changes and implement them, and a Quality assurance engineer to verify them.</p> <p>Let's review a more general example related to User experience. Any drastic changes in how users interact with the system require additional efforts to learn and adapt to how to use the functionality again. It is not critical when it is about moving a button in a direct-2-consumer app (I wanted to use Instagram as an example, but moving a button there might also be impactful). But considering professional and semi-professional software products, such changes will impact productivity resulting in money loss.</p> <p>A frustrated end-user can stop using an app and switch to a competitor. It is more complicated for professional service: you can switch from Figma if they decide to revolutionize the design process in an expected way. For enterprise-level vendors, such a switch might be a costly endeavor. A concerned service can be a vital part of business processes, and it is impossible to drop it immediately and jump to a competitor. Anyway, the cost of switching to another service is always higher than the cost of implementing the breaking changes.</p>","tags":["API Design","BA & PO"]},{"location":"backward-compatibility/#expect-the-unexpected","title":"Expect the unexpected","text":"<p>Is it possible to avoid breaking changes? Yes, technically. Keeping compatibility at any cost leads to an increase in technical debt. Your team will have to implement sometimes non-trivial and not the best solutions to honor their commitments. They also will be very limited in using new frameworks and libraries and major updates of the ones in current use. So you pay the price for maintaining backward compatibility instead of your customers.</p> <p>That strategy may work for conservative industries. The alternative is to regulate the introduction of breaking changes. The regulations depend on the organization's policies and services specifics. In general, it results in API contract terms aligned with consumers.</p> <p>The following questions are considered when \"signing\" the contract:</p> <p>1) Frequency and schedule</p> <p>The organization defines how frequently you are willing to release incompatible versions: per several releases or some calendar period. You aggregate the breaking changes in your product backlog and fire them in a particular release. So consumers can plan their migration activities accordingly.</p> <p>The main issue is to follow that schedule, as there might be business reasons to introduce breaking changes earlier than initially expected.</p> <p>2) Communication</p> <p>It matters how you notify customers about it. The worst option is to send them a link to a Jira ticket with a poor description and a mess in the comments. The best option is to write a comprehensive migration guide. Developers might consider writing such a guide a waste of time, but it is an investment to reduce future support activities.</p> <p>3) Migration support</p> <p>A comprehensive guide will not save you from additional communications: answering questions, helping with the update, and fixing bugs. So be prepared to have a support buffer in your team's capacity. Or even better, super-obvious advice: always have a support buffer.</p> <p>4) Support timeline for previous releases</p> <p>Customers may postpone the update to an unknown time due to various reasons. And they may keep requesting improvements and bug fixes for an older version they currently use. That ends up supporting several releases: moving forward with new releases and producing backports to the previous ones.</p> <p>The backports continuously require more efforts from the team, shifting focus from the future to the past. The more gap you have, the more challenging it is to improve an older version. It is not a trivial task from both a development and testing perspective that can trigger unexpected problems.</p> <p>To fight this, you must include another point in the contract: how long you commit to supporting previous versions. In my practice, there was a case when we supported five previous major releases. That was a solid argument to speed up the update. As we had a 2-week release cycle, the customers had about two months to plan and conduct the update.</p> <p>Frequent updates may not be typical for your industry. That period may vary due to different business contexts. Or you have a good old customer with a fat bank account unwilling to migrate soon. And the senior management will eat you alive if you try to push the unwanted update. That is mainly the organization or program-wide question. You can only support previous releases for a while but can't drop too frequently.</p>","tags":["API Design","BA & PO"]},{"location":"backward-compatibility/#when-the-link-becomes-missing","title":"When the link becomes missing","text":"<p>Maintaining backward compatibility for existing functionality and managing breaking changes is a challenge. And who is responsible for managing that? The answer is rather disappointing -  the entire team in various aspects:</p> <ul> <li>Business Analyst to conduct impact analysis when considering design options. </li> <li>Product owner to communicate with stakeholders. </li> <li>Tech Lead to manage tech debt and overall delivery. </li> <li>Developers follow the agreements and make all that happen. </li> <li>QAs to ensure we don't break something unintentionally.</li> </ul> <p>To finalize that topic, I would like to emphasize the following statements:</p> <ul> <li>When discussing a feature design or a bug fix for such a critical service, always ask yourself and the team if that can potentially introduce breaking changes. Become paranoid, just like me.</li> <li>Ensure all stakeholders, including the team, know the breaking change policy. If you don't have it already, you don't need it. If you need it, start the discussion in your organization.</li> <li>Test Automation is the key to preventing unexpected breaking changes with regression testing.</li> <li>When designing a data structure in general and API request/response format, remember that there will be no chance to change those when your service goes live. It is not possible to elaborate on all questions in advance. But that approach leaves no room for \"will do it later.\" Try to consider all possible options, even if they might be unrealistic. The price for reckless design is the highest price we pay in the industry.</li> <li>Make sure breaking changes are appropriately communicated to your customers.</li> <li>And follow your Contract commitments.</li> </ul> <p>Take care,</p> <p>Ilya</p>","tags":["API Design","BA & PO"]},{"location":"backward-compatibility/#change-history","title":"Change history","text":"<ul> <li>2021-04-26: Initial version published</li> <li>2023-04-04: Second revision published</li> </ul>","tags":["API Design","BA & PO"]},{"location":"definition-of-api-requirements-v2/","title":"Definition of API Requirements","text":"","tags":["API Design"]},{"location":"definition-of-api-requirements-v2/#definition-of-api-requirements","title":"Definition of API Requirements","text":"<p>Requirements definition for APIs is not a standard part of the Business Analysis activities in software development. Usually, API design was a single responsibility of a system architect or a developer, considering implementation subject matter experts.</p> <p>During my BA career, I had to deal with API-specific requirements. I realized that the API layer has stakeholders (aka consumers) who have their needs related to APIs provided by a system-of-interest. And those needs should be analyzed and translated into requirements.</p> <p>The goal of this essay is to give an introduction to the definition of API requirements for my fellow Business Analysts, Product Owner, and Product Managers. I will not discuss technical details and cover API types (REST, RPC, GraphQL, etc.). There are a lot of experts who have done that and did a great job.</p> <p>I will focus on general things, looking at API from the requirements perspective in general. Also, I have mostly worked with RESTful API, which impacts my view on some things.</p> <p>I will not cover a case when you need to integrate with someone's API. That is part of another topic.</p>","tags":["API Design"]},{"location":"definition-of-api-requirements-v2/#when-you-need-requirements-for-api","title":"When you need requirements for API","text":"<p>You don't need to provide any API-specific requirements when there is only one API consumer of your service, and this consumer is a front-end or another service developed within one team.</p> <p>In this case, an API reflects a feature available in the system. And there is only one way how a consumer can use it. You can define a user story describing acceptance criteria with functional, quality (non-functional) requirements and attach UI wireframes. That will be enough for a developer to design and produce an API covering a particular feature.</p> <p>But when more parties consume your APIs, you should consider their needs. We can split those parties into two big categories:</p> <ul> <li>Different teams within your organization.</li> <li>Consumers outside your organization.</li> </ul> <p>They need your API to reach their business goals despite their apparent differences. Each party has its context of usage and a particular integration approach. Thus you need to consider them as stakeholders and address their concerns to provide a great customer experience.</p> <p>You need to draw a clear line: API requirements are not about introducing new or improving current functionality. API is a door to access the functionality, which can be opened in different ways.</p>","tags":["API Design"]},{"location":"definition-of-api-requirements-v2/#terms-definitions","title":"Terms &amp; Definitions","text":"<p>Let us clarify some concepts and align on the terms used in the text.</p> <p>API: translates as \"Application Programmable Interface,\" but that does not give you a key without a Computer Science degree. The main word for my Bachelor of Arts fellows is \"Interface.\" For an analogy, your mouth, tongue, and lungs are verbal communication interfaces.</p> <p>API itself is an extensive term. For now, we need to understand that we are talking about a gateway through which your service communicates with the outside world.</p> <p>API endpoint: a single instance of API with a unique address (URL). Sending a required input to that URL triggers some command within your system and returns an output about a successful result or failure.</p> <p>Example: <code>POST https://ecomplatform/api/v1/purchases/{purchaseId}/cancel</code></p> <p>API call: sending a request to an API endpoint and getting a response.</p> <p>Client: a general term to identify someone or something calling your API.</p>","tags":["API Design"]},{"location":"definition-of-api-requirements-v2/#api-definition","title":"API Definition","text":"","tags":["API Design"]},{"location":"definition-of-api-requirements-v2/#why-what","title":"Why &amp; What","text":"<p>As usual, we need to understand the following things to succeed with the requirements:</p> <ul> <li>Why do we need this?</li> <li>What will it do?</li> </ul> <p>The second question looks like an easy one. API is about passing commands to manipulate data objects of some Entities. The primary activities are Create, Read, Update, and Delete (CRUD) operations, but the devil is in the details.</p> <p>For example, in our e-commerce system, there is the \"Purchase\" Entity and a command \"Cancel\" available for an Entity object. Our API endpoint should cancel a previously made purchase. In a simple view, we need the following:</p> <ul> <li>make sure how we identify a right Purchase to cancel;</li> <li>how we proceed with the cancellation.</li> </ul> <p>Cancellation can mean an actual deletion of that Purchase (bad idea) or an update of a Purchase status with relevant details (good idea). You should be aware of the business logic. Changing a state of an object might trigger a chain of information updates elsewhere in the system, introducing the request logic.</p> <p>The \"Why\" question is more complex. A particular API call can participate in several use cases, each having its context. You might cover every context with one API endpoint or craft the one to rule them all. That is a question of implementation (and risks). But you would better know those use cases.</p> <p>Handling multiple contexts of API usage, even without one organization, is difficult. But when API reaches the outside world, it is almost impossible to consider every use case in which it might be included. You can define the rules, provide some documentation, and hope that will work. Just be prepared for problems where no one expects them to occur.</p>","tags":["API Design"]},{"location":"definition-of-api-requirements-v2/#prerequisites","title":"Prerequisites","text":"<p>The next step is to define what prerequisite of an API call - authentication and authorization:</p> <ul> <li>Authentication is about verifying clients and allowing them to communicate with your service.</li> <li>Authorization is about permission to enable specific clients to make particular API requests.</li> </ul> <p>Usually, an Authentication approach applies to all API endpoints in an instance rather than a specific one. I omit to describe all existing approaches as it is a topic for another essay. For now, let's consider that some API consumers may require a particular method of authentication based on their security restrictions.</p> <p>Permissions can be managed on the system and the API layer. You can define API endpoints doing the same thing but with different business logic or maintain one which considers different roles. Let's return to our e-com example.</p> <p>Canceling a Purchase by a Customer and canceling a Purchase by an Admin are different scenarios. Here we have the same action but with two different contexts. Admin may skip some validation steps required for a Customer in that business logic so that they can cancel a Customer's Purchase in a simplified way. When designing an API endpoint, you need to make sure that dangerous power will be used only by Admins.</p>","tags":["API Design"]},{"location":"definition-of-api-requirements-v2/#api-call","title":"API Call","text":"<p>Now we are ready to define our API endpoint considering the following:</p> <ul> <li>API Contract</li> <li>Request logic</li> </ul> <p></p>","tags":["API Design"]},{"location":"definition-of-api-requirements-v2/#api-contract","title":"API Contract","text":"<p>API contract is an agreement about expected input and outcome between you and the Clients. The Contract is strictly formalized, and clients agree to follow it when they start using your API. The API owner takes responsibility for maintaining the consistency of the Contract.</p> <p>For input, a Client provides a set of required and optional parameters. The Required parameters usually identify an object or a group of homogeneous objects to access or modify them. The optional alters an expected response by reducing the amount of returned data, for example.</p> <p>The Request is also context-bound whether you expect your API to be part of the API request chain or standalone. For example, you need to retrieve a single Purchase. So you need to define an ID to load a Purchase object. Usually, the system provides several identifiers for the same things in different contexts. Let us assume a Purchase entity has a human-readable Business ID and a System ID as a hashcode.</p> <p>Before making a decision, we need to understand how a Client will obtain that ID to make a call. If any other API endpoint does not return the System ID, why would we expect our clients to provide it?</p> <p>Or does the system identify a Purchase directly by the Business ID? We can quickly consider a workaround by making a Purchase search request with a Business ID, extracting a System ID from a found Purchase, and making a call for Purchase details. But now we have a request logic instead of a simple call.</p> <p>For a Response, an API endpoint returns some data. That can be all information about a data object or just a message with a status. There are successful and failed responses. The latter usually returns an error as a code and some message about what has gone wrong.</p> <p>A Response deals with an API model. Understanding that a data model operated by API is not equal to the data model stored in your database is essential. Your API may return a reduced amount of information, skipping purely technical attributes and some sensitive data.</p> <p>Providing expected outcomes is also a part of the Contract. The information should correspond to the client's goals and desired format, even if it differs from the data in the system. That can be localization to a different language, another date format, currency conversion, combining data objects of various entities, adapting data from third-party providers, etc. In this case, a BA needs to deliver a data mapping deliverable.</p>","tags":["API Design"]},{"location":"definition-of-api-requirements-v2/#request-logic","title":"Request Logic","text":"<p>The API request logic may be:</p> <ul> <li>Simple: one call to the Back-end with CRUD operation to a data object of a single Entity.</li> <li>Composite: a chain of calls to one or several Back-end services with several Entities involved.</li> </ul> <p>In the latter case, you should \"orchestrate\" a consecutive or parallel set of API calls. As an alternative, you can expose those calls separately and provide the guideline of how a Client needs to call them.</p> <p>For orchestration, maintaining overall performance and sustainability becomes extremely important. The more steps we have in a sequence, the probability of failure is higher, considering different \"bad\" scenarios such as prolonged response time, messy data, downtime, etc.</p> <p>It is OK when such composite requests consist of 2-3 data retrieval calls. The \"heavy\" requests are too risky and non-maintainable in the mid and long term. When you have more calls with updating data in different parts of the system, you need to revisit the scenario and find another way. It is, without doubt, a technical debt in its essence.</p>","tags":["API Design"]},{"location":"definition-of-api-requirements-v2/#outro","title":"Outro","text":"<p>It is an introduction to such a vast topic as API, so many details have remained overboard. I hope we will cover them in the following materials. Stay tuned!</p> <p>P.S. This a 2nd revision of my first published post. Please read this version, not the original. I will keep it more for nostalgic reasons</p> <p>Take care,</p> <p>Ilya</p> <p>Image by Gerd Altmann from Pixabay</p>","tags":["API Design"]},{"location":"medium-replacing-legacy-3/","title":"Replacing Legacy Part 3 is out on Medium","text":"","tags":["Medium","Legacy Software"]},{"location":"medium-replacing-legacy-3/#my-new-medium-article-for-the-analysts-corner","title":"My New Medium Article for the Analyst's corner","text":"<p>Along with my blog, I have several sources where I publish my materials. Recently, I started posting a new \"Replacing Legacy\" series of articles. That idea initially derived from my BArsawa (a.k.a Business Analysts Community in Warsaw) speech. In its turn, it derived from my lecture about Legacy monolith decomposition I made in 2019 (I will share a link later).</p> <p>I decomposed my speech into two articles, but I got feedback that inspired me to write further.</p> <p>So here they are, in the logical order:</p> <ul> <li>Replacing Legacy. Part 1: Definition, Reasons, Characteristics</li> <li>Replacing Legacy. Part 2: Archeology, Politics, Red Flags</li> <li>Replacing Legacy. Part 3: Conversion &amp; Data Mapping</li> </ul> <p>Parts 4 and 5 are coming soon. Later, I will revise and combine all articles into an essay and publish it here.</p> <p>If you are a Medium user, I would appreciate your following me there. More exciting content is coming.</p> <p>Thank you and take care,</p> <p>Ilya</p>","tags":["Medium","Legacy Software"]},{"location":"my-learning-path-toward-api/","title":"My Learning Path Toward API","text":"","tags":["API Design"]},{"location":"my-learning-path-toward-api/#my-learning-path-toward-api","title":"My Learning Path Toward API","text":"<p>Before 2020, I dealt with API as a Consumer with intergration purposes, using only such tools as Swagger UI, Postman, and Insomnia. Since 2020, I have changed my side. And not as an API Producer but one who gives the Producers tools to build APIs. It's about the API Platform.</p> <p>So, back then, I started my journey to learn more about API and Platform design. And it is far from being over. I can say that I know more than an average person with business analysis background about that topic. But I can't call myself an expert anyway.</p> <p>During the recent webinars, there was a question about what I can suggest to learn about APIs. With this article, I address that question but in a different form. Instead of a reading list, I decompose the last three years of my career and describe what I did and keep doing to learn about APIs being an API Platform Product Manager.</p>","tags":["API Design"]},{"location":"my-learning-path-toward-api/#learning-architecture-design-patterns","title":"Learning Architecture design patterns","text":"<p>There is a point in a Business Analyst or Product Owner career when you need to learn Software Architecture basics. I am not mentioning Product Managers as that may be less common for them depending on their industry.</p> <p>Your target is not to replace Architects and do their job. The first intention is usually to start speaking their language. They might be a problematic stakeholder. Knowing their language or attempting to learn it would be an advantage.</p> <p>Also, your target is not to learn every existing pattern. You can start (and finish) with microservices. That is the most popular pattern nowadays.</p> <p>I recommend Sam Newman's \"Building Microservices.\" Even though I read only the first edition (I looking forward to read the second one), it still targets a broader audience. This book is not for everyone, like \"Microservices for Dummies.\" But if you have some technical background or a general understanding, that book will give you an additional perspective on how things work under the hood.</p> <p>There may be more exciting and easy-going books about Software Architecture for business people. But I read that one, and I liked it.</p>","tags":["API Design"]},{"location":"my-learning-path-toward-api/#learning-rest-api-from-the-documentation-perspective","title":"Learning REST API from the documentation perspective","text":"<p>When onboarding a new Business Analyst or a UX Designer to my team, I first advise (strongly) to pass Tom Johnson's \"Documenting APIs\" course. Yes, it is for technical writers, but that makes it brilliant by looking at APIs from another, not a development-specific perspective. If you are a BA and want to learn about API, go no further.</p> <p>I recommend studying Chapters 1-5. The later chapters focus on tech writing details. But I encourage you to go through it out of curiosity. That is a good investment of your time.</p> <p>The course keeps growing, so sometimes I revisit old and new chapters. I read the \"AI tools and API documentation\" chapter this week and found it very insightful.</p> <p>Please feel free to buy a coffee for the author. This is the best content on the topic on the Internet, for free.</p>","tags":["API Design"]},{"location":"my-learning-path-toward-api/#learning-openapi-specification","title":"Learning OpenAPI specification","text":"<p>You will touch OpenAPI in the course above, but studying OpenAPI spec on its own is also helpful. It is straightforward advice: read the source materials, not just someone's interpretation or references.</p> <p>OpenAPI Map is a handy way to understand the specification structure and components. You can also open Swagger Editor and start playing around with the Pet Store schema to see how everything works.</p>","tags":["API Design"]},{"location":"my-learning-path-toward-api/#learning-api-development-perspective","title":"Learning API development perspective","text":"<p>I found Sergey Konstantinov's \"The API Book\" when only a few chapters were written. So, my experience was growing alongside that book.</p> <p>It gives a developer perspective on API design, so that might not be an easy reading for people without a corresponding background. Assuming you accomplished all the above resources, I recommend reading Sections I, III, IV, VI. Other sections might be too technical for non-developers.</p> <p>Recently, I read the completed (so far) version of the book. My central insight is that API design is like a rabbit hole; the deeper you get, the deeper it gets.</p> <p>There is a Russian version of the book. For my Russian-speaking folks, I recommend reading that version. I like the language and humor there.</p> <p>You can buy a book on Amazon Kindle and Apple Books to support the author.</p>","tags":["API Design"]},{"location":"my-learning-path-toward-api/#learning-api-management-perspective","title":"Learning API management perspective","text":"<p>\"Continuous API Management\" takes the topic to another level, beyond the development. It talks about running API Programs that consider managing API lifecycle, governance, maturity, and many other things I had no idea about before I read that book.</p> <p>A lot is said about how to develop API, but some time ago, there was not much about how to deal with API programs and products from the manager's perspective. Nowadays, there are API Product Managers with books, podcasts, and courses. But just a few years ago, that was not the case.</p> <p>I read the first edition a few years ago, and the second one is already available. This is an excellent opportunity for me to revisit the book.</p>","tags":["API Design"]},{"location":"my-learning-path-toward-api/#following-some-resources-to-be-on-the-track","title":"Following some resources to be on the track","text":"<ul> <li>Nordic APIs blog to keep a hand on the pulse of the API industry.</li> <li>Apiscene: a lot of excellent materials.</li> <li>Tyk: I closely monitor what these guys do (API Gateway and Platform). They have a great blog and newsletter.</li> <li>I keep reading Habr (RUS), as there are many great articles about APIs. I suggest reading comments as well. REST API topic causes a lot of battles. Sometimes, the comments are more insightful than the article itself.</li> <li>Occasionally, I check what's new with AsyncAPI specification and EDA (Event-Driven Architecture).</li> <li>Erik Wilde's YouTube channel: he is a renowned expert in the API world.</li> <li>The API Experience Podcast: I tried several podcasts about APIs, but this one is the most addictive.</li> <li>Also, I am following the API products I am interested in on Twitter (X, my apologies) and LinkedIn. I read their release notes and marketing materials. That list constantly changes, so it makes little sense to publish it here.</li> </ul>","tags":["API Design"]},{"location":"my-learning-path-toward-api/#developing-api-on-your-known","title":"Developing API on your known","text":"<p>To learn something, you need to make your hands dirty. When I joined the platform, I watched how REST API endpoints are exposed in Java on YouTube. I needed that to understand how developers do that, plus make me more familiar with Java code.</p> <p>My knowledge of Python allowed me to explore how APIs are done in frameworks like Django, Flask, and Bottle. Recently, I tried FastAPI to make a few mock APIs for the recent webinar.</p> <p>Nowadays, it is much easier to ask ChatGPT to explain a topic and generate code examples with a resulting OpenAPI schema. I am not 100% sure the code will be operational, but it is enough for the understanding.</p> <p>Before ChatGPT, I reviewed autogenerated code using open-source libraries by providing an OpenAPI schema and then studied how it is structured. You can easily do it in Swagger Editor by generating a client or server code in the most popular languages.</p> <p>Also, I get familiar with API tooling, whether it is a documentation portal, a new IDL, or a new no-code tool. Considering my very limited capacity, of course.</p>","tags":["API Design"]},{"location":"my-learning-path-toward-api/#afterwords","title":"Afterwords","text":"<p>That list is not a comprehensive guide for your API crash course. I forgot to mention some resources. I am sure about that.</p> <p>What worked for me might not work for you. At least, it will be helpful to expand your knowledge after my webinars.</p> <p>Thank you!</p>","tags":["API Design"]},{"location":"new-mkdocs-blog-version/","title":"New Blog version with MkDocs","text":"","tags":["Blog"]},{"location":"new-mkdocs-blog-version/#new-blog-version-with-mkdocs","title":"New Blog version with MkDocs","text":"<p>In early 2021, at the climax of the Covid-19 outbreak, locked up in the apartment with my wife and 6-month-old kid, I decided to have my blog. I will not dive into the reasoning there. I decided that sharing my thoughts on the media platform I own was a good idea.</p> <p>My initial requirements were:</p> <ul> <li>free hosting</li> <li>own domain</li> <li>control over the content and publishing capabilities</li> </ul> <p>A static site generator, GitHub pages, and a custom domain name cover those points. Having a static site generator benefits in supporting the Markdown syntax, which I am using to write my notes. Plus, it is an additional technical challenge to configure and support that all by myself.</p> <p>So my first choice was pretty obvious...</p>","tags":["Blog"]},{"location":"new-mkdocs-blog-version/#jekyll-era-2021-2022","title":"Jekyll era (2021-2022)","text":"<p>Jekyll\u00a0is a very popular static site generator with multiple plugins and themes. It took me a few days to become familiar with it. My experience with building a test blog project in Django helped me there.</p> <p>It possesses an entire ecosystem where you can do almost everything. And I was happy with that, except for one thing that appeared to be critical: Jekyll is written in Ruby. And I am a Python person.</p> <p>So I found myself in an environment that I was not used to. You don't need to know Ruby to use Jekyll. But I felt uncomfortable while configuring or managing dependencies.</p> <p>So I have made another obvious decision: I need Jekyll but written in Python.</p> <p>Github repo with Jekyll blog</p>","tags":["Blog"]},{"location":"new-mkdocs-blog-version/#nikola-era-2022-2023","title":"Nikola era (2022-2023)","text":"<p>There are enough Jekyll replacements in Python, but none have such a big community and extensive support. So I had to look for something really supported by an open-source community.</p> <p>Nikola\u00a0appeared on my radar, and it seemed to be a good choice. The migration from Jekyll was seamless. I just had to change the URLs of my previous one and configure the redirection. Also, Nikola contains most of the features out of the box, so you don't need to install additional plugins.</p> <p>I was happy with Nikola, and the only thing that made me consider another option: moving away from the blog post format. With the API Design series, I started collecting related essays into sections in a kind of e-book format. Technically, Nikola allows doing that. I just haven't found a theme I need.</p> <p>As I already mentioned, Nikola does not have as much support as Jekyll does. So there are not many themes. Some of them are migrated Jekyll themes. So the only choice was to extend an existing one or create my custom Nikola theme. But I did not want to deal with CSS, Jijnja templates, and other UI stuff.</p> <p>So I decided to consider different content platforms which can easily support my ideas.</p> <p>Github repo with Nikola blog</p>","tags":["Blog"]},{"location":"new-mkdocs-blog-version/#mkdocs-era-2023-now","title":"MkDocs era (2023-now)","text":"<p>I keep an eye on documentation tooling, and\u00a0MkDocs\u00a0has been on my radar for some time. It is based on Python and is more straightforward than Nikola, where I could not remember a CLI command to create a new article in Markdown and sometimes struggled with configuration. Also, it has a built-in search which becomes necessary with growing content.</p> <p>MkDocs is built for project documentation, and that is what I need. And it also has a fabulous\u00a0Material\u00a0theme with a fancy design, dark theme, and many other features.</p> <p>The main challenge has been keeping the blog format as it is not something out-of-the-box. The Material theme provides blog capabilities but as a paid feature. The blog itself is net-negative, so I don't want to spend more than a domain price. So I have found a free alternative\u00a0mkdocs-blogging-plugin. Just a few steps, and the blog is incorporated in MkDocs.</p> <p>However, the content migration wasn't as seamless as it was from Jekyll and Nikola. I had to reformat each post's metadata and headings. Not a huge amount of work - but some routine stuff anyway.</p> <p>Github repo with MKDocs blog</p>","tags":["Blog"]},{"location":"new-mkdocs-blog-version/#whats-next","title":"What's next","text":"<p>I am happy with the current look and plan to explore different themes, plugins, and customizations. MkDocs' configuration is managed via YAML and has already expanded. So I will look for a way to split the configuration and automate adding new sections and pages.</p> <p>Also, I am not sure that MkDocs will be my final choice. There is a particular joy in exploring new things, even when they are static site generators.</p> <p>Take care,</p> <p>Ilya</p>","tags":["Blog"]},{"location":"non-functional-requirements-and-api/","title":"Non-functional Requirements and API","text":"","tags":["API Design"]},{"location":"non-functional-requirements-and-api/#non-functional-requirements-and-api","title":"Non-functional Requirements and API","text":"<p>Previously we discussed the notion of requirements for APIs. Now let's talk specifically about their quality attributes. Or how we can refer to them: non-functional requirements.</p> <p>When we use the term \"non-functional requirements,\" we imply that there should be \"functional requirements\" as well. What is a functional requirement for an API endpoint? Return a response based on the provided input data. It sounds oversimplified, but this is how it is.</p> <p>In detaching API from the functionality, meaning we have a variety of APIs for different consumers, I like an association with a \"door.\" Despite any context, the primary function of a door is to change its state from closed to open and vice versa. The door can be built from different materials, and it can be opened by various means. The opened door can lead to different locations. But its primary function remains the same. We are not considering it as a weapon, even if you hit someone by a door (accidentally, I believe).</p> <p>However, the quality of that door matters, and the same we apply to API. There are dozens of non-functional characteristics, so we only look at major ones.</p>","tags":["API Design"]},{"location":"non-functional-requirements-and-api/#security","title":"Security","text":"<p>A banking term KYC (Know Your Customer) also works for APIs. Whether it is an internal, partner, or public API, we need to do the following:</p> <ul> <li>Onboarding - provide means for a consumer to start.</li> <li>Authentication - identify your consumer.</li> <li>Authorization - manage the access level.</li> <li>Offboarding - terminate consumer access.</li> </ul> <p>We must prevent unauthorized access to our system with API and avoid leaking sensitive information that can damage business and infrastructure. The latter is also relevant for authorized users: we don't want to expose some technical details of how the system works or any data not related to a particular consumer.</p> <p>API is a vulnerable place, so there are dozens, if not hundreds, of books and other materials related to security measures and approaches. Using JWT (JSON Web Tokens) tokens is the most common approach nowadays. I don't cover this extensive topic in this article, so I just suggest some reading:</p> <ul> <li>About a token itself</li> <li>About token types</li> </ul> <p>Security must be an essential part of the Architecture design from the beginning. It should cover everything exposed in the API layer, not just a single endpoint.  </p>","tags":["API Design"]},{"location":"non-functional-requirements-and-api/#reliability","title":"Reliability","text":"<p>What happens if something goes wrong? Getting a successful response is not always the case, so we must consider every possible issue.</p> <p>The first is what we return to consumers: error codes and their messages. API should return a meaningful error message so a consumer can understand what happened and what they should do to get a successful result with the next call. </p> <p>There are 4xx and 5xx HTTP status codes, so you don't need to reinvent the wheel. The best practice is to have an Errors template with common cases such as 401, 404, and 500, with the possibility of extending them with custom errors. The custom errors should still be based on the HTTP status codes, so pick the code wisely.</p> <p>There is a classic case with the codes: if a Search API does not find any result, it should return 404 (Not found) or 200 (OK).</p> <p>One more area is error resilience: what happens if something goes wrong in the request logic? For example, your API call is trying to reach a currently unavailable service. There are several scenarios for the so-called Circuit Breaker:</p> <ul> <li>Throw an error immediately.</li> <li>Try several times.</li> <li>Use a plan B to reach a duplicate of that service after trying several times.</li> </ul> <p>Another issue is with composite API: you should make two requests to aggregate data across different services. One responded, another didn't. Your composite API can return an error. Or it can return partial or even mock data. But remember to notify a consumer that data needs to be completed.</p> <p>A weak point of composite API requests is transaction consistency. When an API endpoint triggers an update operation in several services, an issue may occur if some service does not proceed. Ideally, we have to cancel an entire transaction and re-write the already updated data. But in practice, it may be tricky as those changes appear in the history of system changes, or you simply don't know how to revert it.</p>","tags":["API Design"]},{"location":"non-functional-requirements-and-api/#performance","title":"Performance","text":"<p>Sometimes it isn't easy to separate system performance from API performance. But it becomes a crucial element if we are talking about a separate layer as API Gateway. Acting as a proxy or orchestrator, it must process requests and respond quickly.</p> <p>Performance is another weak point for composite APIs. More internal calls we make than more performance may suffer. We can't control how quickly other services will respond (or will they respond at all).</p> <p>But first of all, we need to understand the criteria to measure API performance: request payload, testing environment, available resources for services similar to production, what we consider as low performance, etc. Performance testing should become a routine, not something done during a release.</p>","tags":["API Design"]},{"location":"non-functional-requirements-and-api/#usability","title":"Usability","text":"<p>Developers who will integrate with your API are your direct users. So you need to care about Developer Experience (DX). For API, it matters to follow the best industry practices, not to confuse the developers, and provide meaningful documentation.</p> <p>API documentation is essential to onboard developers and help them use your API effectively. If they ask you questions, you need to consider further improvements.</p> <p>API docs (API references) can be autogenerated, produced manually, or combined with these two approaches. The key point is to define the required components and the formatting. For example, an API must have a summary with 2-3 words using a verb (\"Make Americano\") and a description with more information (\"To trigger making of a small cup of Americano without milk\"). Every request/response attribute must also have a description and example (\"machineId\" - unique identifier of a remote coffee machine, \"edtu-1234-as34-1234\").</p>","tags":["API Design"]},{"location":"non-functional-requirements-and-api/#maintainability","title":"Maintainability","text":"<p>I would instead call it API contract persistence. Both sides must respect the contract, but only the owner can change it. As soon as your API is published, making changes can be problematic.</p> <p>Deploying an API endpoint and never changing it is not possible. An imperative \"Don't break API contract\" impacts how you will support it. If the initial design is bad, changes will likely introduce backward incompatibility. So if you release a new incremental version, consumers will have to keep up with the changes on their side.</p> <p>I already wrote an essay on that topic (link), so I will not repeat its points. From the quality perspective, we must consider how we will maintain the API in the future.</p>","tags":["API Design"]},{"location":"non-functional-requirements-and-api/#compliance","title":"Compliance","text":"<p>Don't be surprised that API is a subject of compliance. And it is not limited to organization or industry standards. In some cases, especially for finance and health, regulatory standards need to be addressed depending on the region of operation. Here are two sources to dive into that topic:</p> <ul> <li>API compliance</li> <li>Global Open Banking standards</li> </ul>","tags":["API Design"]},{"location":"non-functional-requirements-and-api/#summary","title":"Summary","text":"<p>When defining requirements and design for API, you need to take into account its quality attributes, also known as non-functional requirements in the Business Analysis world. They are usually in the shadow of exciting system functionality. But if not addressed from the beginning, both parties will suffer, one from using that API and another from maintaining it. So let's agree that quality comes first.</p> <p>Take care,</p> <p>Ilya</p>","tags":["API Design"]},{"location":"product-manager-sophomore-year/","title":"Product Manager: Sophomore Year","text":"","tags":["Career"]},{"location":"product-manager-sophomore-year/#product-manager-sophomore-year","title":"Product Manager: Sophomore Year","text":"Toddler Vectors by Vecteezy <p>Last year I wrote a short essay summarizing my first 365 days as a Product Manager. One more year has passed, and it is time to share more insights or learned lessons.</p> <p>Important notice: It is only about my experience, so some things may not apply to what other PMs are experiencing. Product Management is a vast discipline with different responsibilities across different companies and industries.</p>","tags":["Career"]},{"location":"product-manager-sophomore-year/#identity-crisis","title":"Identity crisis","text":"<p>The more I read books or consume other content about Product Management, the more I ask myself, \"Am I even a real Product Manager?\" Sometimes I feel like a Jira backlog administrator, and sometimes like a Project manager who needs to go through and respond to dozens of emails daily and micro-manage to make everything work.</p> <p>There were a few moments when I wanted to switch back to Business Analysis, where I felt safer knowing which tools to use and what I could achieve with them. PM is responsible for everything but usually without any means of power. And the sense of powerlessness is devastating. You see multiple success stories around you and push more, but the outcome remains unchanged. So you start questioning your abilities which affect mental health.</p> <p>But the truth is that you can't build a solid house on sand. You can die heroically doing that but what for? The reasons may be lying outside, and I should not blame myself. Maybe. I know what I am capable of.</p>","tags":["Career"]},{"location":"product-manager-sophomore-year/#people-often-dont-know-what-they-are-doing","title":"People (often don't) know what they are doing","text":"<p>I have naive assumptions that I am surrounded by professionals who know what and why they are doing. Mainly, I have never questioned higher management. I could argue with some decisions but never disagree with a general direction. I thought that the smartest guys in a room with dozens of years of experience and university degrees I only could dream of, knowing what they were doing. In reality, it is not always the case.</p> <p>That also applies to some peers from whom you expect to resolve some dependencies. If your team has an external dependency, you must put extra effort into managing this. It is not only about a schedule but also what and how it will be delivered (if delivered at all). And also, only some people care about mid or long-term consequences.</p> <p>I'm not too fond of the escalation. I want peers to align with each other, commit and follow and respect the commitment. Unfortunately, that is not often the case for various reasons: incompetence, lack of responsibility, and \"hidden agenda.\"</p>","tags":["Career"]},{"location":"product-manager-sophomore-year/#look-outside-and-share-what-you-see","title":"Look outside and share what you see","text":"<p>When you are developing an internal platform, you focus needs of a department or an entire organization. At some point, when we were at a crossroads, I understood that we were unlikely the ones who solely fought a similar problem. We cannot look into other internal platforms, but we can research how open-source and commercial solutions are trying to resolve the same issues.</p> <p>So I started revising any available materials: user and technical documentation, release notes, webinars, etc. I was particular about how they approached the functionality we already have and how they designed solutions we only plan to implement. Then I did a summary and presented it to the team. There were a lot of insights during those sessions. It was not about attempts to \"re-use\" someone's design but more about questioning our past decisions and discussing future ones. That gives additional perspective on many things we have taken for granted.</p> <p>Also, comparing our internal platform with market solutions has triggered revisiting the entire product vision. Ok, this is what those guys are providing - who are we compared with them? We are not competing with them, but the comparison can encourage the team. Something we did better (from our perspective), something we need to learn from them. But we can be proud of what we build, which has some potential to contend in the market.</p>","tags":["Career"]},{"location":"product-manager-sophomore-year/#validate-architecture-design","title":"Validate Architecture design","text":"<p>If I provided enough input with business, functional, and non-functional requirements, I would expect tech guys would design the right architecture without my interference. But now I am sure a PM needs to participate or at least validate an outcome of the architecture design process.</p> <p>I am not talking about doing tech design instead of architects. I don't have expertise in tech design, but now I have enough general knowledge and courage to ask straightforward questions about every aspect of it. Ask questions and challenge them against the business needs that solution will cover.</p>","tags":["Career"]},{"location":"product-manager-sophomore-year/#product-vision-clash","title":"Product vision clash","text":"<p>Product management is not only about producing your own vision but about adapting and nurturing others' vision as your own, from my perspective. PM's vision is not existing in a vacuum, as stakeholders ( especially C and V-level roles) are guiding and impacting it.</p> <p>In Year One, I mentioned taking responsibility for a previous product vision and pushing it further. But at some point, you come up with your own vision, which may not match the management stakeholder's view. And here you whether agree and adopt that vision or continue pursuing your vision, but somewhere else.</p>","tags":["Career"]},{"location":"product-manager-sophomore-year/#afterword","title":"Afterword","text":"<p>And again, I am sharing the negative mostly. It is not all bad. Positive stuff results in all other articles, posts, workshops I am doing, and the feedback I get. That keeps me going. Let's see what this year will bring.</p> <p>Take care,</p> <p>Ilya</p>","tags":["Career"]},{"location":"updates-on-content-strategy/","title":"Updates on Content Strategy","text":"<p>There are some changes in the content allocation across my Blog and other social media platforms. That will impact what and where you will see.</p> <p>LinkedIn: no more articles, more short posts</p> <p>I am no longer publishing any articles directly on Linkedin. There are a few reasons:</p> <ul> <li>LinkedIn is not promoting its native articles enough. I did some research and compared the metrics - LinkedIn articles are getting less traction than the posts. I am not chasing the big numbers, but it is disappointing when people don't see good materials.</li> <li>Native LinkedIn articles are not as good at editing and publishing as other platforms.</li> <li>LinkedIn is more about quick \"Tik-tok\"-like content: short posts and videos, memes, and more generic stuff. It is not a place for longer and more complex articles.</li> </ul> <p>However, LinkedIn will stay as my primary social platform. I will move articles to different platforms but continue publishing links and short posts there.</p> <p>Medium: my new social platform</p> <p>As some of you probably noticed, I published the latest part of the No-code series on Medium (please feel free to subscribe). Now it is a place where I will publish my articles. In a short time, I will migrate there my previous posts as well.</p> <p>The reason is pretty simple: to attract a new audience. Even though the competition there is high, Medium is a better place for a mid-length reading about professional topics.</p> <p>Blog: how it will differ from Medium</p> <p>My Blog will continue to be a central hub for my content. I will continue to publish some pieces as articles on Medium, then revise and transform them into more comprehensive material available on my Blog only.</p> <p>Also, the Blog itself will soon be transformed. I keep exploring my areas of interest:</p> <ul> <li>product management</li> <li>business analysis &amp; product ownership</li> <li>low &amp; no-code</li> <li>API and integration</li> </ul> <p>Each area will be restructured in the way of a continuously expanding e-book. At least, that is how I see it.</p> <p>Instagram: a bit more personal</p> <p>Yes, I have an Instagram account. I am not posting much there. But I will keep re-posting stuff coming from LinkedIn and Medium. Sometimes there will be more personal stuff about my hobbies. You can also follow me there.</p> <p>Twitter: a proxy</p> <p>And I have a Twitter account. Here I am just mirroring the content from LinkedIn and Medium. If you are a Twitter person, you can follow me there to stay tuned.</p> <p>Language policy</p> <p>Last but not least. English is my content's primary language, even though most of my audience is Russian-speaking. Sometimes I will write posts and share valuable materials written in Russian. But that will happen mainly on LinkedIn.</p> <p>Take care,</p> <p>Ilya</p>","tags":["Blog"]},{"location":"backlog-management-about-dependencies/","title":"Backlog Management - About Dependencies","text":"","tags":["Backlog Management"]},{"location":"backlog-management-about-dependencies/#backlog-management-about-dependencies","title":"Backlog Management - About Dependencies","text":"<p>Recently, LinkedIn asked me to share my insights to be eligible for the \"Top Voice\" badge. I realized that I have something to share with my followers in a more extended way than typical (ChatGPT-generated) answers to those top-voice questions.</p>","tags":["Backlog Management"]},{"location":"backlog-management-about-dependencies/#definition-and-classification-of-dependencies","title":"Definition and classification of dependencies","text":"<p>As usual, let's start with the definition, which is rather made on my own. When you need someone to do something so you can do your work, that is a dependency. Postponing the dependency means a delay in delivering your work and the expected outcome, which causes financial losses.</p> <p>Your team/service can have one or several dependencies and be a dependency for someone else. Sometimes it can be both. And dependencies might be temporary when you need something to be done once or permanent when you continuously need something to operate.</p> <p>There can be external dependencies, meaning that you are waiting for something to be done outside your organization. Or that will be done inside your organization, which is an internal dependency.</p> <p>We can distinguish cross-team, cross-stream, and cross-department dependencies, each with its own peculiarities.</p> <p>In my world, dependency means an API or a software library. In your world, that may be anything else, like a vehicle part or a plumber to fix a pipeline leak.</p>","tags":["Backlog Management"]},{"location":"backlog-management-about-dependencies/#dependency-is-a-risk","title":"Dependency is a risk","text":"<p>Obviously, it is the most common and unpredictably dangerous risk. Dependency also means you are limited in control and authority to influence all aspects.</p> <p>You can't eliminate all the dependencies, as a system can't act in isolation. It uses different systems on its level and is also embedded into higher-level systems. There is an entire discipline about that, and I have an essay on a book about it.</p> <p>But if you can proceed without a dependency, you should try. If having an external dependency is economically justified but related to a business-critical part of the system, then it is better to proceed on your own. That is the reason why enterprises do a lot of their stuff in-house, even though it would be reasonable to use open-source or paid vendors.</p> <p>Inside an organization, we should avoid duplicating functionality even though it is inevitable on a big scale. With an internal dependency, you should ask yourself twice whether you need it to achieve your goals and whether you can rely on those who commit to delivering it for you.</p>","tags":["Backlog Management"]},{"location":"backlog-management-about-dependencies/#external-dependencies","title":"External dependencies","text":"<p>There is a simple rule: if an external dependency has no contractual obligations, then it is a void promise. Don't believe a salesperson who promises you a feature to be delivered in Q4. However, having a contractual agreement does not guarantee that a dependency will be resolved in time. Legal obligations are additional motivation, and it is better to have them than nothing.</p> <p>You don't have much authority and control over the outcome from your position as a dependent. You provide clear input and your expectations. Then, you have a right to accept or deny the outcome if that does not satisfy your needs. Losing time and money in case of negative scenarios cannot be fully compensated.</p>","tags":["Backlog Management"]},{"location":"backlog-management-about-dependencies/#internal-dependencies","title":"Internal dependencies","text":"<p>Let's clarify that a contractor's team is an external dependency as it is technically outside your organization. If there is a team that consists of contractors inside your organization, then it is an internal dependency.</p> <p>Compared to external dependency, you have more control and the ability to drive things in your expected way. However, if communication between teams is broken, it will still be a challenge.</p> <p>The main advantage is that you can use administrative leverage: basically, call big guys to press on other guys to make them do what you need in the desired terms. But it may backfire in different ways: put yourself in a vulnerable position for higher management or deteriorate your relationship with folks on \"the other side.\"</p>","tags":["Backlog Management"]},{"location":"backlog-management-about-dependencies/#key-thoughts-on-managing-dependencies","title":"Key thoughts on managing dependencies","text":"","tags":["Backlog Management"]},{"location":"backlog-management-about-dependencies/#transparency","title":"Transparency","text":"<ul> <li>Establish all dependencies in a work management tool you are using (e.g., Jira) with ETA (Expected Time of Arrival).</li> <li>If an external dependency owner has no access to your \"Jira,\" then create a placeholder and keep it updated.</li> <li>Build a dashboard or an Excel spreadsheet to have a comprehensive view from top to bottom.</li> <li>Be able to respond at any time by explaining the current state of affairs for any stakeholders.</li> </ul>","tags":["Backlog Management"]},{"location":"backlog-management-about-dependencies/#communication","title":"Communication","text":"<ul> <li>Keep weekly catch-ups for internal dependencies and bi-weekly for external ones.</li> <li>Define clear acceptance criteria; don't rely on someone else to do it instead.</li> <li>Take time to communicate things that seem to be obvious to you.</li> <li>Take time defining the naming convention to be aligned with terms and their definition; making a glossary is a good option.</li> <li>Remember, you don't have the knowledge and resources your dependency owners do. Otherwise, you would do it by yourself.</li> </ul>","tags":["Backlog Management"]},{"location":"backlog-management-about-dependencies/#timeline-and-commitments","title":"Timeline and commitments","text":"<ul> <li>Consider risks of delay due to dependencies as they are almost inevitable.</li> <li>Consider working in parallel in time-sensitive cases where possible.</li> <li>Define and strictly follow API contracts established between the parties.</li> <li>If you did some work ahead of delivering dependency, be ready to change.</li> <li>If you are a dependency and have a dependency for yourself, don't commit until you confirm the commitments of your dependencies</li> </ul>","tags":["Backlog Management"]},{"location":"backlog-management-about-dependencies/#escalation","title":"Escalation","text":"<ul> <li>Know an escalation path both on your and dependency's side when things go wrong</li> <li>Be quick to escalate.</li> <li>Avoid taking responsibility for what is beyond your control.</li> </ul> <p>Next post with a case study </p> <p>Thread Pattern Stock photos by Vecteezy</p>","tags":["Backlog Management"]},{"location":"barszawa-blog-edition-01-2024/","title":"BArszawa Blog - January\u201924 Edition","text":"<p>In 2023, I became a part of the fantastic local community of business analysts, product owners, and product managers who recently relocated to Warsaw. I soon joined the OrgTeam, and we made about a dozen meetups and coffee talks last year. In 2024, we started expanding our media presence, so now we have a blog with the first post available!</p> <p>\"BArszawa\" is the community title, a combination of business analysis or business analyst abbreviation (BA), and a city title in Polish: Warszawa. It also references the Russian name of the city as well: \"\u0412\u0430\u0440\u0448\u0430\u0432\u0430.\"</p> <p>That all started with a Telegram chat and free events. We plan to try different formats as we see a stable demand for such a professional community.</p> <p>A blog is a part of that strategy. It took a while to find a platform with built-in donations where we can publish for free and sponsor users, and it does not require registration. Despite our events being mainly in Russian (we had one English-speaking event), the blog is in English to attract different audiences.</p> <p>I also initially struggled to find an approach to incorporate that community blog into my writing routine as I am posting on LinkedIn, Medium, X/Twitter (no traction there at all), and here in my blog. Ultimately, I will be an editor responsible for publishing a monthly blog edition.</p> <p>An edition contains an editor's foreword, announcements of upcoming events and other stuff we consider attractive, valuable materials the OrgTeam found during a month, and additional thoughts on various topics related to Business Analysis.</p> <p>It should take little effort to produce such a monthly publication where I am not the only author. So, my current combination of ilyazakharau.com, LinkedIn, and Medium will be the primary focus.</p> <p>Please enjoy the reading here: https://www.buymeacoffee.com/barszawaorg/zatetasexo</p> <p>If you want to join our Telegram chat, a temporary invitation link is here: https://t.me/+39GqbAL0Nu5mM2Yy</p> <p>See you soon as I finalize the fifth and the last part of the Replacing Legacy series.</p> <p>Take care,</p> <p>Ilyz</p>","tags":["BArszawa","Community"]},{"location":"barszawa-blog-edition-02-2024/","title":"BArszawa Blog - February\u201924 Edition","text":"","tags":["BArszawa","Community"]},{"location":"barszawa-blog-edition-02-2024/#barszawa-blog-february24-edition","title":"BArszawa Blog - February\u201924 Edition","text":"<p>I am proud to present the second edition of the monthly newsletter made by BArszawa - the Business Analysis community in Warsaw. In one of the previous posts, I explained what this community is and my role in it.</p> <p>Here is a link to BArszawa Blog - February\u201924 Edition</p> <p>I act as an editor, combining some materials gathered by the Community OrgTeam, writing a foreword, and publishing on different media platforms.</p> <p>Hoping you enjoy that post and find it helpful. Please feel free to share it with your friends and colleagues, support us, and visit us if you appear to be in Warsaw, Poland.</p> <p>Meanwhile, I continue thinking about my free email subscription, but I am still unsure about it.</p> <p>Previous BArszawa materials:</p> <ul> <li>BArszawa Blog - January\u201924 Edition</li> </ul> <p>Take care,</p> <p>Ilya</p>","tags":["BArszawa","Community"]},{"location":"barszawa-blog-edition-03-2024/","title":"BArszawa Blog - March\u201924 Edition is out!","text":"","tags":["BArszawa","Community"]},{"location":"barszawa-blog-edition-03-2024/#barszawa-blog-march24-edition-is-out","title":"BArszawa Blog - March\u201924 Edition is out!","text":"<p>I am happy to introduce the third edition of the monthly BArszawa blog, to which I contribute as an author and editor:</p> <p>BArszawa Blog - March\u201924 Edition</p> <p>Although this resource might be for local business analysts in Warsaw, I am adding a product management and product ownership perspective. </p> <p>So, if you happen to live in Warsaw, we would be glad to have you join one of our events. If not, enjoy this newsletter.</p> <p>Also, I decided to postpone the idea of my newsletter. This commitment seems too heavy at the moment. I enjoy my current writing schedule of about two articles a month. I don't want it to become a job instead of joy.</p> <p>Previous BArszawa materials:</p> <ul> <li>BArszawa Blog - February\u201924 Edition</li> <li>BArszawa Blog - January\u201924 Edition</li> </ul> <p>Take care,</p> <p>Ilya</p>","tags":["BArszawa","Community"]},{"location":"barszawa-blog-edition-04-2024/","title":"BArszawa Blog - April\u201924 Edition is out!","text":"","tags":["BArszawa","Community"]},{"location":"barszawa-blog-edition-04-2024/#barszawa-blog-april24-edition-is-out","title":"BArszawa Blog - April\u201924 Edition is out!","text":"<p>A month has almost passed, so here is a new edition of the BArszawa blog, where I serve as a contributor and editor: BArszawa Blog - April\u201924 Edition</p> <p>What is inside:</p> <ul> <li>Updates about recent offline and online events</li> <li>Announcements of exciting events happening in May (no BArszawa events yet, but that will come soon)</li> <li>Useful materials on a wide range of Business Analysis and related topics</li> <li>Exclusive review of a recent IREB Conference in Warsaw from Olga Rapoport</li> <li>Link to a survey to get feedback on our blog from our dear readers</li> </ul> <p>Previous BArszawa materials:</p> <ul> <li>BArszawa Blog - March'24 Edition</li> <li>BArszawa Blog - February\u201924 Edition</li> <li>BArszawa Blog - January\u201924 Edition</li> </ul> <p>Take care,</p> <p>Ilya</p>","tags":["BArszawa","Community"]},{"location":"firefighting-depencies-case-study/","title":"Firefighting in the Dependency Hell: a Case Study","text":"","tags":["Backlog Management"]},{"location":"firefighting-depencies-case-study/#firefighting-in-the-dependency-hell-a-case-study","title":"Firefighting in the Dependency Hell: a Case Study","text":"","tags":["Backlog Management"]},{"location":"firefighting-depencies-case-study/#disclaimer","title":"Disclaimer","text":"<p>The following case study focuses on dependency management, omitting other details that are irrelevant to the topic or might be sensitive to share publicly.</p> <p>I do not necessarily speak on my behalf. Let's assume some Product Owner (The PO) appeared in such a situation and acted a certain way to resolve the dependencies.</p>","tags":["Backlog Management"]},{"location":"firefighting-depencies-case-study/#background-context","title":"Background context","text":"<p>There are a few details to be mentioned to provide context:</p> <ul> <li>PO joined an ongoing project at its critical stage. Thus, there was no room for cross-organizational changes.</li> <li>PO had a flexible number of responsibilities, which might vary considerably from that of the vanilla Scrum product owner.</li> <li>PO had a great team; it would be impossible without them.</li> </ul>","tags":["Backlog Management"]},{"location":"firefighting-depencies-case-study/#dependencies-structure","title":"Dependencies structure","text":"<p>This is what the team topology looks like, approximately. And that impacted how dependencies are distributed.</p> <p></p> <p>Three organizations are involved, each with their own development teams and management. It is obvious that each side pursues its own goals in accordance with contractual obligations.</p> <p>There are five architecture layers, with a number of teams on each layer. It is not described on the diagram (to keep it simple), but a team within the layer might belong to a different specialization, responsible for one or several microservices. Each specialization has its respective PO, Architect, Delivery Manager, QAs, BAs, etc. They have their own scope, backlog, and priorities.</p> <p>They are, from bottom to top:</p> <ul> <li>The Platform layer provides the core capabilities of a system. It exists outside the project.</li> <li>The Feature layer uses, customizes, and extends the core capabilities.</li> <li>The API layer that exposes RESTful API to be consumed by upstream layers.</li> <li>The Integration layers consume those APIs and provide data enrichment from 3rd party services.</li> <li>The Customer layer utilizes the final output for its own purpose.</li> </ul> <p>Our heroic PO is trapped in the middle, being on the frontline of their organization and managing the API backlog for two teams. We will look at dependency management from that perspective.</p>","tags":["Backlog Management"]},{"location":"firefighting-depencies-case-study/#horizontal-and-vertical-dependencies","title":"Horizontal and vertical dependencies","text":"<p>There are 3-week Scrum sprints, so a feature path through each layer takes much time. From the horizontal perspective, there are some scenarios:</p> <p>1) Core functionality without deviation: starts from the API layer.</p> <p>2) Core functionality with customization: starts from the Feature layer.</p> <p>3) New Core functionality: starts from the Platform layer.</p> <p>The Platform has its own per-quarter release cycle with an option to provide intermediate releases on-demand within a quarter. However, there is an additional buffer time (aka upgrade) to deliver a Platform release and ensure it works with the existing customizations.</p> <p>So, case 3 is more unpredictable and depends on multiple criteria. Case 2 is the most common, so our story focuses on it.</p> <p>Starting from the Feature layers, it takes four sprints (12 weeks) to deliver a feature to the top. Plus, we consider end-to-end testing and other production readiness procedures. So it might take even more time.</p> <p>We also consider the Horizontal dependencies within the team in the same layer. They could work in parallel, but sometimes, they must wait for their peers. So delivery might be postponed even further. </p>","tags":["Backlog Management"]},{"location":"firefighting-depencies-case-study/#shrinking-the-gap","title":"Shrinking the gap","text":"<p>The first step will be prioritizing work based on the above-mentioned scenarios. First of all, the PO decides to identify and prioritize what is already available without any downstream dependencies. Next is what is available from the core but requires customization of the feature layer. And last, what is not present in the core must be delivered by the Platform.</p> <p>Secondly, we need to parallel the work to shrink the delivery timeline as much as possible.</p> <p></p> <p>In this case, it is possible for the API and Integration to work in parallel: the API teams provide an API contract for each future-coming  API endpoint or expected changes for the existing one. Teams can implement based on the contracts but not merge into the main branch.</p> <p>An alternative strategy would be exposing a mock API (i.e., API with mock data). That was a meaningful decision by engineering leads not to merge any mock code. We later discuss what downsides it would cause.</p> <p>At some point, due to some postponements and waiting for new Platform core pieces, three layers are forced to work in parallel.</p> <p></p> <p>The API and Feature layers align on the API contract between them. And that is not the same API contract that exists. So, the PO has to manage two types of API contracts across the parties.</p> <p>An advantage here is that all four upstream layers act as a Platform's customers, so they request a design that does not require customization and skip the feature layer. However, the Platform, having many customers, has the right to provide a generic solution, not a custom feature that suits one customer but another one.</p> <p>Even though they managed to pack an ideal delivery timeline across four technology and organizational layers, the cost is high:</p> <ul> <li>Excessive communication and efforts to manage parallel work.</li> <li>Inevitable reworks and last-minute changes in the API contracts.</li> <li>Communicating and enforcing all parties to keep the API contracts.</li> <li>\"Communal\" testing that leads to multiple bugs.</li> <li>Late coming or missed requirements.</li> <li>Fighting \"who owns what\" as each organization pushes its own agenda.</li> </ul> <p>That parallel work looks pretty good on paper, but that is a fragile construct that is far from smooth operation.</p>","tags":["Backlog Management"]},{"location":"firefighting-depencies-case-study/#art-of-extreme-facilitation","title":"Art of extreme facilitation","text":"<p>The API layer has to identify requirements from the upstream layers and pass them to the downstream for further gap analysis to see whether a query fits one of three scenarios. The API team lacks the specialization knowledge that the Feature team does, and they both lack the Platform knowledge.</p> <p>Being responsible for requirements, the API layer's PO has to communicate vertically between up and downstream to come up with a design that satisfies everyone and the server business needs of the customer. That means bringing everyone to one table and facilitating all parties to be productive and reach a particular conclusion.</p> <p>Along with that, horizontal communication across teams in the same layers must be managed and facilitated as well. Different specializations often cannot align on something without a 3rd party facilitator, and the API folks fit that role.</p> <p>After concluding the design, the next step is to make sure it is prioritized accordingly, both vertically and horizontally, and closely monitor any deviation from the plan. Those deviations are inevitable.</p>","tags":["Backlog Management"]},{"location":"firefighting-depencies-case-study/#what-if","title":"What if...","text":"<p>The PO thinks the main problem is the team structure, which complicates communication. Having five layers, where one layer is a bottleneck, is too far from being effective.</p> <p></p> <p>The Customer layer should merge with the Integration, and API with Features should make the cross-functional dedicated team serve API and core customization within the required specialization. That would require additional training and learning from each other, but it would benefit everyone.</p> <p>The PO thinks that a dedicated API team is bullshit. And I can't agree more after reading the Team Topologies book (I wrote about it here).</p> <p>The Platform remains a constant as it exists beyond the project, and there is not much to do with it from that perspective.</p> <p>The PO would also proceed with mock API instead of API contracts even though it considers some additional development and testing efforts (make a mock, test it, replace it with the actual implementation, and test it again) and risks of forgetting to remove mocks. In the end, maintaining and communicating API contracts takes the same effort, if not more.</p>","tags":["Backlog Management"]},{"location":"firefighting-depencies-case-study/#conclusion","title":"Conclusion","text":"<p>The current case study explores how having multiple layers complicates effective delivery and causes multiple dependency downsides and demanding commitments to the upstream. Any changes to improve the process with good intentions mainly intensify the agony and firefighting to communicate with all parties to resolve dependency in time.</p> <p>The management should carefully structure teams before the project starts and consider some flexibility for further changes down the line. Major restructuring in the late stages would put the project at risk. Decide wisely.</p>","tags":["Backlog Management"]},{"location":"medium-replacing-legacy-4/","title":"Replacing Legacy Part 4 is available on Medium","text":"","tags":["Medium","Legacy Software"]},{"location":"medium-replacing-legacy-4/#my-new-medium-article-for-the-analysts-corner","title":"My New Medium Article for the Analyst's corner","text":"<p>That piece was quite difficult to write. I started it as a more personal story of overcoming burden of moving and adapting business logic from one system to another. I spent multiple days trying to shape and structure but every time that ended up as a whinning on the past experience with no particular clue.</p> <p>So, I decided to follow the formal approach of listing some general difficulties and humble options how to resolve them. If they can be resolved at all.</p> <p>Next time I will try not to overthink for 3 months in a row.</p> <p>Here is the entire series at the moment:</p> <ul> <li>Replacing Legacy. Part 1: Definition, Reasons, Characteristics</li> <li>Replacing Legacy. Part 2: Archeology, Politics, Red Flags</li> <li>Replacing Legacy. Part 3: Conversion &amp; Data Mapping</li> <li>New! Replacing Legacy. Part 4: Business Logic Burden</li> </ul> <p>Part 5 will conclude the series on Medium, but I will still continue elaborating the Legacy replacement topic in another format.</p> <p>If you are a Medium user, I would appreciate your following me there. More exciting content is coming.</p> <p>Thank you and take care,</p> <p>Ilya</p>","tags":["Medium","Legacy Software"]},{"location":"medium-replacing-legacy-5/","title":"Replacing Legacy Part 5 (and Final) is available on Medium","text":"","tags":["Legacy Software","Medium"]},{"location":"medium-replacing-legacy-5/#my-new-medium-article-for-the-analysts-corner","title":"My New Medium Article for the Analyst's corner","text":"<p>I wanted to conclude the Replacing Legacy series with something less practical and more philosophical. Here are my thoughts on why we are at this point of rapid and sometimes senseless replacement or modernization. And what does the future bring us in the face of AI?</p> <p>I did some research for the AI part and felt a lack of knowledge to read scientific papers. Like one about the CARGO algorithm, I mentioned in the article. I really tried, but I cannot fully understand the details. That is a considerable gap to be addressed.</p> <p>I recently bought a course about Product Management in AI, but I am unsure how technical it is. I still don't know how to embed that course into my schedule.</p> <p>Here is the entire series at the moment:</p> <ul> <li>Replacing Legacy. Part 1: Definition, Reasons, Characteristics</li> <li>Replacing Legacy. Part 2: Archeology, Politics, Red Flags</li> <li>Replacing Legacy. Part 3: Conversion &amp; Data Mapping</li> <li>Replacing Legacy. Part 4: Business Logic Burden</li> <li>New! Replacing Legacy. Part 5: Cloud, SaaS Legacy, and AI</li> </ul> <p>If you are a Medium user, I would appreciate your following me there. More exciting content is coming.</p> <p>Now, I am focused on publishing the entire series on my blog in an edited format. I worked on writing all that for over six months and would love to rewrite it altogether. But I don't want to touch this text now. Through some time, I will.</p> <p>Also, I plan to translate the series into Russian to publish on different BA resources. No more details - if that will work, you will soon find out.</p> <p>Last, but not least, I am changing my publishing strategy. I will no longer post exclusive content on Medium like I did with the Replacing Legacy. A new article will be published simultaneously on my blog and Medium. I will promote a link to the blog on LinkedIn and Twitter (X, whatever).</p> <p>The reason is simple: I don't want my content under a paywall like Medium. It doesn't make sense to me as I am not getting any money. Thus, the Medium audience continues getting posts there, as I have a few subscribers. Others can read the blog without mandatory sign-up.</p> <p>Also, I am looking for another form of publishing. LinkedIn has become a shit show and trash can: serious content does not suit there. Maybe an email newsletter (but without news). However, I am unsure about duplicating content across blog, Medium, and email subscriptions.</p> <p>Also, I created an account in BuyMeaCofee. Yes, I will try to monetize my writing. Books are freaking expensive.</p> <p>That is how quickly an announcement about a Medium blog transforms into whining. Sorry about that. And thank you for reading.</p> <p>Stay tuned and take care,</p> <p>Ilyaz</p>","tags":["Legacy Software","Medium"]},{"location":"reading-product-management-in-enterprise/","title":"Thoughts about \"Building Products for the Enterprise: Product Management in Enterprise Software\" by B. Reeves and B. Gaines","text":"","tags":["Career"]},{"location":"reading-product-management-in-enterprise/#thoughts-about-building-products-for-the-enterprise-product-management-in-enterprise-software-by-blair-reeves-and-benjamin-gaines","title":"Thoughts about \"Building Products for the Enterprise: Product Management in Enterprise Software\" by Blair Reeves and Benjamin Gaines","text":"<p>After a long break, I return to book reviews in the form of an internal dialog. That time it is one of the most valuable books I have read about Product management: \"Building Products for the Enterprise: Product Management in Enterprise Software\" by Blair Reeves and Benjamin Gaines.</p> <p></p> <p>OK. I am glad you are finally talking about this book. It is an obvious question, but I must ask it. What this book is about?</p> <p>The title is self-explanatory enough: the book is about being a Product Manager (PM) in a B2B Enterprise organization.</p> <p>Sounds fair. What is so unique about working in the Enterprise compared to other PMs?</p> <p>First, let's agree that Product management is a vast discipline. Every organization looks at it from a different angle. So, a PM's responsibilities and role definition might vary for similar products but from other businesses in the same market.</p> <p>Enterprise PM differs from a startup PM in that the first needs to survive in a complex hierarchy, build relationships, and comply with an Enterprise's restrictions. Also, it depends on whether it is B2B, B2C, B2G, B2B2B, etc. That impacts a lot on how products are developed and sold.</p> <p>I will paraphrase the book to not expand on this topic further. What makes PM in the Enterprise different:</p> <ul> <li>business model: usually direct sales or subscription</li> <li>specialization: very specialized products</li> <li>the split between customers and users</li> </ul> <p>Understood. Is there any story about how you found that book?</p> <p>At some point in my career as a Business analyst, I consumed all materials about Product Management I could only find. I considered buying that book while visiting the biggest bookstore in Dubai, UAE (I spent multiple hours and money there instead of relaxing on a beach).</p> <p>But the book appeared too thin and expensive, so I bought another about product management. And I will write about that particular book very soon as it is worthwhile. A few years later, I bought it on Amazon.</p> <p>Alright. What is the main idea of the book?</p> <p>There are several ideas. The first I already mentioned is that the PM role in the Enterprise is different. They start with a statement that the PM is not the CEO of the product. And I 100% agree. You are executing the vision of the executives or senior management. You might sell them your vision or align your vision with theirs. But you are very limited in power, so you need to choose your tactics and tools wisely.</p> <p>Then, the authors raise an important topic that stands out for B2B: the separation between user and customer.</p> <p>And how does that separation work?</p> <p>Quoting the book, in B2B, another organization hires your product to help it grow. So, who pays is your customer who will use your product according to their goals.</p> <p>End users are far away and sometimes out of touch. Their interests might be different from the ones of the customers.</p> <p>But PM can't just ignore users. They might know customers and their business, understand users' needs, and find a balance.</p> <p>That is challenging. What else?</p> <p>In further chapters, the authors describe 3 types of knowledge for a PM to seek and master:</p> <ul> <li>Organizational knowledge</li> <li>Product knowledge</li> <li>Industry knowledge</li> </ul> <p>OK. Let's start with the Organizational type and then cover others individually.</p> <p>Organizational knowledge\u00a0is about how to work with internal teams, marketing, sales, and executives.</p> <p>Ultimate PM's goal is to drive alignment across teams in complex organizations. You can't do everything alone inside your team and department. You must cooperate with other people from different divisions. That might be extremely difficult as some of them might give a shit about what you are doing and have their own, sometimes contradictory, agenda. It can be seen as fitting pieces of a puzzle that do not fit.</p> <p>Also, the PM is involved in Politics, which is inevitable. So, you need time (a few years) to learn how to navigate that environment and build relationships and trust with the support you need.</p> <p>Feedback loops and delivery in Enterprise are prolonged compared to startups. You need to know the process and the shortcuts to become efficient as a PM. If you don't have the right background and existing connections for a new job, working one year or less is not enough to make a prominent impact. You need more time to acquire all the tools and the remaining types of knowledge to deliver results.</p> <p>Product knowledge\u00a0is pretty straightforward, as PMs must know their product or products. It would help if you learned it in a way your customers and users do to build empathy with them.</p> <p>The authors suggest that PM should also have a basic understanding of how the system behind your product works - basic architecture. That really helps to understand limitations.</p> <p>You need to understand the product lifecycle, where your product is, and how the development process goes with all nuances. Also, the PM must clearly communicate product release information so the customer understands how new functionality could be valuable to them (see, not talking about users there).</p> <p>Industry knowledge\u00a0is the most crucial and the most difficult to get. It would help if you had a lot of time to understand your market. Not only one market but also related markets as well.</p> <p>You need to know your typical customers, their use cases, and their problems. Plus, you need to know how to sell it.</p> <p>It is essential to have a good knowledge of your competitors. But at the same time, avoid becoming obsessed with them and competition in general.</p> <p>And it would be best if you kept running. Constantly. Keep tracking and learning to get some market insights and understand how other markets are impacting yours, as they are not in isolated silos.</p> <p>Challenge your knowledge, as industry experts might be wrong. The authors give a great example. I also witnessed when, 10 years ago, only some people believed big Enterprises would move to the Cloud. But we now see that it has happened.</p> <p>Got it. What are you overall feeling about the book?</p> <p>I am very upset when I don't see that book in different tops of the Product management books. It is a hidden gem.</p> <p>This is not a giant book, but it contains a lot of valuable concepts. It is not an ultimate guide: it will not teach you to build roadmaps and research a market. But that is not the purpose of the book.</p> <p>The first time I read it was when I was a Business analyst who wanted to become a Product manager. As I have always worked on Enterprise projects, the book resonates with me. All other sources were mainly about B2C and startups in particular. And even then, I felt it does not match well with enterprises.</p> <p>The second time I read that book, I had already been in a PM position for several years.</p> <p>I refreshed my memories, found new insights, and changed my attitude to some given advice as I know I have some experience in that field as well.</p> <p>So, I recommend that book to future and current PMs to better understand how to navigate the Enterprise world and B2B and its variations in particular.</p> <p>Thank you and take care,</p> <p>Ilya</p>","tags":["Career"]},{"location":"replacing-legacy-blog-edition/","title":"Entire \"Replacing Legacy\" series is available on the Blog","text":"","tags":["Legacy Software"]},{"location":"replacing-legacy-blog-edition/#entire-replacing-legacy-series-is-available-on-the-blog","title":"Entire \"Replacing Legacy\" series is available on the Blog","text":"<p>For those who are not Medium fans, I've packed the Replacing Legacy series into the long read available on my blog.</p> <p>There are some slight differences from the original: some passages have been edited, and others have been removed. Text is now more straightforward, but there are still a lot of places for improvement.</p> <p>Now everything is in one place. I hope you enjoy reading.</p> <p>And a few more updates:</p> <p>-&gt; I keep experimenting with formats and media platforms. Now, I will no longer publish unique content on one platform, like I did with the above-mentioned series on Medium.</p> <p>I will simultaneously post on Medium and my blog. On LinkedIn, I publish a link to the blog with a short summary. So there will be a choice of where to read. And I will not spend time again migrating content from one place to another.</p> <p>I am unsure about maintaining LinkedIn Articles, as last year's experience was not the best. The traction was minimal compared to a usual post.</p> <p>-&gt; The blog changed the look and feel a bit. I migrated to a built-in blog plugin of the MkDocs Material. Before, it was available only for sponsors. But now it is free for everyone.</p> <p>I spent the whole weekend migrating and testing. Even though there are some minor issues, I am delighted with the result.</p> <p>-&gt; If you visit my blog, you will see a link to the \"Buy Me a Coffee\" page. Yes, one more content creator is begging for money. Anyway, this is another way to express your gratitude to the author. </p> <p>If there is anything, I will spend them on books. Good books are freaking expensive nowadays\u2014especially those I want to read.</p> <p>-&gt; I am planning my email newsletter, so there will be a pilot by the end of  February. Why do I need another platform? Because (you won't believe me) there is life outside LinkedIn. I want people to reach my content not only with LinkedIn and Medium.</p> <p>The newsletter subscribers will get some extra: I spend a lot of time researching different tools for backlog management, system analysis, APIs, etc., and I will share my insights there for free.</p> <p>As always, stay tuned and take care!</p>","tags":["Legacy Software"]},{"location":"requirements-api-analysis/","title":"A new part of Requirements & API - Analysis is available!","text":"<p>Last month, I started summarizing all my API-related posts, workshops, and webinars into extended and structured reading. That is usually a part of the Essays section, where you can find my recent Replacing Legacy series.</p> <p>Reflecting on my past materials about API, I realized they were disconnected and lacked a logical narrative. However, I am proud to share that I am starting anew, from simple concepts to in-depth reviews of various Interface Definition Languages, showing significant improvement in my approach.</p> <p>The new chapter, \"Analysis,\" focuses on business analysis and aspects of requirements engineering. That was tough to write and edit, cutting pieces that did not fit and made text difficult to comprehend. Hopefully, I will get a satisfactory result.</p> <p>Previous chapters:</p> <ul> <li>Definitions, the best place to start the journey.</li> <li>Glossary that I keep up-to-date with terms and abbreviations.</li> <li>The index page is where you can find a plan for future topics.</li> </ul> <p>At the same time, I am publishing it on my Medium to reach a broader audience. I would appreciate your support there.</p> <p>Next time, we discuss HTTP protocol and API structure using OpenAPI as a reference.</p> <p>Stay tuned and take care,</p> <p>Ilya</p>","tags":["Requirements & API"]},{"location":"swebok-v3-v4/","title":"SWEBOK v3 and v4 - Software Requirements","text":"<p>SWEBOK Guide, by its nature, is similar to other Bodies of Knowledge (PMBOK, BABOK, etc.) and stands for the Guide to the Software Engineering Body of Knowledge. It is not a standard but a guide that defines the scope of software engineering as a discipline (that is important to address). It outlines Knowledge Areas described in terms of its component processes, practices, inputs, outputs, tools, and techniques. Those areas are representations of the discipline at a particular moment.</p> <p>Of course, Software engineering can't ignore such a massive topic as requirements. So it contains a dedicated chapter, or, in SWEBOK terms, knowledge area (KA)  \"Software Requirements\".</p> <p>I started learning about industry standards and Bodies of Knowledge a few years ago. So I went through SWEBOK Guide v3, published in 2014, to review existing KAs focusing on the \"Software Requirements.\"</p> <p>The 4th version is in the public review and will replace v3 soon. This article compares the Software Requirements chapter, my domain of interest, between newer and current versions. And there is what to compare. But let's go back to v3.</p> <p>And there is not much there. The KA heavily relies on an older edition (2nd) of the \"Software Requirements\" by Karl Wiegers and just a few other well-known sources. And the chapter itself is about 18 pages long. The Guide should not provide extensive information about a particular topic but should give an overview and further references to study.</p> <p>However, the provided information is insufficient to give an overview of such an essential piece of software engineering. Moreover, it struggles to offer a structured categorization of requirements types and a comprehensive overview of requirements practices.</p> <p>I am not criticizing; I am expressing my feeling that not enough attention was given to that part of SWEBOK. And written in 2014, it quickly became outdated.</p> <p>I read it for the first time in 2020, and RUP (Rational Unified Process) has already been dead for a while. I barely heard about practicing RUP in 2014 because Agile methodologies were on the hype train then (and claimed to be dead soon, too). A newer generation of IT folks has no idea what it is.</p> <p>I could not recommend SWEBOK Guide v3 to start your journey to the requirements engineer or business analysis. Even at the moment of 2014, there were better sources and materials. This KA looks unarticulated compared to the further KAs.</p> <p>The good news is that v4 has done everything right!</p> <p>In 2024, I started revisiting the standards BOKs, researching some topics for future articles. For the sake of curiosity, I have looked into a draft version of SWEBOK Guide v4 (2024 Jan 16th Public Review Version). And I am surprised in a good way. The \"Software Requirements\" KA has been completely rewritten and extended. </p> <p>I am not going to dive deep into reviewing each point. You can easily read the document and make your conclusion. And we need to consider that it is still not a final version, and some changes are expected. However, I don't expect much will change: IEEE (Institute of Electrical and Electronics Engineers) folks and KA editors have done a great job.</p> <p>Let's see what v4 has done right compared to v3: </p> <p>1. Number of references</p> <p>The KA is now 24 pages long and references 29 different sources, Compared to 9 references in v3. And I found a lot of unknown materials I would like to become familiar with. These sources give different perspectives on different aspects of the topic. There are still classical sources but with a newer edition: K. E. Wiegers and J. Beatty, Software Requirements, 3rd edition, and I. Sommerville, Software Engineering, 10th edition. But there are also more recent works, such as up-to-date ISO/IEC/IEEE standards.</p> <p>2. Consistent text</p> <p>Despite an increased volume and number of references, the text feels consistent, comprehensive, and easier to digest than its predecessor. Thanks to the editors who combined those pieces altogether.</p> <p>3. Explanation of what Requirement means</p> <p>The v4 has a better and more comprehensive Definition of Software Requirements, considering the complex nature of the definition itself.</p> <p>4. Categorization of Requirements</p> <p>Neither v3 nor v4 deal with such terms as business and stakeholder requirements. I wrote about the ambiguity between business and stakeholder requirements. So they decided not to mess with that.</p> <p>Even though both versions define stakeholders, they do not introduce a specific requirements type. Stakeholders act as a source of requirements, and that might make sense.</p> <p>Also, in v4, there is a line that software project requirements are sometimes called business requirements. It is arguable, but I am still processing and looking for references to understand the reasoning.</p> <p>Overall, the Requirements categorization in v4 makes more sense than in v3.</p> <p>5. Non-functional requirements They are splitting non-functional requirements into Technical Constraints such as choosing a programming language, framework, database, and more traditional Quality of Service constraints.</p> <p>6. Why Categorize Requirements This Way?</p> <p>A section called \"Why Categorize Requirements This Way?\" provides a great explanation of the provided categorization. I like the phrase from there concerning non-functional requirements: </p> <p>Large systems often span more than one subject matter area, or domain. As explained in [S. Tockey, How to Engineer Software, Hoboken, NJ: Wiley, 2019., c6], recursive design shows how non-functional requirements in a parent domain can become or can induce, functional requirements in a child domain.</p> <p>I observed that one many times, but I read about it only there.</p> <p>7. Derived Requirements</p> <p>v3 mentioned \"Emergent properties\" and that some requirements come from different components dependent on the system architecture. The v4 explains that concept better with \"Derived Requirements\": </p> <p>to mean a requirement that was not made by a stakeholder external to the overall project but that was imposed inside the larger development team.</p> <p>Here is an essential separation of the software and system requirements, as a system might mean something bigger that includes software.</p> <p>8. Let's talk about economics</p> <p>The \"Economics of Quality of Service Constraints\" section is part of Requirements Analysis practices. That is frequently overlooked in business analysis materials: the costs of reaching some high level of quality might not be economically justified. And that is what we all should keep in our minds.</p> <p>9. The Specification way</p> <p>The \"Requirements specification\" section is greatly expanded. It asks a question to what extent the requirements should be documented and further covers the following approaches:</p> <ul> <li>Unstructured Natural Language Requirements Specification</li> <li>Structured Natural Language Requirements Specification</li> <li>Acceptance Criteria-Based Requirements Specification<ul> <li>acceptance test-driven development (ATDD)</li> <li>behavior-driven development (BDD)</li> </ul> </li> <li>Model-Based Requirements Specification</li> </ul> <p>And so on...</p> <p>There is an entire new section, \"Requirements Management Activities,\" that was not present before, and many other minor changes. As I mentioned, the Software Requirements KA has been completely rewritten. It reflects the current requirements, processes, and practices. However, it does not mention AI engagement in the requirements engineering. It may not be in v4, as we still need to elaborate on the methodology and best practices here.</p> <p>But there is another question: Is ten years between versions of BOK or standard not too much?</p> <p>I think it is. With rapid AI development, the landscape is changing too fast. It may fail the hopes the blockchain did after all the hype it had in 2017. But staying ten years in limbo is not an option anymore.</p> <p>But anyway, I want to thank everyone who worked on the Software Requirements KA for doing a great job.</p> <p></p> <p>Take care,</p> <p>Ilya</p>","tags":["BOK"]},{"location":"team-topologies/","title":"Thoughts about \"Team Topologies\" by Matthew Skelton and Manuel Pais","text":""},{"location":"team-topologies/#thoughts-about-team-topologies-by-matthew-skelton-and-manuel-pais","title":"Thoughts about \"Team Topologies\" by Matthew Skelton and Manuel Pais","text":"<p>This time, let's talk about \"Team Topologies: Organizing Business and Technology Teams for Fast Flow,\" a book about organizational design written by Matthew Skelton and Manuel Pais.</p> <p></p> <p>Looking at the title, this book is not about product management or business analysis...</p> <p>Yes, you are right. This book is about constructing teams and establishing their interactions. It is not about my day-to-day work, but it is an area of my concern. I tend to read general books about management more and more. So we will discuss more such books in the future.</p> <p>How did you find out about \"Team Topologies\"?</p> <p>I heard about it during the Platform Engineering fundamentals course brought by Tyk (I have a fancy certificate, by the way). There were a lot of references to that book, so I decided to add it to my reading list. It is funny, but \"Team Topology\" references many other sources but combines them into a solid idea.</p> <p>The book basically addresses the most common problem, probably on the humanity level.</p> <p>What kind of problem do you mean? We have plenty of those.</p> <p>Communication. The lack of it, to be precise. </p> <p>It is the most crucial aspect of any organization, but we discuss software development here and in the book. I have almost a decade in the industry, and how communication is defined within an organization causes the most severe problems. That is why the team structure, or topology, is so important.</p> <p>And the book addresses that: not answering all questions (no silver bullet), but giving guidance at least. </p> <p>Ok. What is the main idea of the book?</p> <p>We should build the system architecture and then define the team structure using specific principles. Also, while the architecture evolves, the team topology should also evolve to address the changes.</p> <p>Key takeaways:</p> <ul> <li>Four fundamental team types:<ul> <li>stream-aligned</li> <li>platform</li> <li>enabling</li> <li>complicated-subsystem</li> </ul> </li> <li>and three core team interaction models:<ul> <li>collaboration</li> <li>X-as-a-service</li> <li>facilitation</li> </ul> </li> </ul> <p>The current issue is that managers are building the organization structure, architectures are designing systems, and in the end, those things do not match well with each other. Those sides usually don't interact mostly because they are structured to exist in silos.</p> <p>That is all about Conway's law, which states that organizations build systems similar to their communication structure (my interpretation). So no matter how good your new design is, if your org structure is not flexible to adapt it, you are fucked doomed anyway.</p> <p>Also, take into account the rising complexity bar with cloud, microservices, DevOps, and now AI on top of that. The approaches that worked for ten years with dedicated front-end teams, who interact with back-end teams and who interact with database administrators, are not working anymore. You can still develop software in the old way, but that does not allow you to compete with big guys.</p> <p>So the book suggests utilizing, quoting:</p> <p>... \"inverse Conway maneuver\" (or reverse Conway maneuver), whereby an organization focuses on organizing team structures to match the architecture they want the system to exhibit rather than expecting teams to follow a mandated architecture design.</p> <p>Skelton, Matthew; Pais, Manuel. Team Topologies (p. 40). IT Revolution Press. Kindle Edition.</p> <p>The team interaction models areus, plus I don't want you to retell the book. Let's touch on the team types. The platform is evident here, but the remaining is not.</p> <p>Platform team is my specialty, but we should start with Stream-aligned teams, which might also be called \"domain\" or \"capability\" teams. They are working on something that generates revenue. The critical question is how to define those streams and domains and correctly split the teams. Again, there is no universal answer here. However, we can use the concept of cognitive load and some other techniques described in Chapter 6.</p> <p>And one more important fact: we are talking about cross-functional teams that have every competence they need to do their job: back-end, front-end, DevOps, etc</p> <p>A Platform provides an easy-to-use service around stream-aligned teams to reduce their cognitive load. It is a vast topic, and I prefer to write a separate article about it someday.</p> <p>Enabling is a consultancy service: very high-skilled folks appear to bridge the knowledge gap in a particular team for a limited time. And these are the full-time folks.</p> <p>And complicated subsystems: there might be systems and technologies that require a very narrow and specific knowledge, resulting in a special team to address those particular areas.</p> <p>That all sounds straightforward. Why are organizations still suffering, then?</p> <p>Due to various reasons. One of them I already mentioned: different people are building organizational structures, and another is designing systems. And they do not talk with each other. In turn, that creates bottlenecks that are almost impossible to resolve.</p> <p>And what I see from my practice is that DevOps as a separate unit is always a bottleneck, at least in the organization I worked with. Separated UX designers might also be a bottleneck if teams wait until they draw you UI mockups.</p> <p>Also, chaotic team communication adds a lot along with cognitive load. The book mentions that there should be a team's API: the described written way of what resources they own, what documentation they provide, and how to communicate with the team.</p> <p>Ownership itself is a critical topic. If no one owns something, then no one owns it. That isn't good, especially when we are talking about code.</p> <p>So many aspects should be considered, but the focus should be on the team first.</p> <p>That makes sense. I usually quote Ed Catmull from Pixar, who said that a brilliant team can take a mediocre idea and make something extraordinary.</p> <p>Right. There should be a team-first approach. All should be focused on achieving team goals, not evaluating individual contributions. I feel stupid when I am forced to set up individual OKRs. Achieving team goals is the only thing that matters. A team matters more than individuals.</p> <p>Ad-hoc changes, headcount deduction, and other \"re-structurization\" eliminate the team's ability to deliver software effectively. I observed how bad organizational decisions almost destroyed great teams and even software. So, not only building but preserving an effective, empowered, and motivated unit is the most complex task.</p> <p>Last question: to whom do you recommend reading this book?</p> <p>I recommend that book to people who see that the organization has good professionals and looks like a reasonable process, but that all does not generally work. So basically, everyone who has \"manager\" in their title should read the book.</p> <p>Again, it does not provide all the answers, and some points could be argued. But the book can give you food for thought if you seek an answer on how to build an efficient organization to deliver software in a highly competitive environment.</p> <p>Software development shifted in the wrong direction when managers with a background in traditional industries came there. They tried to adapt the manufacturing approaches and principles. Thus now we have a lot of software which is shitty and unreliable.</p> <p>I consider software as a piece of art, and building it requires tremendous creativity from organized groups of people. But the difference with traditional art is that software is delivered immediately (and provides some real value rather than aesthetics only). That is why different approaches should be applied there.</p> <p>We made a step forward twenty years ago with the Agile Manifesto. Nowadays, we are a few steps back from where we expected to be.</p> <p>Take care,</p> <p>Ilya</p>"},{"location":"writing-routine/","title":"About My Writing Routine","text":"","tags":["Blog"]},{"location":"writing-routine/#about-my-writing-routine","title":"About My Writing Routine","text":"<p>Here is my writing routine: the way how I structure my research on various topics and then write an article.</p> <p>It is not my usual type of content, but it might be helpful to someone. And yes, I need to fill the vacuum while working on two new writing pieces: a book review and a new topic.</p>","tags":["Blog"]},{"location":"writing-routine/#writing-tools","title":"Writing Tools","text":"<p>I use Obsidian as a knowledge base and content management. It is free, keeps your data in your hands, not in a vendor cloud, uses Markdown for formatting, and has a variety of great plugins.\u00a0</p> <p>The latter is handy as my blog\u00a0is also built\u00a0with the MkDocs engine based on the Markdown format. So, I keep writing and editing in Markdown, which is very convenient. I don't particularly appreciate it when each tool tries to reinvent the wheel with its custom formatting, which is incompatible with anyone else. With Markdown files stored on my local machine and my cloud storage, I can quickly grab them and migrate them to another tool.</p> <p>I use the Zettelkasten technique in Obsidian when I research something and need to document some information and my thoughts to reference it later. You can find a lot of information about this approach. I keep my notes connected with tags and internal references where possible. Obsidian provides a nice graph where I can filter out some notes and track references.</p> <p>Once a year, I clean up by editing, merging, or even deleting some notes. So, I try to keep the number of my Markdown notes from spreading. You can see a part of the notes graph in the attached image below.</p> <p></p> <p>I still use Notion, even though its performance problem a few years ago forced me to try Obsidian and stay with it. I don't synchronize my notes between Obsidian and Notion, as I use them for different cases. Obsidian doesn't have built-in databases like Notion does. Even though there are community plugins to address, I keep Notion for that purpose.</p>","tags":["Blog"]},{"location":"writing-routine/#writing-process","title":"Writing Process","text":"<p>When I start to work on an article, I combine my thoughts, ideas, and relevant Zettelkasten notes in Canvas. It is a recently added Obsidian feature that is a mind map you can combine from new and existing notes. I waited long for someone to implement that by uniting a knowledge base and mind maps.</p> <p>I used to start writing in a separate MD file, but the more complex topics appeared, the more time I spent on editing and restructuring. Now, I structure everything in Canvas, reshuffling pieces of content to have a logical and straightforward narrative.</p> <p>Below, you can find images of how my recent API article and upcoming writing about Composability looks like in Canvas. I also started copying articles I gathered to prepare material to keep everything in one place. That really helps to focus.</p> <p></p> <p></p> <p>In the next step, I finally put everything in a single document and proceed with a first round of editing, literally \"adding meat to the bones.\" Then, I use Grammarly to help edit and fix spelling and syntax issues.</p> <p>I pay yearly for a Grammarly Premium subscription, and I am delighted about that. Before, I spent a lot of time editing and fixing issues, and now that has gone.</p> <p>I tried ChatGPT for editing, but the styling and word choice usually concern me. My specialization was Literary translation at the university. Thus, I know a bit about the topic and what I consider my writing style. And \"delve\" is not a part of it, sorry. So, I stay with Grammarly as a happy customer.</p> <p>Back to track. I do two rounds of editing with Grammarly to clean up the text. In parallel, I search for images or draw diagrams by myself. I use Lucidchart because I have a license from work, but I can also switch to draw.io anytime.</p> <p>Then, I combine a draft and\u00a0usually\u00a0ask my wife to read a piece before publication. She is not an expert in the domains I am writing about, but her linguistic capabilities exceed mine. So she can say what sounds too incomprehensible and whether the text is OK.</p>","tags":["Blog"]},{"location":"writing-routine/#publishing","title":"Publishing","text":"<p>I push an MD file with a new article to a GitHub repository with my blog, so in a few minutes, it is available. Then I go to Medium and automatically import my new article there. It works flawlessly, so I have to do a little editing.</p> <p>If I send my Medium article to the Analyst's Corner, some time\u00a0is required\u00a0for a review and publishing, but not so long.</p> <p>Then, it's time to write a post for LinkedIn with a link to my article. And that is it. I tried to post that on Twitter and Instagram but then dropped. They are not my platform because I like to write long texts or don't know how to work with them (or I simply don't care).</p> <p>Ultimately, I relax watching LinkedIn, Medium, and Google Analytics stats on my blog. The Medium audience is steadily growing, and that makes me happy. LinkedIn is also doing fine.</p> <p>That is my writing process in a nutshell. If this post gets enough traction, I will share some tips on using Obsidian in my day-to-day work as a product manager next time.</p> <p>Stay tuned, and take care!</p>","tags":["Blog"]},{"location":"archive/2024/","title":"2024","text":""},{"location":"archive/2023/","title":"2023","text":""},{"location":"archive/2022/","title":"2022","text":""},{"location":"archive/2021/","title":"2021","text":""},{"location":"category/career/","title":"Career","text":""},{"location":"category/media/","title":"Media","text":""},{"location":"category/api/","title":"API","text":""},{"location":"category/announcements/","title":"Announcements","text":""},{"location":"category/product-management/","title":"Product Management","text":""},{"location":"category/books/","title":"Books","text":""},{"location":"category/business-analysis/","title":"Business Analysis","text":""},{"location":"page/2/","title":"Recent Publications","text":""},{"location":"page/3/","title":"Recent Publications","text":""},{"location":"page/4/","title":"Recent Publications","text":""},{"location":"archive/2024/page/2/","title":"2024","text":""},{"location":"archive/2023/page/2/","title":"2023","text":""}]}